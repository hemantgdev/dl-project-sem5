{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "# Set your OpenAI API key\n",
    "client = OpenAI(\n",
    "    # This is preferably set as an environment variable\n",
    "    api_key=\"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\"\n",
    ")\n",
    "\n",
    "\n",
    "# Step 1: Convert CSV to JSONL\n",
    "def convert_csv_to_jsonl(input_csv, output_jsonl, prompt_column):\n",
    "    \"\"\"\n",
    "    Convert a CSV file to a JSONL file for OpenAI's Batch API.\n",
    "    \n",
    "    :param input_csv: Path to the input CSV file.\n",
    "    :param output_jsonl: Path to the output JSONL file.\n",
    "    :param prompt_column: Column name in the CSV containing the prompts.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_csv)\n",
    "    with open(output_jsonl, 'w') as jsonl_file:\n",
    "        for index, row in df.iterrows():\n",
    "            json_obj = {\n",
    "                \"custom_id\": f\"request-{index}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": \"gpt-4o-mini\",\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": f\"News article {row['content']} {prompt_column}\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"max_tokens\": 150  # Optional: add token limit\n",
    "                }\n",
    "            }\n",
    "            jsonl_file.write(json.dumps(json_obj) + '\\n')\n",
    "\n",
    "def upload_jsonl_file(jsonl_path):\n",
    "    \"\"\"\n",
    "    Upload the JSONL file to OpenAI's API for batch processing.\n",
    "    \n",
    "    :param jsonl_path: Path to the JSONL file.\n",
    "    :return: The uploaded file ID.\n",
    "    \"\"\"\n",
    "    with open(jsonl_path, \"rb\") as file:\n",
    "        response = client.files.create(\n",
    "            file=file,\n",
    "            purpose=\"batch\"\n",
    "        )\n",
    "    return response.id\n",
    "\n",
    "def create_batch_job(input_file_id):\n",
    "    \"\"\"\n",
    "    Create a batch job using the uploaded file.\n",
    "    \n",
    "    :param input_file_id: The ID of the uploaded JSONL file.\n",
    "    :return: The batch job ID.\n",
    "    \"\"\"\n",
    "\n",
    "    batch_job = client.batches.create(\n",
    "            input_file_id=input_file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\"\n",
    "        )\n",
    "    return batch_job.id\n",
    "\n",
    "def monitor_batch_job(batch_job_id):\n",
    "    \"\"\"\n",
    "    Monitor the status of a batch job.\n",
    "    \n",
    "    :param batch_job_id: The ID of the batch job.\n",
    "    :return: The batch job status object when completed.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        batch_status = client.batches.retrieve(batch_job_id)\n",
    "        print(f\"Current status: {batch_status.status}\")\n",
    "        \n",
    "        if batch_status.status in ['completed', 'failed']:\n",
    "            return batch_status\n",
    "        \n",
    "        time.sleep(60)  # Wait for 1 minute before checking again\n",
    "\n",
    "def download_results(output_file_id, output_path):\n",
    "    \"\"\"\n",
    "    Download the results of a batch job.\n",
    "    \n",
    "    :param output_file_id: The ID of the output file.\n",
    "    :param output_path: Path to save the output file.\n",
    "    \"\"\"\n",
    "    # Use the files download method from the client\n",
    "    response = client.files.content(output_file_id)\n",
    "    \n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(response.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONL file created: try1jsonl.jsonl\n"
     ]
    }
   ],
   "source": [
    "input_csv = \"data.csv\"  \n",
    "output_jsonl = \"try1jsonl.jsonl\"\n",
    "prompt_column = \"\"\"\n",
    "\n",
    "prompt_template = Extract features from this cricket article to predict a player's future performance: 1.  ⁠Extract Key Features:  - Player Mentioned- Runs Scored\n",
    "   - Wickets Taken\n",
    "   - Match Context (Location, Opponent)\n",
    "   - Mention of Injuries or Selection Updates\n",
    "   - Predicted Player Confidence Level (0 to 1)\n",
    "   - Reason for Praise or Criticism (Short Text)\n",
    "\n",
    "2.  ⁠Discover additional context-specific features:\n",
    "   - Tactical Hints (Role Changes, Strategy Adjustments)\n",
    "   - Emerging Performance Indicators\n",
    "\n",
    "Provide a *short justification* explaining why these features are relevant.\n",
    "\n",
    "Article: {article_content}\n",
    "\"\"\"\n",
    "convert_csv_to_jsonl(input_csv, output_jsonl, prompt_column)\n",
    "print(f\"JSONL file created: {output_jsonl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file uploaded. File ID: file-1DiMctbnv2D7gN5sdHaLQ1\n"
     ]
    }
   ],
   "source": [
    "input_file_id = upload_jsonl_file(output_jsonl)\n",
    "print(f\"Input file uploaded. File ID: {input_file_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Invalid value: '1h'. Supported values are: '24h'.\", 'type': 'invalid_request_error', 'param': 'completion_window', 'code': 'invalid_value'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch_job_id \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_batch_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 64\u001b[0m, in \u001b[0;36mcreate_batch_job\u001b[0;34m(input_file_id)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_batch_job\u001b[39m(input_file_id):\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m    Create a batch job using the uploaded file.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    :param input_file_id: The ID of the uploaded JSONL file.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    :return: The batch job ID.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     batch_job \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_file_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_file_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1h\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch_job\u001b[38;5;241m.\u001b[39mid\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/openai/lib/python3.11/site-packages/openai/resources/batches.py:96\u001b[0m, in \u001b[0;36mBatches.create\u001b[0;34m(self, completion_window, endpoint, input_file_id, metadata, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m     63\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Batch:\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    Creates and executes a batch from an uploaded file of requests\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/batches\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompletion_window\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompletion_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mendpoint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_file_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_file_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBatchCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/openai/lib/python3.11/site-packages/openai/_base_client.py:1280\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1268\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1275\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1277\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1278\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1279\u001b[0m     )\n\u001b[0;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/openai/lib/python3.11/site-packages/openai/_base_client.py:957\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    955\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/openai/lib/python3.11/site-packages/openai/_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1070\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Invalid value: '1h'. Supported values are: '24h'.\", 'type': 'invalid_request_error', 'param': 'completion_window', 'code': 'invalid_value'}}"
     ]
    }
   ],
   "source": [
    "batch_job_id = create_batch_job(input_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    input_csv = \"your_input.csv\"  # Path to your input CSV file\n",
    "    output_jsonl = \"input_file.jsonl\"  # Path to save the JSONL file\n",
    "    prompt_column = \"prompt\"  # Column in the CSV containing prompts\n",
    "    output_results = \"output_results.jsonl\"  # Path to save the results\n",
    "    \n",
    "    # Step 1: Convert CSV to JSONL\n",
    "\n",
    "    \n",
    "    # Step 2: Upload JSONL File\n",
    "    input_file_id = upload_jsonl_file(output_jsonl)\n",
    "    print(f\"Input file uploaded. File ID: {input_file_id}\")\n",
    "    \n",
    "    # Step 3: Create Batch Job\n",
    "    batch_job_id = create_batch_job(input_file_id)\n",
    "    print(f\"Batch job created. Job ID: {batch_job_id}\")\n",
    "    \n",
    "    # Step 4: Monitor Batch Job\n",
    "    batch_status = monitor_batch_job(batch_job_id)\n",
    "    print(f\"Batch job completed. Status: {batch_status['status']}\")\n",
    "    \n",
    "    if batch_status['status'] == 'completed':\n",
    "        # Step 5: Download Results\n",
    "        output_file_id = batch_status['output_file_ids'][0]\n",
    "        download_results(output_file_id, output_results)\n",
    "        print(f\"Results downloaded to: {output_results}\")\n",
    "    else:\n",
    "        print(\"Batch job failed. Check the API for details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Y9rGrC0YaSAcK4hmMuO1uqgx on tokens per min (TPM): Limit 800000, Used 799576, Requested 2283. Please try again in 139ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 182\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# For async processing (in an async context)\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# results = asyncio.run(processor.process_csv_async(\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;66;03m#     csv_path='input.csv', \u001b[39;00m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m#     text_column='content', \u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m#     output_path='output_async.csv'\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# ))\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 182\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 167\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m processor \u001b[38;5;241m=\u001b[39m FastBatchProcessor(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Synchronous processing\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_csv_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata_3of3.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput_3of3_4o.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    172\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 117\u001b[0m, in \u001b[0;36mFastBatchProcessor.process_csv_batch\u001b[0;34m(self, csv_path, text_column, output_path, model)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Process texts\u001b[39;00m\n\u001b[1;32m    116\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 117\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_texts_concurrently\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Optional: save results\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 98\u001b[0m, in \u001b[0;36mFastBatchProcessor.process_texts_concurrently\u001b[0;34m(self, texts, model, max_tokens)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_workers) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m     90\u001b[0m     futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     91\u001b[0m         executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m     92\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m         ) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts\n\u001b[1;32m     97\u001b[0m     ]\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_completed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 98\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_workers) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m     90\u001b[0m     futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     91\u001b[0m         executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m     92\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m         ) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts\n\u001b[1;32m     97\u001b[0m     ]\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mas_completed(futures)]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/openai/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/openai/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/openai/lib/python3.11/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/openai/lib/python3.11/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/openai/lib/python3.11/site-packages/openai/resources/chat/completions.py:829\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    826\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    827\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    828\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/openai/lib/python3.11/site-packages/openai/_base_client.py:1280\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1268\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1275\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1277\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1278\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1279\u001b[0m     )\n\u001b[0;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/openai/lib/python3.11/site-packages/openai/_base_client.py:957\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    955\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/openai/lib/python3.11/site-packages/openai/_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1045\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1046\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/openai/lib/python3.11/site-packages/openai/_base_client.py:1095\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1095\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/openai/lib/python3.11/site-packages/openai/_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1045\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1046\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/openai/lib/python3.11/site-packages/openai/_base_client.py:1095\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1095\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/openai/lib/python3.11/site-packages/openai/_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1070\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Y9rGrC0YaSAcK4hmMuO1uqgx on tokens per min (TPM): Limit 800000, Used 799576, Requested 2283. Please try again in 139ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import json\n",
    "import asyncio\n",
    "import aiohttp\n",
    "max_tokens = 1000\n",
    "\n",
    "prompt = \"\"\"Extract features from the given cricket news article to predict the future performance of players mentioned. Your task is to analyze the article and identify all relevant players, extracting information about their recent performance, form, and role in the team. For each player, provide concise performance metrics, insights into their playing style and form, arguments (positive or negative) about their performance, and numerical predictions for their performance in the current match and future matches. Specifically:\n",
    "\n",
    "Identify all players mentioned in the article, including those highlighted in sections like team line-ups, 'Watch out for,' or any specific mentions of individuals. For each player identified, include the following information:\n",
    "\n",
    "1. player_name: Provide the name of the player in 'firstname_lastname' format. For example, Cameron White should be formatted as 'Cameron_White.'\n",
    "\n",
    "2. Metrics: Provide concise, keyword based notes on the player’s performance metrics mentioned in the article. This could include stats like batting averages, strike rates, economy rates, records, notable achievements, or any other performance-related data highlighted.\n",
    "\n",
    "3. Insights: Write brief keyword based insights into the player’s playing style, form, strengths, weaknesses, and role in the team as described in the article. This can include information about their recent performances, potential to adapt to certain game formats, or their fit within the team’s strategy.\n",
    "\n",
    "4. Arguments: Summarize positive or negative arguments or narratives about the player as drawn from the article in a very concise manner. For instance, if the article mentions a player’s strong Twenty20 record or doubts their ability to adapt to the format, include these perspectives.\n",
    "\n",
    "5. match_performance: Assign a numerical value between 0 and 1 indicating how the article portrays the player’s likely performance in the upcoming match. A value of 0 indicates very poor expectations, while a value of 1 indicates excellent expectations based on the article’s description.\n",
    "\n",
    "6. predicted_future_performance: Assign a numerical value between 0 and 1 predicting the player’s likely performance in future matches based on the information provided in the article. This should take into account their historical performance, current form, and the overall sentiment about the player in the article.\n",
    "\n",
    "Output the result as a JSON array of objects. Each object should represent one player and contain the extracted information in the following structure:\n",
    "\n",
    "{\n",
    "  'player_name': 'firstname_lastname',\n",
    "  'Metrics': 'Concise notes on performance metrics',\n",
    "  'Insights': 'Brief insights into playing style, form, and role',\n",
    "  'Arguments': 'Positive or negative arguments mentioned in the article',\n",
    "  'match_performance': <number between 0 and 1>,\n",
    "  'predicted_future_performance': <number between 0 and 1>\n",
    "}\n",
    "\n",
    "If multiple players are mentioned in the article, create a list of objects, one for each player, and include them all in a single JSON array. If only one player is mentioned, return an array with a single object.\n",
    "\n",
    "Example article style: A news report about a Twenty20 cricket match where players like Cameron White, Sourav Ganguly, Rahul Dravid, and Jacques Kallis are mentioned. The article may include descriptions of their performance metrics, role in the team, historical records, and match predictions. Use the provided information to fill in the JSON structure for each player mentioned. Return only the JSON array as the output.\n",
    "\"\"\"\n",
    "\n",
    "class FastBatchProcessor:\n",
    "    def __init__(self, api_key=None, max_workers=10):\n",
    "        \"\"\"\n",
    "        Initialize the batch processor with OpenAI client and concurrency settings.\n",
    "        \n",
    "        :param api_key: OpenAI API key (optional, will use environment variable if not provided)\n",
    "        :param max_workers: Maximum number of concurrent workers for processing\n",
    "        \"\"\"\n",
    "        self.client = OpenAI(api_key=\"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\")\n",
    "        self.max_workers = max_workers\n",
    "\n",
    "    async def process_text_async(self, texts, model=\"gpt-4o-mini\", max_tokens=1000):\n",
    "        \"\"\"\n",
    "        Asynchronously process multiple texts using OpenAI's API.\n",
    "        \n",
    "        :param texts: List of texts to process\n",
    "        :param model: OpenAI model to use\n",
    "        :param max_tokens: Maximum tokens for response\n",
    "        :return: List of processed results\n",
    "        \"\"\"\n",
    "        async def process_single_text(session, text):\n",
    "            async with session.post(\"https://api.openai.com/v1/chat/completions\", \n",
    "                                    headers={\n",
    "                                        \"Authorization\": f\"Bearer {self.client.api_key}\",\n",
    "                                        \"Content-Type\": \"application/json\"\n",
    "                                    },\n",
    "                                    json={\n",
    "                                        \"model\": model,\n",
    "                                        \"messages\": [{\"role\": \"user\", \"content\": text}],\n",
    "                                        \"max_tokens\": max_tokens\n",
    "                                    }) as response:\n",
    "                return await response.json()\n",
    "\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            tasks = [process_single_text(session, text) for text in texts]\n",
    "            return await asyncio.gather(*tasks)\n",
    "\n",
    "    def process_texts_concurrently(self, texts, model=\"gpt-4o-mini\", max_tokens=1000):\n",
    "        \"\"\"\n",
    "        Concurrently process texts using thread pool executor.\n",
    "        \n",
    "        :param texts: List of texts to process\n",
    "        :param model: OpenAI model to use\n",
    "        :param max_tokens: Maximum tokens for response\n",
    "        :return: List of processed results\n",
    "        \"\"\"\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            futures = [\n",
    "                executor.submit(\n",
    "                    self.client.chat.completions.create,\n",
    "                    model=model,\n",
    "                    messages=[{\"role\": \"user\", \"content\": text+prompt}],\n",
    "                    max_tokens=max_tokens\n",
    "                ) for text in texts\n",
    "            ]\n",
    "            return [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "\n",
    "    def process_csv_batch(self, csv_path, text_column, output_path=None, model=\"gpt-4o-mini\"):\n",
    "        \"\"\"\n",
    "        Process an entire CSV file in batches using concurrent processing.\n",
    "        \n",
    "        :param csv_path: Path to input CSV file\n",
    "        :param text_column: Column containing texts to process\n",
    "        :param output_path: Optional path to save results\n",
    "        :param model: OpenAI model to use\n",
    "        :return: Processed results\n",
    "        \"\"\"\n",
    "        # Read CSV\n",
    "        df = pd.read_csv(csv_path)\n",
    "        texts = df[text_column].tolist()\n",
    "        dates = df['date'].tolist()  # Add date column to be included in the results\n",
    "\n",
    "        # Process texts\n",
    "        start_time = time.time()\n",
    "        results = self.process_texts_concurrently(texts, model)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Optional: save results\n",
    "        if output_path:\n",
    "            output_df = pd.DataFrame({\n",
    "                'date': dates,  # Include date column\n",
    "                'original_text': texts,\n",
    "                'processed_results': [r.choices[0].message.content for r in results]\n",
    "            })\n",
    "            output_df.to_csv(output_path, index=False)\n",
    "\n",
    "        print(f\"Processed {len(texts)} texts in {end_time - start_time:.2f} seconds\")\n",
    "        return results\n",
    "\n",
    "    async def process_csv_async(self, csv_path, text_column, output_path=None, model=\"gpt-4o-mini\"):\n",
    "        \"\"\"\n",
    "        Asynchronously process CSV file.\n",
    "        \n",
    "        :param csv_path: Path to input CSV file\n",
    "        :param text_column: Column containing texts to process\n",
    "        :param output_path: Optional path to save results\n",
    "        :param model: OpenAI model to use\n",
    "        :return: Processed results\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(csv_path)\n",
    "        texts = df[text_column].tolist()\n",
    "        dates = df['date'].tolist()  # Add date column\n",
    "\n",
    "        start_time = time.time()\n",
    "        results = await self.process_text_async(texts, model)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Optional: save results\n",
    "        if output_path:\n",
    "            output_df = pd.DataFrame({\n",
    "                'date': dates,  # Include date column\n",
    "                'original_text': texts,\n",
    "                'processed_results': [r['choices'][0]['message']['content'] for r in results]\n",
    "            })\n",
    "            output_df.to_csv(output_path, index=False)\n",
    "\n",
    "        print(f\"Async processed {len(texts)} texts in {end_time - start_time:.2f} seconds\")\n",
    "        return results\n",
    "\n",
    "def main():\n",
    "    # Example usage\n",
    "    processor = FastBatchProcessor(max_workers=100)\n",
    "    \n",
    "    # Synchronous processing\n",
    "    results = processor.process_csv_batch(\n",
    "        csv_path='data_3of3.csv', \n",
    "        text_column='content', \n",
    "        output_path='output_3of3_4o.csv',\n",
    "        model=\"gpt-4o\"\n",
    "    )\n",
    "    \n",
    "    # For async processing (in an async context)\n",
    "    # results = asyncio.run(processor.process_csv_async(\n",
    "    #     csv_path='input.csv', \n",
    "    #     text_column='content', \n",
    "    #     output_path='output_async.csv'\n",
    "    # ))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('output_1of3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Stephen Fleming and Glenn McGrath at the launch of the Champions Twenty20 League in Delhi¬© AFP\\nCricket entered a new paradigm on Thursday with the launch of an international Twenty20 competition that will feature teams, operated as franchises, and players from across the world. Called the Champions Twenty20 League, it will be run by four cricket boards - of India, England, Australia and South Africa -and will feature the top two teams from each of those countries.\\nThough no players were named as participants, several big names were present at the ceremony - Sachin Tendulkar, Rahul Dravid, Sourav Ganguly, Anil Kumble, Glenn McGrath and Stephen Fleming.\\nThe inaugural tournament is scheduled to start in October 2008 and is planned over nine days, with $5 million in prize money, including $2 million for the winners.\\nThat the league has official sanction, as opposed to the Indian Cricket League, was borne out by the men on the dais - ICC president Ray Mali, Indian board president Sharad Pawar, the Cricket South Africa CEO, Gerald Majola, and Cricket Australia's chief executive James Sutherland. The ECB was represented by deputy chief executive Hugh Morris.\\nWhile the teams from England, Australia and South Africa will be the top two teams of their existing Twenty20 tournaments, India's representatives will qualify through a new league called the BCCI Indian Premier League. This tournament, to be held in April 2008, will last for 44 days and involve 59 matches.\\nEach team in this league will have a minimum of 16 players, including four international players and four from the area where the team is based. The matches will be played on a home-and-away basis, guaranteeing seven matches at each venue. The matches will be played on Saturdays, starting at 5 pm India time and 8 pm. All matches will be televised and the rights to telecast these matches will be sold through a separate tender. No matches will be played concurrently.\\nThe league will be run by a governing council comprising former Indian captains Ravi Shastri, Sunil Gavaskar, MAK Pataudi, BCCI office-bearers Rajiv Shukla and Chirayu Amin, Inderjit Singh Bindra, the Punjab Cricket Association president, and Arun Jaitley, the president of the Delhi and Districts Cricket Association. Lalit Modi, a BCCI vice-president, was named as its convenor.\\nCricket Australia Chief Executive Officer James Sutherland said the new league would boost interstate cricket. Apart from giving the two state KFC Twenty20 finalists the chance to compete for the overall prize, it would expose interstate cricket stars to international competition and give fans of local state-based teams the excitement of supporting their favourite players on a global stage.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['original_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13-Sep-07',\n",
       " '16-Sep-07',\n",
       " '19-Sep-07',\n",
       " '23-Sep-07',\n",
       " '1-Oct-07',\n",
       " '4-Oct-07',\n",
       " '6-Oct-07',\n",
       " '9-Oct-07',\n",
       " '12-Oct-07',\n",
       " '16-Oct-07',\n",
       " '19-Oct-07',\n",
       " '28-Oct-07',\n",
       " '30-Oct-07',\n",
       " '31-Oct-07',\n",
       " '7-Nov-07',\n",
       " '13-Nov-07',\n",
       " '2-Dec-07',\n",
       " '2-Dec-07',\n",
       " '14-Dec-07',\n",
       " '16-Dec-07',\n",
       " '18-Dec-07',\n",
       " '18-Dec-07',\n",
       " '23-Dec-07',\n",
       " '30-Dec-07',\n",
       " '14-Jan-08',\n",
       " '23-Jan-08',\n",
       " '24-Jan-08',\n",
       " '25-Jan-08',\n",
       " '26-Jan-08',\n",
       " '28-Jan-08',\n",
       " '2-Feb-08',\n",
       " '5-Feb-08',\n",
       " '6-Feb-08',\n",
       " '6-Feb-08',\n",
       " '7-Feb-08',\n",
       " '7-Feb-08',\n",
       " '8-Feb-08',\n",
       " '9-Feb-08',\n",
       " '9-Feb-08',\n",
       " '10-Feb-08',\n",
       " '11-Feb-08',\n",
       " '11-Feb-08',\n",
       " '11-Feb-08',\n",
       " '11-Feb-08',\n",
       " '11-Feb-08',\n",
       " '11-Feb-08',\n",
       " '12-Feb-08',\n",
       " '13-Feb-08',\n",
       " '13-Feb-08',\n",
       " '13-Feb-08',\n",
       " '14-Feb-08',\n",
       " '14-Feb-08',\n",
       " '14-Feb-08',\n",
       " '14-Feb-08',\n",
       " '15-Feb-08',\n",
       " '15-Feb-08',\n",
       " '15-Feb-08',\n",
       " '15-Feb-08',\n",
       " '16-Feb-08',\n",
       " '16-Feb-08',\n",
       " '17-Feb-08',\n",
       " '17-Feb-08',\n",
       " '17-Feb-08',\n",
       " '18-Feb-08',\n",
       " '18-Feb-08',\n",
       " '18-Feb-08',\n",
       " '18-Feb-08',\n",
       " '18-Feb-08',\n",
       " '19-Feb-08',\n",
       " '19-Feb-08',\n",
       " '19-Feb-08',\n",
       " '19-Feb-08',\n",
       " '19-Feb-08',\n",
       " '20-Feb-08',\n",
       " '20-Feb-08',\n",
       " '20-Feb-08',\n",
       " '20-Feb-08',\n",
       " '20-Feb-08',\n",
       " '20-Feb-08',\n",
       " '20-Feb-08',\n",
       " '20-Feb-08',\n",
       " '20-Feb-08',\n",
       " '20-Feb-08',\n",
       " '20-Feb-08',\n",
       " '21-Feb-08',\n",
       " '21-Feb-08',\n",
       " '21-Feb-08',\n",
       " '21-Feb-08',\n",
       " '22-Feb-08',\n",
       " '22-Feb-08',\n",
       " '22-Feb-08',\n",
       " '22-Feb-08',\n",
       " '22-Feb-08',\n",
       " '22-Feb-08',\n",
       " '23-Feb-08',\n",
       " '23-Feb-08',\n",
       " '23-Feb-08',\n",
       " '23-Feb-08',\n",
       " '24-Feb-08',\n",
       " '24-Feb-08',\n",
       " '25-Feb-08',\n",
       " '25-Feb-08',\n",
       " '26-Feb-08',\n",
       " '26-Feb-08',\n",
       " '26-Feb-08',\n",
       " '27-Feb-08',\n",
       " '27-Feb-08',\n",
       " '28-Feb-08',\n",
       " '28-Feb-08',\n",
       " '28-Feb-08',\n",
       " '28-Feb-08',\n",
       " '28-Feb-08',\n",
       " '29-Feb-08',\n",
       " '29-Feb-08',\n",
       " '1-Mar-08',\n",
       " '1-Mar-08',\n",
       " '2-Mar-08',\n",
       " '2-Mar-08',\n",
       " '2-Mar-08',\n",
       " '3-Mar-08',\n",
       " '4-Mar-08',\n",
       " '5-Mar-08',\n",
       " '5-Mar-08',\n",
       " '7-Mar-08',\n",
       " '7-Mar-08',\n",
       " '8-Mar-08',\n",
       " '9-Mar-08',\n",
       " '9-Mar-08',\n",
       " '10-Mar-08',\n",
       " '10-Mar-08',\n",
       " '10-Mar-08',\n",
       " '11-Mar-08',\n",
       " '11-Mar-08',\n",
       " '11-Mar-08',\n",
       " '11-Mar-08',\n",
       " '11-Mar-08',\n",
       " '11-Mar-08',\n",
       " '11-Mar-08',\n",
       " '11-Mar-08',\n",
       " '12-Mar-08',\n",
       " '12-Mar-08',\n",
       " '13-Mar-08',\n",
       " '13-Mar-08',\n",
       " '13-Mar-08',\n",
       " '14-Mar-08',\n",
       " '14-Mar-08',\n",
       " '15-Mar-08',\n",
       " '15-Mar-08',\n",
       " '16-Mar-08',\n",
       " '16-Mar-08',\n",
       " '16-Mar-08',\n",
       " '18-Mar-08',\n",
       " '19-Mar-08',\n",
       " '19-Mar-08',\n",
       " '19-Mar-08',\n",
       " '21-Mar-08',\n",
       " '21-Mar-08',\n",
       " '22-Mar-08',\n",
       " '22-Mar-08',\n",
       " '22-Mar-08',\n",
       " '23-Mar-08',\n",
       " '23-Mar-08',\n",
       " '24-Mar-08',\n",
       " '25-Mar-08',\n",
       " '26-Mar-08',\n",
       " '27-Mar-08',\n",
       " '27-Mar-08',\n",
       " '29-Mar-08',\n",
       " '29-Mar-08',\n",
       " '29-Mar-08',\n",
       " '30-Mar-08',\n",
       " '30-Mar-08',\n",
       " '1-Apr-08',\n",
       " '2-Apr-08',\n",
       " '2-Apr-08',\n",
       " '3-Apr-08',\n",
       " '3-Apr-08',\n",
       " '3-Apr-08',\n",
       " '3-Apr-08',\n",
       " '4-Apr-08',\n",
       " '4-Apr-08',\n",
       " '4-Apr-08',\n",
       " '5-Apr-08',\n",
       " '5-Apr-08',\n",
       " '6-Apr-08',\n",
       " '7-Apr-08',\n",
       " '7-Apr-08',\n",
       " '7-Apr-08',\n",
       " '7-Apr-08',\n",
       " '8-Apr-08',\n",
       " '8-Apr-08',\n",
       " '8-Apr-08',\n",
       " '8-Apr-08',\n",
       " '8-Apr-08',\n",
       " '9-Apr-08',\n",
       " '9-Apr-08',\n",
       " '9-Apr-08',\n",
       " '9-Apr-08',\n",
       " '9-Apr-08',\n",
       " '9-Apr-08',\n",
       " '10-Apr-08',\n",
       " '10-Apr-08',\n",
       " '10-Apr-08',\n",
       " '10-Apr-08',\n",
       " '11-Apr-08',\n",
       " '11-Apr-08',\n",
       " '11-Apr-08',\n",
       " '11-Apr-08',\n",
       " '13-Apr-08',\n",
       " '13-Apr-08',\n",
       " '14-Apr-08',\n",
       " '14-Apr-08',\n",
       " '14-Apr-08',\n",
       " '14-Apr-08',\n",
       " '14-Apr-08',\n",
       " '15-Apr-08',\n",
       " '15-Apr-08',\n",
       " '15-Apr-08',\n",
       " '15-Apr-08',\n",
       " '15-Apr-08',\n",
       " '15-Apr-08',\n",
       " '15-Apr-08',\n",
       " '15-Apr-08',\n",
       " '16-Apr-08',\n",
       " '16-Apr-08',\n",
       " '16-Apr-08',\n",
       " '16-Apr-08',\n",
       " '16-Apr-08',\n",
       " '16-Apr-08',\n",
       " '16-Apr-08',\n",
       " '17-Apr-08',\n",
       " '17-Apr-08',\n",
       " '17-Apr-08',\n",
       " '17-Apr-08',\n",
       " '17-Apr-08',\n",
       " '17-Apr-08',\n",
       " '17-Apr-08',\n",
       " '17-Apr-08',\n",
       " '17-Apr-08',\n",
       " '18-Apr-08',\n",
       " '18-Apr-08',\n",
       " '18-Apr-08',\n",
       " '18-Apr-08',\n",
       " '18-Apr-08',\n",
       " '18-Apr-08',\n",
       " '18-Apr-08',\n",
       " '18-Apr-08',\n",
       " '18-Apr-08',\n",
       " '18-Apr-08',\n",
       " '18-Apr-08',\n",
       " '19-Apr-08',\n",
       " '19-Apr-08',\n",
       " '19-Apr-08',\n",
       " '19-Apr-08',\n",
       " '19-Apr-08',\n",
       " '19-Apr-08',\n",
       " '19-Apr-08',\n",
       " '19-Apr-08',\n",
       " '20-Apr-08',\n",
       " '20-Apr-08',\n",
       " '20-Apr-08',\n",
       " '20-Apr-08',\n",
       " '20-Apr-08',\n",
       " '20-Apr-08',\n",
       " '20-Apr-08',\n",
       " '21-Apr-08',\n",
       " '21-Apr-08',\n",
       " '21-Apr-08',\n",
       " '21-Apr-08',\n",
       " '21-Apr-08',\n",
       " '22-Apr-08',\n",
       " '22-Apr-08',\n",
       " '22-Apr-08',\n",
       " '22-Apr-08',\n",
       " '22-Apr-08',\n",
       " '22-Apr-08',\n",
       " '22-Apr-08',\n",
       " '23-Apr-08',\n",
       " '23-Apr-08',\n",
       " '23-Apr-08',\n",
       " '23-Apr-08',\n",
       " '23-Apr-08',\n",
       " '24-Apr-08',\n",
       " '24-Apr-08',\n",
       " '24-Apr-08',\n",
       " '24-Apr-08',\n",
       " '24-Apr-08',\n",
       " '24-Apr-08',\n",
       " '24-Apr-08',\n",
       " '24-Apr-08',\n",
       " '25-Apr-08',\n",
       " '25-Apr-08',\n",
       " '25-Apr-08',\n",
       " '25-Apr-08',\n",
       " '25-Apr-08',\n",
       " '25-Apr-08',\n",
       " '25-Apr-08',\n",
       " '25-Apr-08',\n",
       " '25-Apr-08',\n",
       " '25-Apr-08',\n",
       " '26-Apr-08',\n",
       " '26-Apr-08',\n",
       " '26-Apr-08',\n",
       " '26-Apr-08',\n",
       " '26-Apr-08',\n",
       " '26-Apr-08',\n",
       " '26-Apr-08',\n",
       " '26-Apr-08',\n",
       " '26-Apr-08',\n",
       " '26-Apr-08',\n",
       " '26-Apr-08',\n",
       " '27-Apr-08',\n",
       " '27-Apr-08',\n",
       " '27-Apr-08',\n",
       " '27-Apr-08',\n",
       " '27-Apr-08',\n",
       " '27-Apr-08',\n",
       " '27-Apr-08',\n",
       " '28-Apr-08',\n",
       " '28-Apr-08',\n",
       " '28-Apr-08',\n",
       " '28-Apr-08',\n",
       " '28-Apr-08',\n",
       " '28-Apr-08',\n",
       " '28-Apr-08',\n",
       " '28-Apr-08',\n",
       " '28-Apr-08',\n",
       " '28-Apr-08',\n",
       " '29-Apr-08',\n",
       " '29-Apr-08',\n",
       " '29-Apr-08',\n",
       " '29-Apr-08',\n",
       " '29-Apr-08',\n",
       " '29-Apr-08',\n",
       " '30-Apr-08',\n",
       " '30-Apr-08',\n",
       " '30-Apr-08',\n",
       " '30-Apr-08',\n",
       " '30-Apr-08',\n",
       " '30-Apr-08',\n",
       " '30-Apr-08',\n",
       " '30-Apr-08',\n",
       " '1-May-08',\n",
       " '1-May-08',\n",
       " '1-May-08',\n",
       " '1-May-08',\n",
       " '1-May-08',\n",
       " '1-May-08',\n",
       " '1-May-08',\n",
       " '1-May-08',\n",
       " '1-May-08',\n",
       " '2-May-08',\n",
       " '2-May-08',\n",
       " '2-May-08',\n",
       " '2-May-08',\n",
       " '2-May-08',\n",
       " '3-May-08',\n",
       " '3-May-08',\n",
       " '3-May-08',\n",
       " '3-May-08',\n",
       " '3-May-08',\n",
       " '3-May-08',\n",
       " '3-May-08',\n",
       " '4-May-08',\n",
       " '4-May-08',\n",
       " '4-May-08',\n",
       " '4-May-08',\n",
       " '4-May-08',\n",
       " '5-May-08',\n",
       " '5-May-08',\n",
       " '5-May-08',\n",
       " '5-May-08',\n",
       " '5-May-08',\n",
       " '5-May-08',\n",
       " '6-May-08',\n",
       " '6-May-08',\n",
       " '6-May-08',\n",
       " '6-May-08',\n",
       " '6-May-08',\n",
       " '6-May-08',\n",
       " '6-May-08',\n",
       " '7-May-08',\n",
       " '7-May-08',\n",
       " '7-May-08',\n",
       " '7-May-08',\n",
       " '7-May-08',\n",
       " '7-May-08',\n",
       " '7-May-08',\n",
       " '8-May-08',\n",
       " '8-May-08',\n",
       " '8-May-08',\n",
       " '8-May-08',\n",
       " '8-May-08',\n",
       " '8-May-08',\n",
       " '8-May-08',\n",
       " '9-May-08',\n",
       " '9-May-08',\n",
       " '9-May-08',\n",
       " '9-May-08',\n",
       " '9-May-08',\n",
       " '10-May-08',\n",
       " '10-May-08',\n",
       " '10-May-08',\n",
       " '10-May-08',\n",
       " '11-May-08',\n",
       " '11-May-08',\n",
       " '11-May-08',\n",
       " '11-May-08',\n",
       " '12-May-08',\n",
       " '12-May-08',\n",
       " '12-May-08',\n",
       " '12-May-08',\n",
       " '12-May-08',\n",
       " '12-May-08',\n",
       " '12-May-08',\n",
       " '12-May-08',\n",
       " '13-May-08',\n",
       " '13-May-08',\n",
       " '13-May-08',\n",
       " '13-May-08',\n",
       " '13-May-08',\n",
       " '13-May-08',\n",
       " '13-May-08',\n",
       " '13-May-08',\n",
       " '14-May-08',\n",
       " '14-May-08',\n",
       " '14-May-08',\n",
       " '14-May-08',\n",
       " '14-May-08',\n",
       " '14-May-08',\n",
       " '14-May-08',\n",
       " '14-May-08',\n",
       " '14-May-08',\n",
       " '14-May-08',\n",
       " '14-May-08',\n",
       " '14-May-08',\n",
       " '15-May-08',\n",
       " '15-May-08',\n",
       " '15-May-08',\n",
       " '15-May-08',\n",
       " '15-May-08',\n",
       " '15-May-08',\n",
       " '16-May-08',\n",
       " '16-May-08',\n",
       " '16-May-08',\n",
       " '16-May-08',\n",
       " '16-May-08',\n",
       " '16-May-08',\n",
       " '16-May-08',\n",
       " '17-May-08',\n",
       " '17-May-08',\n",
       " '17-May-08',\n",
       " '17-May-08',\n",
       " '17-May-08',\n",
       " '17-May-08',\n",
       " '17-May-08',\n",
       " '17-May-08',\n",
       " '18-May-08',\n",
       " '18-May-08',\n",
       " '18-May-08',\n",
       " '18-May-08',\n",
       " '18-May-08',\n",
       " '18-May-08',\n",
       " '18-May-08',\n",
       " '19-May-08',\n",
       " '19-May-08',\n",
       " '19-May-08',\n",
       " '19-May-08',\n",
       " '19-May-08',\n",
       " '19-May-08',\n",
       " '19-May-08',\n",
       " '19-May-08',\n",
       " '20-May-08',\n",
       " '20-May-08',\n",
       " '20-May-08',\n",
       " '20-May-08',\n",
       " '20-May-08',\n",
       " '20-May-08',\n",
       " '21-May-08',\n",
       " '21-May-08',\n",
       " '21-May-08',\n",
       " '21-May-08',\n",
       " '21-May-08',\n",
       " '21-May-08',\n",
       " '22-May-08',\n",
       " '22-May-08',\n",
       " '23-May-08',\n",
       " '23-May-08',\n",
       " '23-May-08',\n",
       " '23-May-08',\n",
       " '24-May-08',\n",
       " '24-May-08',\n",
       " '24-May-08',\n",
       " '24-May-08',\n",
       " '24-May-08',\n",
       " '25-May-08',\n",
       " '25-May-08',\n",
       " '26-May-08',\n",
       " '26-May-08',\n",
       " '26-May-08',\n",
       " '26-May-08',\n",
       " '27-May-08',\n",
       " '27-May-08',\n",
       " '27-May-08',\n",
       " '27-May-08',\n",
       " '28-May-08',\n",
       " '28-May-08',\n",
       " '29-May-08',\n",
       " '29-May-08',\n",
       " '29-May-08',\n",
       " '29-May-08',\n",
       " '29-May-08',\n",
       " '29-May-08',\n",
       " '29-May-08',\n",
       " '29-May-08',\n",
       " '29-May-08',\n",
       " '29-May-08',\n",
       " '30-May-08',\n",
       " '30-May-08',\n",
       " '30-May-08',\n",
       " '30-May-08',\n",
       " '30-May-08',\n",
       " '30-May-08',\n",
       " '30-May-08',\n",
       " '30-May-08',\n",
       " '31-May-08',\n",
       " '31-May-08',\n",
       " '31-May-08',\n",
       " '31-May-08',\n",
       " '31-May-08',\n",
       " '31-May-08',\n",
       " '31-May-08',\n",
       " '31-May-08',\n",
       " '1-Jun-08',\n",
       " '1-Jun-08',\n",
       " '1-Jun-08',\n",
       " '1-Jun-08',\n",
       " '1-Jun-08',\n",
       " '1-Jun-08',\n",
       " '1-Jun-08',\n",
       " '2-Jun-08',\n",
       " '2-Jun-08',\n",
       " '2-Jun-08',\n",
       " '2-Jun-08',\n",
       " '2-Jun-08',\n",
       " '2-Jun-08',\n",
       " '2-Jun-08',\n",
       " '3-Jun-08',\n",
       " '3-Jun-08',\n",
       " '3-Jun-08',\n",
       " '4-Jun-08',\n",
       " '6-Jun-08',\n",
       " '7-Jun-08',\n",
       " '8-Jun-08',\n",
       " '8-Jun-08',\n",
       " '10-Jun-08',\n",
       " '11-Jun-08',\n",
       " '20-Jun-08',\n",
       " '24-Jul-08',\n",
       " '3-Aug-08',\n",
       " '6-Aug-08',\n",
       " '19-Aug-08',\n",
       " '16-Sep-08',\n",
       " '27-Sep-08',\n",
       " '29-Sep-08',\n",
       " '29-Sep-08',\n",
       " '3-Oct-08',\n",
       " '9-Oct-08',\n",
       " '10-Oct-08',\n",
       " '14-Oct-08',\n",
       " '15-Oct-08',\n",
       " '16-Oct-08',\n",
       " '21-Oct-08',\n",
       " '22-Oct-08',\n",
       " '23-Oct-08',\n",
       " '23-Oct-08',\n",
       " '24-Oct-08',\n",
       " '26-Oct-08',\n",
       " '27-Oct-08',\n",
       " '27-Oct-08',\n",
       " '30-Oct-08',\n",
       " '31-Oct-08',\n",
       " '31-Oct-08',\n",
       " '31-Oct-08',\n",
       " '4-Nov-08',\n",
       " '9-Nov-08',\n",
       " '15-Nov-08',\n",
       " '15-Nov-08',\n",
       " '24-Nov-08',\n",
       " '27-Nov-08',\n",
       " '10-Dec-08',\n",
       " '10-Dec-08',\n",
       " '11-Dec-08',\n",
       " '14-Dec-08',\n",
       " '17-Dec-08',\n",
       " '22-Dec-08',\n",
       " '27-Dec-08',\n",
       " '31-Dec-08',\n",
       " '3-Jan-09',\n",
       " '3-Jan-09',\n",
       " '9-Jan-09',\n",
       " '9-Jan-09',\n",
       " '12-Jan-09',\n",
       " '13-Jan-09',\n",
       " '14-Jan-09',\n",
       " '17-Jan-09',\n",
       " '17-Jan-09',\n",
       " '19-Jan-09',\n",
       " '19-Jan-09',\n",
       " '21-Jan-09',\n",
       " '21-Jan-09',\n",
       " '22-Jan-09',\n",
       " '23-Jan-09',\n",
       " '23-Jan-09',\n",
       " '23-Jan-09',\n",
       " '23-Jan-09',\n",
       " '25-Jan-09',\n",
       " '26-Jan-09',\n",
       " '26-Jan-09',\n",
       " '26-Jan-09',\n",
       " '27-Jan-09',\n",
       " '27-Jan-09',\n",
       " '28-Jan-09',\n",
       " '29-Jan-09',\n",
       " '29-Jan-09',\n",
       " '30-Jan-09',\n",
       " '30-Jan-09',\n",
       " '30-Jan-09',\n",
       " '2-Feb-09',\n",
       " '2-Feb-09',\n",
       " '2-Feb-09',\n",
       " '3-Feb-09',\n",
       " '3-Feb-09',\n",
       " '5-Feb-09',\n",
       " '5-Feb-09',\n",
       " '5-Feb-09',\n",
       " '5-Feb-09',\n",
       " '5-Feb-09',\n",
       " '6-Feb-09',\n",
       " '6-Feb-09',\n",
       " '6-Feb-09',\n",
       " '6-Feb-09',\n",
       " '6-Feb-09',\n",
       " '6-Feb-09',\n",
       " '6-Feb-09',\n",
       " '6-Feb-09',\n",
       " '7-Feb-09',\n",
       " '7-Feb-09',\n",
       " '7-Feb-09',\n",
       " '7-Feb-09',\n",
       " '8-Feb-09',\n",
       " '10-Feb-09',\n",
       " '10-Feb-09',\n",
       " '11-Feb-09',\n",
       " '13-Feb-09',\n",
       " '14-Feb-09',\n",
       " '15-Feb-09',\n",
       " '16-Feb-09',\n",
       " '16-Feb-09',\n",
       " '17-Feb-09',\n",
       " '17-Feb-09',\n",
       " '19-Feb-09',\n",
       " '19-Feb-09',\n",
       " '20-Feb-09',\n",
       " '21-Feb-09',\n",
       " '21-Feb-09',\n",
       " '22-Feb-09',\n",
       " '23-Feb-09',\n",
       " '23-Feb-09',\n",
       " '24-Feb-09',\n",
       " '24-Feb-09',\n",
       " '25-Feb-09',\n",
       " '28-Feb-09',\n",
       " '2-Mar-09',\n",
       " '2-Mar-09',\n",
       " '3-Mar-09',\n",
       " '4-Mar-09',\n",
       " '4-Mar-09',\n",
       " '4-Mar-09',\n",
       " '5-Mar-09',\n",
       " '5-Mar-09',\n",
       " '5-Mar-09',\n",
       " '5-Mar-09',\n",
       " '6-Mar-09',\n",
       " '8-Mar-09',\n",
       " '9-Mar-09',\n",
       " '10-Mar-09',\n",
       " '10-Mar-09',\n",
       " '12-Mar-09',\n",
       " '12-Mar-09',\n",
       " '13-Mar-09',\n",
       " '13-Mar-09',\n",
       " '15-Mar-09',\n",
       " '16-Mar-09',\n",
       " '16-Mar-09',\n",
       " '17-Mar-09',\n",
       " '17-Mar-09',\n",
       " '18-Mar-09',\n",
       " '18-Mar-09',\n",
       " '18-Mar-09',\n",
       " '19-Mar-09',\n",
       " '19-Mar-09',\n",
       " '19-Mar-09',\n",
       " '20-Mar-09',\n",
       " '20-Mar-09',\n",
       " '20-Mar-09',\n",
       " '20-Mar-09',\n",
       " '21-Mar-09',\n",
       " '21-Mar-09',\n",
       " '22-Mar-09',\n",
       " '22-Mar-09',\n",
       " '22-Mar-09',\n",
       " '22-Mar-09',\n",
       " '22-Mar-09',\n",
       " '22-Mar-09',\n",
       " '22-Mar-09',\n",
       " '22-Mar-09',\n",
       " '23-Mar-09',\n",
       " '23-Mar-09',\n",
       " '23-Mar-09',\n",
       " '23-Mar-09',\n",
       " '23-Mar-09',\n",
       " '24-Mar-09',\n",
       " '24-Mar-09',\n",
       " '24-Mar-09',\n",
       " '24-Mar-09',\n",
       " '25-Mar-09',\n",
       " '25-Mar-09',\n",
       " '25-Mar-09',\n",
       " '25-Mar-09',\n",
       " '25-Mar-09',\n",
       " '25-Mar-09',\n",
       " '25-Mar-09',\n",
       " '26-Mar-09',\n",
       " '26-Mar-09',\n",
       " '26-Mar-09',\n",
       " '26-Mar-09',\n",
       " '26-Mar-09',\n",
       " '27-Mar-09',\n",
       " '27-Mar-09',\n",
       " '27-Mar-09',\n",
       " '28-Mar-09',\n",
       " '28-Mar-09',\n",
       " '28-Mar-09',\n",
       " '29-Mar-09',\n",
       " '30-Mar-09',\n",
       " '30-Mar-09',\n",
       " '30-Mar-09',\n",
       " '31-Mar-09',\n",
       " '31-Mar-09',\n",
       " '31-Mar-09',\n",
       " '1-Apr-09',\n",
       " '1-Apr-09',\n",
       " '2-Apr-09',\n",
       " '2-Apr-09',\n",
       " '3-Apr-09',\n",
       " '3-Apr-09',\n",
       " '3-Apr-09',\n",
       " '3-Apr-09',\n",
       " '4-Apr-09',\n",
       " '4-Apr-09',\n",
       " '4-Apr-09',\n",
       " '5-Apr-09',\n",
       " '5-Apr-09',\n",
       " '6-Apr-09',\n",
       " '6-Apr-09',\n",
       " '6-Apr-09',\n",
       " '6-Apr-09',\n",
       " '6-Apr-09',\n",
       " '6-Apr-09',\n",
       " '6-Apr-09',\n",
       " '6-Apr-09',\n",
       " '7-Apr-09',\n",
       " '7-Apr-09',\n",
       " '7-Apr-09',\n",
       " '7-Apr-09',\n",
       " '7-Apr-09',\n",
       " '7-Apr-09',\n",
       " '7-Apr-09',\n",
       " '8-Apr-09',\n",
       " '9-Apr-09',\n",
       " '9-Apr-09',\n",
       " '10-Apr-09',\n",
       " '10-Apr-09',\n",
       " '11-Apr-09',\n",
       " '11-Apr-09',\n",
       " '12-Apr-09',\n",
       " '12-Apr-09',\n",
       " '12-Apr-09',\n",
       " '13-Apr-09',\n",
       " '13-Apr-09',\n",
       " '13-Apr-09',\n",
       " '13-Apr-09',\n",
       " '13-Apr-09',\n",
       " '13-Apr-09',\n",
       " '13-Apr-09',\n",
       " '13-Apr-09',\n",
       " '14-Apr-09',\n",
       " '14-Apr-09',\n",
       " '14-Apr-09',\n",
       " '14-Apr-09',\n",
       " '14-Apr-09',\n",
       " '15-Apr-09',\n",
       " '15-Apr-09',\n",
       " '15-Apr-09',\n",
       " '15-Apr-09',\n",
       " '15-Apr-09',\n",
       " '15-Apr-09',\n",
       " '15-Apr-09',\n",
       " '16-Apr-09',\n",
       " '16-Apr-09',\n",
       " '16-Apr-09',\n",
       " '16-Apr-09',\n",
       " '16-Apr-09',\n",
       " '16-Apr-09',\n",
       " '17-Apr-09',\n",
       " '17-Apr-09',\n",
       " '17-Apr-09',\n",
       " '17-Apr-09',\n",
       " '17-Apr-09',\n",
       " '17-Apr-09',\n",
       " '17-Apr-09',\n",
       " '17-Apr-09',\n",
       " '17-Apr-09',\n",
       " '17-Apr-09',\n",
       " '17-Apr-09',\n",
       " '18-Apr-09',\n",
       " '18-Apr-09',\n",
       " '18-Apr-09',\n",
       " '18-Apr-09',\n",
       " '18-Apr-09',\n",
       " '18-Apr-09',\n",
       " '18-Apr-09',\n",
       " '18-Apr-09',\n",
       " '18-Apr-09',\n",
       " '18-Apr-09',\n",
       " '18-Apr-09',\n",
       " '18-Apr-09',\n",
       " '18-Apr-09',\n",
       " '18-Apr-09',\n",
       " '18-Apr-09',\n",
       " '18-Apr-09',\n",
       " '18-Apr-09',\n",
       " '19-Apr-09',\n",
       " '19-Apr-09',\n",
       " '19-Apr-09',\n",
       " '19-Apr-09',\n",
       " '19-Apr-09',\n",
       " '19-Apr-09',\n",
       " '19-Apr-09',\n",
       " '19-Apr-09',\n",
       " '19-Apr-09',\n",
       " '19-Apr-09',\n",
       " '19-Apr-09',\n",
       " '20-Apr-09',\n",
       " '20-Apr-09',\n",
       " '20-Apr-09',\n",
       " '20-Apr-09',\n",
       " '20-Apr-09',\n",
       " '20-Apr-09',\n",
       " '20-Apr-09',\n",
       " '20-Apr-09',\n",
       " '20-Apr-09',\n",
       " '20-Apr-09',\n",
       " '20-Apr-09',\n",
       " '20-Apr-09',\n",
       " '20-Apr-09',\n",
       " '20-Apr-09',\n",
       " '20-Apr-09',\n",
       " '21-Apr-09',\n",
       " '21-Apr-09',\n",
       " '21-Apr-09',\n",
       " '21-Apr-09',\n",
       " '21-Apr-09',\n",
       " '21-Apr-09',\n",
       " '21-Apr-09',\n",
       " '21-Apr-09',\n",
       " '21-Apr-09',\n",
       " '21-Apr-09',\n",
       " '22-Apr-09',\n",
       " '22-Apr-09',\n",
       " '22-Apr-09',\n",
       " '22-Apr-09',\n",
       " '22-Apr-09',\n",
       " '22-Apr-09',\n",
       " '22-Apr-09',\n",
       " '22-Apr-09',\n",
       " '22-Apr-09',\n",
       " '22-Apr-09',\n",
       " '22-Apr-09',\n",
       " '22-Apr-09',\n",
       " '23-Apr-09',\n",
       " '23-Apr-09',\n",
       " '23-Apr-09',\n",
       " '23-Apr-09',\n",
       " '23-Apr-09',\n",
       " '23-Apr-09',\n",
       " '23-Apr-09',\n",
       " '23-Apr-09',\n",
       " '23-Apr-09',\n",
       " '23-Apr-09',\n",
       " '23-Apr-09',\n",
       " '24-Apr-09',\n",
       " '24-Apr-09',\n",
       " '24-Apr-09',\n",
       " '24-Apr-09',\n",
       " '24-Apr-09',\n",
       " '24-Apr-09',\n",
       " '24-Apr-09',\n",
       " '24-Apr-09',\n",
       " '24-Apr-09',\n",
       " '24-Apr-09',\n",
       " '24-Apr-09',\n",
       " '24-Apr-09',\n",
       " '24-Apr-09',\n",
       " '24-Apr-09',\n",
       " '24-Apr-09',\n",
       " '24-Apr-09',\n",
       " '24-Apr-09',\n",
       " '25-Apr-09',\n",
       " '25-Apr-09',\n",
       " '25-Apr-09',\n",
       " '25-Apr-09',\n",
       " '25-Apr-09',\n",
       " '25-Apr-09',\n",
       " '25-Apr-09',\n",
       " '25-Apr-09',\n",
       " '25-Apr-09',\n",
       " '25-Apr-09',\n",
       " '25-Apr-09',\n",
       " '25-Apr-09',\n",
       " '25-Apr-09',\n",
       " '25-Apr-09',\n",
       " '25-Apr-09',\n",
       " '25-Apr-09',\n",
       " '26-Apr-09',\n",
       " '26-Apr-09',\n",
       " '26-Apr-09',\n",
       " '26-Apr-09',\n",
       " '26-Apr-09',\n",
       " '26-Apr-09',\n",
       " '26-Apr-09',\n",
       " '26-Apr-09',\n",
       " '26-Apr-09',\n",
       " '26-Apr-09',\n",
       " '26-Apr-09',\n",
       " '26-Apr-09',\n",
       " '26-Apr-09',\n",
       " '26-Apr-09',\n",
       " '26-Apr-09',\n",
       " '26-Apr-09',\n",
       " '27-Apr-09',\n",
       " '27-Apr-09',\n",
       " '27-Apr-09',\n",
       " '27-Apr-09',\n",
       " '27-Apr-09',\n",
       " '27-Apr-09',\n",
       " '27-Apr-09',\n",
       " '27-Apr-09',\n",
       " '27-Apr-09',\n",
       " '27-Apr-09',\n",
       " '27-Apr-09',\n",
       " '27-Apr-09',\n",
       " '27-Apr-09',\n",
       " '28-Apr-09',\n",
       " '28-Apr-09',\n",
       " '28-Apr-09',\n",
       " '28-Apr-09',\n",
       " '28-Apr-09',\n",
       " '28-Apr-09',\n",
       " '28-Apr-09',\n",
       " '28-Apr-09',\n",
       " '28-Apr-09',\n",
       " '29-Apr-09',\n",
       " '29-Apr-09',\n",
       " '29-Apr-09',\n",
       " '29-Apr-09',\n",
       " '29-Apr-09',\n",
       " '29-Apr-09',\n",
       " '30-Apr-09',\n",
       " '30-Apr-09',\n",
       " '30-Apr-09',\n",
       " '30-Apr-09',\n",
       " '1-May-09',\n",
       " '1-May-09',\n",
       " '1-May-09',\n",
       " '1-May-09',\n",
       " '1-May-09',\n",
       " '2-May-09',\n",
       " '2-May-09',\n",
       " '2-May-09',\n",
       " '2-May-09',\n",
       " '3-May-09',\n",
       " '3-May-09',\n",
       " '3-May-09',\n",
       " '4-May-09',\n",
       " '4-May-09',\n",
       " '4-May-09',\n",
       " '5-May-09',\n",
       " '5-May-09',\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = df['content'].tolist()\n",
    "dates = df['date'].tolist()  # Add date column\n",
    "texts\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted player data saved to p_output_3of3.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the dataset\n",
    "file_path = './output_3of3.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter rows where the processed_results length is greater than 30 characters\n",
    "filtered_data_30 = data[data['processed_results'].str.len() > 30]\n",
    "\n",
    "# Function to clean and parse JSON data\n",
    "def parse_player_data(entry):\n",
    "    try:\n",
    "        # Remove the enclosing backticks and `json` marker\n",
    "        cleaned_entry = entry.strip('```json').strip('```').strip()\n",
    "        \n",
    "        # Parse the JSON\n",
    "        json_data = json.loads(cleaned_entry)\n",
    "        \n",
    "        # Ensure it is a list of dictionaries\n",
    "        if isinstance(json_data, list):\n",
    "            return json_data\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return None\n",
    "\n",
    "# Apply the function to the filtered data\n",
    "parsed_data = filtered_data_30['processed_results'].apply(parse_player_data)\n",
    "\n",
    "# Flatten the parsed data and add date\n",
    "flattened_data = []\n",
    "for i, players in enumerate(parsed_data):\n",
    "    if players:\n",
    "        for player in players:\n",
    "            player['date'] = filtered_data_30.iloc[i]['date']\n",
    "            flattened_data.append(player)\n",
    "\n",
    "# Convert the flattened data to a DataFrame\n",
    "player_details_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Save the extracted player data to a CSV file\n",
    "output_file_path = 'p_output_3of3.csv'\n",
    "player_details_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Extracted player data saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('p_output_1of3.csv')\n",
    "df2 = pd.read_csv('p_output_2of3.csv')\n",
    "df3 = pd.read_csv('p_output_3of3.csv')\n",
    "data_ready = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "data_ready.to_csv('data_ready.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

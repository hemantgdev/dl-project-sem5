{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e4f14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "                                                 url  \\\n",
      "0  https://www.espncricinfo.com/story/bcci-launch...   \n",
      "1  https://www.espncricinfo.com/story/warne-joins...   \n",
      "2  https://www.espncricinfo.com/story/mcgrath-hop...   \n",
      "3  https://www.espncricinfo.com/story/will-twenty...   \n",
      "4  https://www.espncricinfo.com/story/jayawardene...   \n",
      "\n",
      "                                               title       date  \\\n",
      "0             International Twenty20 league launched  13-Sep-07   \n",
      "1  Warne joins player pool for Indian Twenty20 le...  16-Sep-07   \n",
      "2       McGrath hopes Twenty20 stays as third format  19-Sep-07   \n",
      "3                       Will Twenty20 wreck cricket?  23-Sep-07   \n",
      "4    Jayawardene among eight Sri Lankans to join IPL   1-Oct-07   \n",
      "\n",
      "                                             content Unnamed: 4 Unnamed: 5  \\\n",
      "0  Stephen Fleming and Glenn McGrath at the launc...        NaN        NaN   \n",
      "1  Shane Warne and Glenn McGrath could soon be pl...        NaN        NaN   \n",
      "2  Glenn McGrath has not played cricket since the...        NaN        NaN   \n",
      "3  The fans have lapped up international Twenty20...        NaN        NaN   \n",
      "4  Mahela Jayawardene is keen to be a part of the...        NaN        NaN   \n",
      "\n",
      "  Unnamed: 6  Unnamed: 7  Unnamed: 8 Unnamed: 9 Unnamed: 10 Unnamed: 11  \\\n",
      "0        NaN         NaN         NaN        NaN         NaN         NaN   \n",
      "1        NaN         NaN         NaN        NaN         NaN         NaN   \n",
      "2        NaN         NaN         NaN        NaN         NaN         NaN   \n",
      "3        NaN         NaN         NaN        NaN         NaN         NaN   \n",
      "4        NaN         NaN         NaN        NaN         NaN         NaN   \n",
      "\n",
      "  Unnamed: 12 Unnamed: 13 Unnamed: 14 Unnamed: 15 Unnamed: 16  \n",
      "0         NaN         NaN         NaN         NaN         NaN  \n",
      "1         NaN         NaN         NaN         NaN         NaN  \n",
      "2         NaN         NaN         NaN         NaN         NaN  \n",
      "3         NaN         NaN         NaN         NaN         NaN  \n",
      "4         NaN         NaN         NaN         NaN         NaN  \n",
      "\n",
      "Preprocessed Data:\n",
      "                                                 url  \\\n",
      "0  https://www.espncricinfo.com/story/bcci-launch...   \n",
      "1  https://www.espncricinfo.com/story/warne-joins...   \n",
      "2  https://www.espncricinfo.com/story/mcgrath-hop...   \n",
      "3  https://www.espncricinfo.com/story/will-twenty...   \n",
      "4  https://www.espncricinfo.com/story/jayawardene...   \n",
      "\n",
      "                                               title       date  \\\n",
      "0             International Twenty20 league launched 2007-09-13   \n",
      "1  Warne joins player pool for Indian Twenty20 le... 2007-09-16   \n",
      "2       McGrath hopes Twenty20 stays as third format 2007-09-19   \n",
      "3                       Will Twenty20 wreck cricket? 2007-09-23   \n",
      "4    Jayawardene among eight Sri Lankans to join IPL 2007-10-01   \n",
      "\n",
      "                                             content Unnamed: 4 Unnamed: 5  \\\n",
      "0  Stephen Fleming and Glenn McGrath at the launc...        NaN        NaN   \n",
      "1  Shane Warne and Glenn McGrath could soon be pl...        NaN        NaN   \n",
      "2  Glenn McGrath has not played cricket since the...        NaN        NaN   \n",
      "3  The fans have lapped up international Twenty20...        NaN        NaN   \n",
      "4  Mahela Jayawardene is keen to be a part of the...        NaN        NaN   \n",
      "\n",
      "  Unnamed: 6  Unnamed: 7  Unnamed: 8 Unnamed: 9 Unnamed: 10 Unnamed: 11  \\\n",
      "0        NaN         NaN         NaN        NaN         NaN         NaN   \n",
      "1        NaN         NaN         NaN        NaN         NaN         NaN   \n",
      "2        NaN         NaN         NaN        NaN         NaN         NaN   \n",
      "3        NaN         NaN         NaN        NaN         NaN         NaN   \n",
      "4        NaN         NaN         NaN        NaN         NaN         NaN   \n",
      "\n",
      "  Unnamed: 12 Unnamed: 13 Unnamed: 14 Unnamed: 15 Unnamed: 16  \n",
      "0         NaN         NaN         NaN         NaN         NaN  \n",
      "1         NaN         NaN         NaN         NaN         NaN  \n",
      "2         NaN         NaN         NaN         NaN         NaN  \n",
      "3         NaN         NaN         NaN         NaN         NaN  \n",
      "4         NaN         NaN         NaN         NaN         NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/3szy81ds4mx0klg4kp2z0hrm0000gn/T/ipykernel_46110/333222453.py:19: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['date'] = pd.to_datetime(df['date'], errors='coerce', dayfirst=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load and Preprocess the CSV File\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/hemantg/Desktop/dl-project-scraped-final.csv'  # Update this path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Original Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Preprocessing\n",
    "# Remove extra whitespace and newlines in text columns\n",
    "df['title'] = df['title'].str.strip().replace(r'\\s+', ' ', regex=True)\n",
    "df['content'] = df['content'].str.strip().replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# Standardize the date format\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# Drop rows with invalid dates\n",
    "df = df.dropna(subset=['date'])\n",
    "\n",
    "# Sort the DataFrame by date\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "# Display preprocessed data\n",
    "print(\"\\nPreprocessed Data:\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2686af45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (Cleaned):\n",
      "                                                 url  \\\n",
      "0  https://www.espncricinfo.com/story/bcci-launch...   \n",
      "1  https://www.espncricinfo.com/story/warne-joins...   \n",
      "2  https://www.espncricinfo.com/story/mcgrath-hop...   \n",
      "3  https://www.espncricinfo.com/story/will-twenty...   \n",
      "4  https://www.espncricinfo.com/story/jayawardene...   \n",
      "\n",
      "                                               title       date  \\\n",
      "0             International Twenty20 league launched  13-Sep-07   \n",
      "1  Warne joins player pool for Indian Twenty20 le...  16-Sep-07   \n",
      "2       McGrath hopes Twenty20 stays as third format  19-Sep-07   \n",
      "3                       Will Twenty20 wreck cricket?  23-Sep-07   \n",
      "4    Jayawardene among eight Sri Lankans to join IPL   1-Oct-07   \n",
      "\n",
      "                                             content  \n",
      "0  Stephen Fleming and Glenn McGrath at the launc...  \n",
      "1  Shane Warne and Glenn McGrath could soon be pl...  \n",
      "2  Glenn McGrath has not played cricket since the...  \n",
      "3  The fans have lapped up international Twenty20...  \n",
      "4  Mahela Jayawardene is keen to be a part of the...  \n",
      "\n",
      "Preprocessed Data:\n",
      "                                                 url  \\\n",
      "0  https://www.espncricinfo.com/story/bcci-launch...   \n",
      "1  https://www.espncricinfo.com/story/warne-joins...   \n",
      "2  https://www.espncricinfo.com/story/mcgrath-hop...   \n",
      "3  https://www.espncricinfo.com/story/will-twenty...   \n",
      "4  https://www.espncricinfo.com/story/jayawardene...   \n",
      "\n",
      "                                               title       date  \\\n",
      "0             International Twenty20 league launched 2007-09-13   \n",
      "1  Warne joins player pool for Indian Twenty20 le... 2007-09-16   \n",
      "2       McGrath hopes Twenty20 stays as third format 2007-09-19   \n",
      "3                       Will Twenty20 wreck cricket? 2007-09-23   \n",
      "4    Jayawardene among eight Sri Lankans to join IPL 2007-10-01   \n",
      "\n",
      "                                             content  \n",
      "0  Stephen Fleming and Glenn McGrath at the launc...  \n",
      "1  Shane Warne and Glenn McGrath could soon be pl...  \n",
      "2  Glenn McGrath has not played cricket since the...  \n",
      "3  The fans have lapped up international Twenty20...  \n",
      "4  Mahela Jayawardene is keen to be a part of the...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/3szy81ds4mx0klg4kp2z0hrm0000gn/T/ipykernel_46110/2686956157.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['date'] = pd.to_datetime(df['date'], errors='coerce', dayfirst=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load and Preprocess the CSV File\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/hemantg/Desktop/dl-project-scraped-final.csv'  # Update this path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove unnamed columns\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Original Data (Cleaned):\")\n",
    "print(df.head())\n",
    "\n",
    "# Preprocessing\n",
    "# Remove extra whitespace and newlines in text columns\n",
    "df['title'] = df['title'].str.strip().replace(r'\\s+', ' ', regex=True)\n",
    "df['content'] = df['content'].str.strip().replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# Standardize the date format\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# Drop rows with invalid dates\n",
    "df = df.dropna(subset=['date'])\n",
    "\n",
    "# Sort the DataFrame by date\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "# Display preprocessed data\n",
    "print(\"\\nPreprocessed Data:\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "722a4471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (Cleaned):\n",
      "                                                 url  \\\n",
      "0  https://www.espncricinfo.com/story/bcci-launch...   \n",
      "1  https://www.espncricinfo.com/story/warne-joins...   \n",
      "2  https://www.espncricinfo.com/story/mcgrath-hop...   \n",
      "3  https://www.espncricinfo.com/story/will-twenty...   \n",
      "4  https://www.espncricinfo.com/story/jayawardene...   \n",
      "\n",
      "                                               title       date  \\\n",
      "0             International Twenty20 league launched  13-Sep-07   \n",
      "1  Warne joins player pool for Indian Twenty20 le...  16-Sep-07   \n",
      "2       McGrath hopes Twenty20 stays as third format  19-Sep-07   \n",
      "3                       Will Twenty20 wreck cricket?  23-Sep-07   \n",
      "4    Jayawardene among eight Sri Lankans to join IPL   1-Oct-07   \n",
      "\n",
      "                                             content  \n",
      "0  Stephen Fleming and Glenn McGrath at the launc...  \n",
      "1  Shane Warne and Glenn McGrath could soon be pl...  \n",
      "2  Glenn McGrath has not played cricket since the...  \n",
      "3  The fans have lapped up international Twenty20...  \n",
      "4  Mahela Jayawardene is keen to be a part of the...  \n",
      "\n",
      "Preprocessed Data:\n",
      "                                                 url  \\\n",
      "0  https://www.espncricinfo.com/story/bcci-launch...   \n",
      "1  https://www.espncricinfo.com/story/warne-joins...   \n",
      "2  https://www.espncricinfo.com/story/mcgrath-hop...   \n",
      "3  https://www.espncricinfo.com/story/will-twenty...   \n",
      "4  https://www.espncricinfo.com/story/jayawardene...   \n",
      "\n",
      "                                               title       date  \\\n",
      "0             International Twenty20 league launched 2007-09-13   \n",
      "1  Warne joins player pool for Indian Twenty20 le... 2007-09-16   \n",
      "2       McGrath hopes Twenty20 stays as third format 2007-09-19   \n",
      "3                       Will Twenty20 wreck cricket? 2007-09-23   \n",
      "4    Jayawardene among eight Sri Lankans to join IPL 2007-10-01   \n",
      "\n",
      "                                             content  \n",
      "0  Stephen Fleming and Glenn McGrath at the launc...  \n",
      "1  Shane Warne and Glenn McGrath could soon be pl...  \n",
      "2  Glenn McGrath has not played cricket since the...  \n",
      "3  The fans have lapped up international Twenty20...  \n",
      "4  Mahela Jayawardene is keen to be a part of the...  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load and Preprocess the CSV File\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/hemantg/Desktop/dl-project-scraped-final.csv'  # Update this path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove unnamed columns\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Original Data (Cleaned):\")\n",
    "print(df.head())\n",
    "\n",
    "# Preprocessing\n",
    "# Remove extra whitespace and newlines in text columns\n",
    "df['title'] = df['title'].str.strip().replace(r'\\s+', ' ', regex=True)\n",
    "df['content'] = df['content'].str.strip().replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# Standardize the date format explicitly\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d-%b-%y', errors='coerce')\n",
    "\n",
    "# Drop rows with invalid dates\n",
    "df = df.dropna(subset=['date'])\n",
    "\n",
    "# Sort the DataFrame by date\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "# Display preprocessed data\n",
    "print(\"\\nPreprocessed Data:\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9ca92f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n",
      "Processed 0 articles...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m batch_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Apply Sentiment Analysis\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m batch_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_label\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_response\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m batch_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: pd\u001b[38;5;241m.\u001b[39mSeries(analyze_sentiment_grok(x, i))\n\u001b[1;32m     71\u001b[0m )\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Save Progress After Each Batch\u001b[39;00m\n\u001b[1;32m     74\u001b[0m batch_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/sentiment_analysis_batch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4529\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\u001b[38;5;28mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmap_infer(\n\u001b[1;32m   1077\u001b[0m             values,\n\u001b[1;32m   1078\u001b[0m             f,\n\u001b[1;32m   1079\u001b[0m             convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype,\n\u001b[1;32m   1080\u001b[0m         )\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[5], line 70\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     66\u001b[0m batch_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Apply Sentiment Analysis\u001b[39;00m\n\u001b[1;32m     69\u001b[0m batch_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_label\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_response\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m batch_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: pd\u001b[38;5;241m.\u001b[39mSeries(analyze_sentiment_grok(x, i))\n\u001b[1;32m     71\u001b[0m )\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Save Progress After Each Batch\u001b[39;00m\n\u001b[1;32m     74\u001b[0m batch_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/sentiment_analysis_batch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m, in \u001b[0;36manalyze_sentiment_grok\u001b[0;34m(text, index)\u001b[0m\n\u001b[1;32m     26\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(retries):\n\u001b[0;32m---> 28\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(API_URL, headers\u001b[38;5;241m=\u001b[39mheaders, json\u001b[38;5;241m=\u001b[39mpayload)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     31\u001b[0m         result \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, data\u001b[38;5;241m=\u001b[39mdata, json\u001b[38;5;241m=\u001b[39mjson, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    715\u001b[0m     conn,\n\u001b[1;32m    716\u001b[0m     method,\n\u001b[1;32m    717\u001b[0m     url,\n\u001b[1;32m    718\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    719\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    720\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    721\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    722\u001b[0m )\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    461\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m             six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 461\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1276\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1277\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Step 2: Sentiment Analysis Using Grok API\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Define the Grok API Key and Endpoint\n",
    "API_KEY = \"xai-s8uBO0ByYKXw3QQ48PRQnieUBYCAPQQFdICsVeyTWYfNRqkGyFbrqIpOMnAXQx7N3D2vm3kRMsTdHe0c\"\n",
    "API_URL = \"https://api.x.ai/v1/chat/completions\"\n",
    "\n",
    "# Function to Analyze Sentiment Using Grok API with Retry Logic\n",
    "def analyze_sentiment_grok(text, index):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"grok-beta\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a sentiment analysis assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Analyze the sentiment of the following text: {text}\"}\n",
    "        ],\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "\n",
    "    retries = 3\n",
    "    for attempt in range(retries):\n",
    "        response = requests.post(API_URL, headers=headers, json=payload)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            completion_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "            # Extract sentiment information\n",
    "            label = \"Neutral\"\n",
    "            score = 0.0\n",
    "\n",
    "            if \"Positive\" in completion_text:\n",
    "                label = \"Positive\"\n",
    "                score = 0.9\n",
    "            elif \"Negative\" in completion_text:\n",
    "                label = \"Negative\"\n",
    "                score = 0.1\n",
    "\n",
    "            # Print progress every 100 articles\n",
    "            if index % 100 == 0:\n",
    "                print(f\"Processed {index} articles...\")\n",
    "\n",
    "            return label, score, completion_text\n",
    "\n",
    "        elif response.status_code in [429, 500]:  # Retry on rate-limit or server error\n",
    "            print(f\"Rate limit or server error at index {index}. Retrying in 30 seconds...\")\n",
    "            time.sleep(30)\n",
    "        else:\n",
    "            print(f\"API Error at index {index}: {response.status_code}, {response.text}\")\n",
    "            return \"Neutral\", 0.0, \"Error in response\"\n",
    "\n",
    "    # If all retries fail\n",
    "    return \"Neutral\", 0.0, \"Max retries exceeded\"\n",
    "\n",
    "\n",
    "# **Save Progress Logic**\n",
    "batch_size = 500\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch_df = df.iloc[i:i+batch_size].copy()\n",
    "    \n",
    "    # Apply Sentiment Analysis\n",
    "    batch_df[['sentiment_label', 'sentiment_score', 'raw_response']] = batch_df['content'].apply(\n",
    "        lambda x: pd.Series(analyze_sentiment_grok(x, i))\n",
    "    )\n",
    "\n",
    "    # Save Progress After Each Batch\n",
    "    batch_df.to_csv(f'/kaggle/working/sentiment_analysis_batch_{i}.csv', index=False)\n",
    "    print(f\"Saved batch {i} to CSV.\")\n",
    "\n",
    "print(\"\\nSentiment Analysis Completed Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05edd768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed article 0: Sentiment=Positive, Score=0.9\n",
      "Processed article 1: Sentiment=Positive, Score=0.9\n",
      "Processed article 2: Sentiment=Positive, Score=0.9\n",
      "Processed article 3: Sentiment=Positive, Score=0.9\n",
      "Processed article 4: Sentiment=Neutral, Score=0.0\n",
      "Processed article 5: Sentiment=Positive, Score=0.9\n",
      "Processed article 6: Sentiment=Positive, Score=0.9\n",
      "Processed article 7: Sentiment=Positive, Score=0.9\n",
      "Processed article 8: Sentiment=Negative, Score=0.1\n",
      "Processed article 9: Sentiment=Neutral, Score=0.0\n",
      "Processed article 10: Sentiment=Positive, Score=0.9\n",
      "Processed article 11: Sentiment=Positive, Score=0.9\n",
      "Processed article 12: Sentiment=Positive, Score=0.9\n",
      "Processed article 13: Sentiment=Positive, Score=0.9\n",
      "Processed article 14: Sentiment=Positive, Score=0.9\n",
      "Processed article 15: Sentiment=Positive, Score=0.9\n",
      "Processed article 16: Sentiment=Neutral, Score=0.0\n",
      "Processed article 17: Sentiment=Positive, Score=0.9\n",
      "Processed article 18: Sentiment=Positive, Score=0.9\n",
      "Processed article 19: Sentiment=Positive, Score=0.9\n",
      "Processed article 20: Sentiment=Positive, Score=0.9\n",
      "Processed article 21: Sentiment=Positive, Score=0.9\n",
      "Processed article 22: Sentiment=Neutral, Score=0.0\n",
      "Processed article 23: Sentiment=Negative, Score=0.1\n",
      "Processed article 24: Sentiment=Positive, Score=0.9\n",
      "Processed article 25: Sentiment=Positive, Score=0.9\n",
      "Processed article 26: Sentiment=Neutral, Score=0.0\n",
      "Processed article 27: Sentiment=Positive, Score=0.9\n",
      "Processed article 28: Sentiment=Positive, Score=0.9\n",
      "Processed article 29: Sentiment=Positive, Score=0.9\n",
      "Processed article 30: Sentiment=Positive, Score=0.9\n",
      "Processed article 31: Sentiment=Negative, Score=0.1\n",
      "Processed article 32: Sentiment=Neutral, Score=0.0\n",
      "Processed article 33: Sentiment=Positive, Score=0.9\n",
      "Processed article 34: Sentiment=Negative, Score=0.1\n",
      "Processed article 35: Sentiment=Neutral, Score=0.0\n",
      "Processed article 36: Sentiment=Positive, Score=0.9\n",
      "Processed article 37: Sentiment=Positive, Score=0.9\n",
      "Processed article 38: Sentiment=Positive, Score=0.9\n",
      "Processed article 39: Sentiment=Positive, Score=0.9\n",
      "Processed article 40: Sentiment=Positive, Score=0.9\n",
      "Processed article 41: Sentiment=Neutral, Score=0.0\n",
      "Processed article 42: Sentiment=Positive, Score=0.9\n",
      "Processed article 43: Sentiment=Neutral, Score=0.0\n",
      "Processed article 44: Sentiment=Positive, Score=0.9\n",
      "Processed article 45: Sentiment=Neutral, Score=0.0\n",
      "Processed article 46: Sentiment=Neutral, Score=0.0\n",
      "Processed article 47: Sentiment=Positive, Score=0.9\n",
      "Processed article 48: Sentiment=Positive, Score=0.9\n",
      "Processed article 49: Sentiment=Neutral, Score=0.0\n",
      "Processed article 50: Sentiment=Positive, Score=0.9\n",
      "Processed article 51: Sentiment=Positive, Score=0.9\n",
      "Processed article 52: Sentiment=Positive, Score=0.9\n",
      "Processed article 53: Sentiment=Positive, Score=0.9\n",
      "Processed article 54: Sentiment=Positive, Score=0.9\n",
      "Processed article 55: Sentiment=Negative, Score=0.1\n",
      "Processed article 56: Sentiment=Positive, Score=0.9\n",
      "Processed article 57: Sentiment=Positive, Score=0.9\n",
      "Processed article 58: Sentiment=Negative, Score=0.1\n",
      "Processed article 59: Sentiment=Negative, Score=0.1\n",
      "Processed article 60: Sentiment=Neutral, Score=0.0\n",
      "Processed article 61: Sentiment=Negative, Score=0.1\n",
      "Processed article 62: Sentiment=Neutral, Score=0.0\n",
      "Processed article 63: Sentiment=Neutral, Score=0.0\n",
      "Processed article 64: Sentiment=Positive, Score=0.9\n",
      "Processed article 65: Sentiment=Positive, Score=0.9\n",
      "Processed article 66: Sentiment=Positive, Score=0.9\n",
      "Processed article 67: Sentiment=Positive, Score=0.9\n",
      "Processed article 68: Sentiment=Negative, Score=0.1\n",
      "Processed article 69: Sentiment=Positive, Score=0.9\n",
      "Processed article 70: Sentiment=Positive, Score=0.9\n",
      "Processed article 71: Sentiment=Neutral, Score=0.0\n",
      "Processed article 72: Sentiment=Positive, Score=0.9\n",
      "Processed article 73: Sentiment=Neutral, Score=0.0\n",
      "Processed article 74: Sentiment=Neutral, Score=0.0\n",
      "Processed article 75: Sentiment=Positive, Score=0.9\n",
      "Processed article 76: Sentiment=Neutral, Score=0.0\n",
      "Processed article 77: Sentiment=Positive, Score=0.9\n",
      "Processed article 78: Sentiment=Positive, Score=0.9\n",
      "Processed article 79: Sentiment=Positive, Score=0.9\n",
      "Processed article 80: Sentiment=Positive, Score=0.9\n",
      "Processed article 81: Sentiment=Positive, Score=0.9\n",
      "Processed article 82: Sentiment=Positive, Score=0.9\n",
      "Processed article 83: Sentiment=Positive, Score=0.9\n",
      "Processed article 84: Sentiment=Positive, Score=0.9\n",
      "Processed article 85: Sentiment=Positive, Score=0.9\n",
      "Processed article 86: Sentiment=Neutral, Score=0.0\n",
      "Processed article 87: Sentiment=Negative, Score=0.1\n",
      "Processed article 88: Sentiment=Positive, Score=0.9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m batch_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Apply Sentiment Analysis with Correct Index and Real-Time Output\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m batch_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_label\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_response\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m batch_df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: pd\u001b[38;5;241m.\u001b[39mSeries(analyze_sentiment_grok(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m], row\u001b[38;5;241m.\u001b[39mname)), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     70\u001b[0m )\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Save Progress After Each Batch\u001b[39;00m\n\u001b[1;32m     73\u001b[0m batch_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/hemantg/Desktop/sentiment_analysis_batch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9414\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   9415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9416\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9421\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   9422\u001b[0m )\n\u001b[0;32m-> 9423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(v)\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[6], line 69\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     65\u001b[0m batch_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Apply Sentiment Analysis with Correct Index and Real-Time Output\u001b[39;00m\n\u001b[1;32m     68\u001b[0m batch_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_label\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_response\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m batch_df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: pd\u001b[38;5;241m.\u001b[39mSeries(analyze_sentiment_grok(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m], row\u001b[38;5;241m.\u001b[39mname)), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     70\u001b[0m )\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Save Progress After Each Batch\u001b[39;00m\n\u001b[1;32m     73\u001b[0m batch_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/hemantg/Desktop/sentiment_analysis_batch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m, in \u001b[0;36manalyze_sentiment_grok\u001b[0;34m(text, row_index)\u001b[0m\n\u001b[1;32m     26\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(retries):\n\u001b[0;32m---> 28\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(API_URL, headers\u001b[38;5;241m=\u001b[39mheaders, json\u001b[38;5;241m=\u001b[39mpayload)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     31\u001b[0m         result \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, data\u001b[38;5;241m=\u001b[39mdata, json\u001b[38;5;241m=\u001b[39mjson, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    715\u001b[0m     conn,\n\u001b[1;32m    716\u001b[0m     method,\n\u001b[1;32m    717\u001b[0m     url,\n\u001b[1;32m    718\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    719\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    720\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    721\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    722\u001b[0m )\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    461\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m             six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 461\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1276\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1277\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Step 2: Sentiment Analysis Using Grok API\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Define the Grok API Key and Endpoint\n",
    "API_KEY = \"xai-s8uBO0ByYKXw3QQ48PRQnieUBYCAPQQFdICsVeyTWYfNRqkGyFbrqIpOMnAXQx7N3D2vm3kRMsTdHe0c\"\n",
    "API_URL = \"https://api.x.ai/v1/chat/completions\"\n",
    "\n",
    "# Function to Analyze Sentiment Using Grok API\n",
    "def analyze_sentiment_grok(text, row_index):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"grok-beta\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a sentiment analysis assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Analyze the sentiment of the following text: {text}\"}\n",
    "        ],\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "\n",
    "    retries = 3\n",
    "    for attempt in range(retries):\n",
    "        response = requests.post(API_URL, headers=headers, json=payload)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            completion_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "            # Extract sentiment information\n",
    "            label = \"Neutral\"\n",
    "            score = 0.0\n",
    "\n",
    "            if \"Positive\" in completion_text:\n",
    "                label = \"Positive\"\n",
    "                score = 0.9\n",
    "            elif \"Negative\" in completion_text:\n",
    "                label = \"Negative\"\n",
    "                score = 0.1\n",
    "\n",
    "            # Print progress for each article\n",
    "            print(f\"Processed article {row_index}: Sentiment={label}, Score={score}\")\n",
    "\n",
    "            return label, score, completion_text\n",
    "\n",
    "        elif response.status_code in [429, 500]:  # Retry on rate-limit or server error\n",
    "            print(f\"Rate limit or server error at index {row_index}. Retrying in 30 seconds...\")\n",
    "            time.sleep(30)\n",
    "        else:\n",
    "            print(f\"API Error at index {row_index}: {response.status_code}, {response.text}\")\n",
    "            return \"Neutral\", 0.0, \"Error in response\"\n",
    "\n",
    "    # If all retries fail\n",
    "    return \"Neutral\", 0.0, \"Max retries exceeded\"\n",
    "\n",
    "\n",
    "# **Save Progress Logic**\n",
    "batch_size = 500\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch_df = df.iloc[i:i+batch_size].copy()\n",
    "    \n",
    "    # Apply Sentiment Analysis with Correct Index and Real-Time Output\n",
    "    batch_df[['sentiment_label', 'sentiment_score', 'raw_response']] = batch_df.apply(\n",
    "        lambda row: pd.Series(analyze_sentiment_grok(row['content'], row.name)), axis=1\n",
    "    )\n",
    "\n",
    "    # Save Progress After Each Batch\n",
    "    batch_df.to_csv(f'/Users/hemantg/Desktop/sentiment_analysis_batch_{i}.csv', index=False)\n",
    "    print(f\"Saved batch {i} to CSV.\")\n",
    "\n",
    "print(\"\\nSentiment Analysis Completed Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "439cff4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed article 0: Extracted Contextual Features\n",
      "Processed article 1: Extracted Contextual Features\n",
      "Processed article 2: Extracted Contextual Features\n",
      "Processed article 3: Extracted Contextual Features\n",
      "Processed article 4: Extracted Contextual Features\n",
      "Processed article 5: Extracted Contextual Features\n",
      "Processed article 6: Extracted Contextual Features\n",
      "Processed article 7: Extracted Contextual Features\n",
      "Processed article 8: Extracted Contextual Features\n",
      "Processed article 9: Extracted Contextual Features\n",
      "Processed article 10: Extracted Contextual Features\n",
      "Processed article 11: Extracted Contextual Features\n",
      "Processed article 12: Extracted Contextual Features\n",
      "Processed article 13: Extracted Contextual Features\n",
      "Processed article 14: Extracted Contextual Features\n",
      "Processed article 15: Extracted Contextual Features\n",
      "Processed article 16: Extracted Contextual Features\n",
      "Processed article 17: Extracted Contextual Features\n",
      "Processed article 18: Extracted Contextual Features\n",
      "Processed article 19: Extracted Contextual Features\n",
      "Processed article 20: Extracted Contextual Features\n",
      "Processed article 21: Extracted Contextual Features\n",
      "Processed article 22: Extracted Contextual Features\n",
      "Processed article 23: Extracted Contextual Features\n",
      "Processed article 24: Extracted Contextual Features\n",
      "Processed article 25: Extracted Contextual Features\n",
      "Processed article 26: Extracted Contextual Features\n",
      "Processed article 27: Extracted Contextual Features\n",
      "Processed article 28: Extracted Contextual Features\n",
      "Processed article 29: Extracted Contextual Features\n",
      "Processed article 30: Extracted Contextual Features\n",
      "Processed article 31: Extracted Contextual Features\n",
      "Processed article 32: Extracted Contextual Features\n",
      "Processed article 33: Extracted Contextual Features\n",
      "Processed article 34: Extracted Contextual Features\n",
      "Processed article 35: Extracted Contextual Features\n",
      "Processed article 36: Extracted Contextual Features\n",
      "Processed article 37: Extracted Contextual Features\n",
      "Processed article 38: Extracted Contextual Features\n",
      "Processed article 39: Extracted Contextual Features\n",
      "Processed article 40: Extracted Contextual Features\n",
      "Processed article 41: Extracted Contextual Features\n",
      "Processed article 42: Extracted Contextual Features\n",
      "Processed article 43: Extracted Contextual Features\n",
      "Processed article 44: Extracted Contextual Features\n",
      "Processed article 45: Extracted Contextual Features\n",
      "Processed article 46: Extracted Contextual Features\n",
      "Processed article 47: Extracted Contextual Features\n",
      "Processed article 48: Extracted Contextual Features\n",
      "Processed article 49: Extracted Contextual Features\n",
      "Processed article 50: Extracted Contextual Features\n",
      "Processed article 51: Extracted Contextual Features\n",
      "Processed article 52: Extracted Contextual Features\n",
      "Processed article 53: Extracted Contextual Features\n",
      "Processed article 54: Extracted Contextual Features\n",
      "Processed article 55: Extracted Contextual Features\n",
      "Processed article 56: Extracted Contextual Features\n",
      "Processed article 57: Extracted Contextual Features\n",
      "Processed article 58: Extracted Contextual Features\n",
      "Processed article 59: Extracted Contextual Features\n",
      "Processed article 60: Extracted Contextual Features\n",
      "Processed article 61: Extracted Contextual Features\n",
      "Processed article 62: Extracted Contextual Features\n",
      "Processed article 63: Extracted Contextual Features\n",
      "Processed article 64: Extracted Contextual Features\n",
      "Processed article 65: Extracted Contextual Features\n",
      "Processed article 66: Extracted Contextual Features\n",
      "Processed article 67: Extracted Contextual Features\n",
      "Processed article 68: Extracted Contextual Features\n",
      "Processed article 69: Extracted Contextual Features\n",
      "Processed article 70: Extracted Contextual Features\n",
      "Processed article 71: Extracted Contextual Features\n",
      "Processed article 72: Extracted Contextual Features\n",
      "Processed article 73: Extracted Contextual Features\n",
      "Processed article 74: Extracted Contextual Features\n",
      "Processed article 75: Extracted Contextual Features\n",
      "Processed article 76: Extracted Contextual Features\n",
      "Processed article 77: Extracted Contextual Features\n",
      "Processed article 78: Extracted Contextual Features\n",
      "Processed article 79: Extracted Contextual Features\n",
      "Processed article 80: Extracted Contextual Features\n",
      "Processed article 81: Extracted Contextual Features\n",
      "Processed article 82: Extracted Contextual Features\n",
      "Processed article 83: Extracted Contextual Features\n",
      "Processed article 84: Extracted Contextual Features\n",
      "Processed article 85: Extracted Contextual Features\n",
      "Processed article 86: Extracted Contextual Features\n",
      "Processed article 87: Extracted Contextual Features\n",
      "Processed article 88: Extracted Contextual Features\n",
      "Processed article 89: Extracted Contextual Features\n",
      "Processed article 90: Extracted Contextual Features\n",
      "Processed article 91: Extracted Contextual Features\n",
      "Processed article 92: Extracted Contextual Features\n",
      "Processed article 93: Extracted Contextual Features\n",
      "Processed article 94: Extracted Contextual Features\n",
      "Processed article 95: Extracted Contextual Features\n",
      "Processed article 96: Extracted Contextual Features\n",
      "Processed article 97: Extracted Contextual Features\n",
      "Processed article 98: Extracted Contextual Features\n",
      "Processed article 99: Extracted Contextual Features\n",
      "Processed article 100: Extracted Contextual Features\n",
      "Processed article 101: Extracted Contextual Features\n",
      "Processed article 102: Extracted Contextual Features\n",
      "Processed article 103: Extracted Contextual Features\n",
      "Processed article 104: Extracted Contextual Features\n",
      "Processed article 105: Extracted Contextual Features\n",
      "Processed article 106: Extracted Contextual Features\n",
      "Processed article 107: Extracted Contextual Features\n",
      "Processed article 108: Extracted Contextual Features\n",
      "Processed article 109: Extracted Contextual Features\n",
      "Processed article 110: Extracted Contextual Features\n",
      "Processed article 111: Extracted Contextual Features\n",
      "Processed article 112: Extracted Contextual Features\n",
      "Processed article 113: Extracted Contextual Features\n",
      "Processed article 114: Extracted Contextual Features\n",
      "Processed article 115: Extracted Contextual Features\n",
      "Processed article 116: Extracted Contextual Features\n",
      "Processed article 117: Extracted Contextual Features\n",
      "Processed article 118: Extracted Contextual Features\n",
      "Processed article 119: Extracted Contextual Features\n",
      "Processed article 120: Extracted Contextual Features\n",
      "Processed article 121: Extracted Contextual Features\n",
      "Processed article 122: Extracted Contextual Features\n",
      "Processed article 123: Extracted Contextual Features\n",
      "Processed article 124: Extracted Contextual Features\n",
      "Processed article 125: Extracted Contextual Features\n",
      "Processed article 126: Extracted Contextual Features\n",
      "Processed article 127: Extracted Contextual Features\n",
      "Processed article 128: Extracted Contextual Features\n",
      "Processed article 129: Extracted Contextual Features\n",
      "Processed article 130: Extracted Contextual Features\n",
      "Processed article 131: Extracted Contextual Features\n",
      "Processed article 132: Extracted Contextual Features\n",
      "Processed article 133: Extracted Contextual Features\n",
      "Processed article 134: Extracted Contextual Features\n",
      "Processed article 135: Extracted Contextual Features\n",
      "Processed article 136: Extracted Contextual Features\n",
      "Processed article 137: Extracted Contextual Features\n",
      "Processed article 138: Extracted Contextual Features\n",
      "Processed article 139: Extracted Contextual Features\n",
      "Processed article 140: Extracted Contextual Features\n",
      "Processed article 141: Extracted Contextual Features\n",
      "Processed article 142: Extracted Contextual Features\n",
      "Processed article 143: Extracted Contextual Features\n",
      "Processed article 144: Extracted Contextual Features\n",
      "Processed article 145: Extracted Contextual Features\n",
      "Processed article 146: Extracted Contextual Features\n",
      "Processed article 147: Extracted Contextual Features\n",
      "Processed article 148: Extracted Contextual Features\n",
      "Processed article 149: Extracted Contextual Features\n",
      "Processed article 150: Extracted Contextual Features\n",
      "Processed article 151: Extracted Contextual Features\n",
      "Processed article 152: Extracted Contextual Features\n",
      "Processed article 153: Extracted Contextual Features\n",
      "Processed article 154: Extracted Contextual Features\n",
      "Processed article 155: Extracted Contextual Features\n",
      "Processed article 156: Extracted Contextual Features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed article 157: Extracted Contextual Features\n",
      "Processed article 158: Extracted Contextual Features\n",
      "Processed article 159: Extracted Contextual Features\n",
      "Processed article 160: Extracted Contextual Features\n",
      "Processed article 161: Extracted Contextual Features\n",
      "Processed article 162: Extracted Contextual Features\n",
      "Processed article 163: Extracted Contextual Features\n",
      "Processed article 164: Extracted Contextual Features\n",
      "Processed article 165: Extracted Contextual Features\n",
      "Processed article 166: Extracted Contextual Features\n",
      "Processed article 167: Extracted Contextual Features\n",
      "Processed article 168: Extracted Contextual Features\n",
      "Processed article 169: Extracted Contextual Features\n",
      "Processed article 170: Extracted Contextual Features\n",
      "Processed article 171: Extracted Contextual Features\n",
      "Processed article 172: Extracted Contextual Features\n",
      "Processed article 173: Extracted Contextual Features\n",
      "Processed article 174: Extracted Contextual Features\n",
      "Processed article 175: Extracted Contextual Features\n",
      "Processed article 176: Extracted Contextual Features\n",
      "Processed article 177: Extracted Contextual Features\n",
      "Processed article 178: Extracted Contextual Features\n",
      "Processed article 179: Extracted Contextual Features\n",
      "Processed article 180: Extracted Contextual Features\n",
      "Processed article 181: Extracted Contextual Features\n",
      "Processed article 182: Extracted Contextual Features\n",
      "Processed article 183: Extracted Contextual Features\n",
      "Processed article 184: Extracted Contextual Features\n",
      "Processed article 185: Extracted Contextual Features\n",
      "Processed article 186: Extracted Contextual Features\n",
      "Processed article 187: Extracted Contextual Features\n",
      "Processed article 188: Extracted Contextual Features\n",
      "Processed article 189: Extracted Contextual Features\n",
      "Processed article 190: Extracted Contextual Features\n",
      "Processed article 191: Extracted Contextual Features\n",
      "Processed article 192: Extracted Contextual Features\n",
      "Processed article 193: Extracted Contextual Features\n",
      "Processed article 194: Extracted Contextual Features\n",
      "Processed article 195: Extracted Contextual Features\n",
      "Processed article 196: Extracted Contextual Features\n",
      "Processed article 197: Extracted Contextual Features\n",
      "Processed article 198: Extracted Contextual Features\n",
      "Processed article 199: Extracted Contextual Features\n",
      "Processed article 200: Extracted Contextual Features\n",
      "Processed article 201: Extracted Contextual Features\n",
      "Processed article 202: Extracted Contextual Features\n",
      "Processed article 203: Extracted Contextual Features\n",
      "Processed article 204: Extracted Contextual Features\n",
      "Processed article 205: Extracted Contextual Features\n",
      "Processed article 206: Extracted Contextual Features\n",
      "Processed article 207: Extracted Contextual Features\n",
      "Processed article 208: Extracted Contextual Features\n",
      "Processed article 209: Extracted Contextual Features\n",
      "Processed article 210: Extracted Contextual Features\n",
      "Processed article 211: Extracted Contextual Features\n",
      "Processed article 212: Extracted Contextual Features\n",
      "Processed article 213: Extracted Contextual Features\n",
      "Processed article 214: Extracted Contextual Features\n",
      "Processed article 215: Extracted Contextual Features\n",
      "Processed article 216: Extracted Contextual Features\n",
      "Processed article 217: Extracted Contextual Features\n",
      "Processed article 218: Extracted Contextual Features\n",
      "Processed article 219: Extracted Contextual Features\n",
      "Processed article 220: Extracted Contextual Features\n",
      "Processed article 221: Extracted Contextual Features\n",
      "Processed article 222: Extracted Contextual Features\n",
      "Processed article 223: Extracted Contextual Features\n",
      "Processed article 224: Extracted Contextual Features\n",
      "Processed article 225: Extracted Contextual Features\n",
      "Processed article 226: Extracted Contextual Features\n",
      "Processed article 227: Extracted Contextual Features\n",
      "Processed article 228: Extracted Contextual Features\n",
      "Processed article 229: Extracted Contextual Features\n",
      "Processed article 230: Extracted Contextual Features\n",
      "Processed article 231: Extracted Contextual Features\n",
      "Processed article 232: Extracted Contextual Features\n",
      "Processed article 233: Extracted Contextual Features\n",
      "Processed article 234: Extracted Contextual Features\n",
      "Processed article 235: Extracted Contextual Features\n",
      "Processed article 236: Extracted Contextual Features\n",
      "Processed article 237: Extracted Contextual Features\n",
      "Processed article 238: Extracted Contextual Features\n",
      "Processed article 239: Extracted Contextual Features\n",
      "Processed article 240: Extracted Contextual Features\n",
      "Processed article 241: Extracted Contextual Features\n",
      "Processed article 242: Extracted Contextual Features\n",
      "Processed article 243: Extracted Contextual Features\n",
      "Processed article 244: Extracted Contextual Features\n",
      "Processed article 245: Extracted Contextual Features\n",
      "Processed article 246: Extracted Contextual Features\n",
      "Processed article 247: Extracted Contextual Features\n",
      "Processed article 248: Extracted Contextual Features\n",
      "Processed article 249: Extracted Contextual Features\n",
      "Processed article 250: Extracted Contextual Features\n",
      "Processed article 251: Extracted Contextual Features\n",
      "Processed article 252: Extracted Contextual Features\n",
      "Processed article 253: Extracted Contextual Features\n",
      "Processed article 254: Extracted Contextual Features\n",
      "Processed article 255: Extracted Contextual Features\n",
      "Processed article 256: Extracted Contextual Features\n",
      "Processed article 257: Extracted Contextual Features\n",
      "Processed article 258: Extracted Contextual Features\n",
      "Processed article 259: Extracted Contextual Features\n",
      "Processed article 260: Extracted Contextual Features\n",
      "Processed article 261: Extracted Contextual Features\n",
      "Processed article 262: Extracted Contextual Features\n",
      "Processed article 263: Extracted Contextual Features\n",
      "Processed article 264: Extracted Contextual Features\n",
      "Processed article 265: Extracted Contextual Features\n",
      "Processed article 266: Extracted Contextual Features\n",
      "Processed article 267: Extracted Contextual Features\n",
      "Processed article 268: Extracted Contextual Features\n",
      "Processed article 269: Extracted Contextual Features\n",
      "Processed article 270: Extracted Contextual Features\n",
      "Processed article 271: Extracted Contextual Features\n",
      "Processed article 272: Extracted Contextual Features\n",
      "Processed article 273: Extracted Contextual Features\n",
      "Processed article 274: Extracted Contextual Features\n",
      "Processed article 275: Extracted Contextual Features\n",
      "Processed article 276: Extracted Contextual Features\n",
      "Processed article 277: Extracted Contextual Features\n",
      "Processed article 278: Extracted Contextual Features\n",
      "Processed article 279: Extracted Contextual Features\n",
      "Processed article 280: Extracted Contextual Features\n",
      "Processed article 281: Extracted Contextual Features\n",
      "Processed article 282: Extracted Contextual Features\n",
      "Processed article 283: Extracted Contextual Features\n",
      "Processed article 284: Extracted Contextual Features\n",
      "Processed article 285: Extracted Contextual Features\n",
      "Processed article 286: Extracted Contextual Features\n",
      "Processed article 287: Extracted Contextual Features\n",
      "Processed article 288: Extracted Contextual Features\n",
      "Processed article 289: Extracted Contextual Features\n",
      "Processed article 290: Extracted Contextual Features\n",
      "Processed article 291: Extracted Contextual Features\n",
      "Processed article 292: Extracted Contextual Features\n",
      "Processed article 293: Extracted Contextual Features\n",
      "Processed article 294: Extracted Contextual Features\n",
      "Processed article 295: Extracted Contextual Features\n",
      "Processed article 296: Extracted Contextual Features\n",
      "Processed article 297: Extracted Contextual Features\n",
      "Processed article 298: Extracted Contextual Features\n",
      "Processed article 299: Extracted Contextual Features\n",
      "Processed article 300: Extracted Contextual Features\n",
      "Processed article 301: Extracted Contextual Features\n",
      "Processed article 302: Extracted Contextual Features\n",
      "Processed article 303: Extracted Contextual Features\n",
      "Processed article 304: Extracted Contextual Features\n",
      "Processed article 305: Extracted Contextual Features\n",
      "Processed article 306: Extracted Contextual Features\n",
      "Processed article 307: Extracted Contextual Features\n",
      "Processed article 308: Extracted Contextual Features\n",
      "Processed article 309: Extracted Contextual Features\n",
      "Processed article 310: Extracted Contextual Features\n",
      "Processed article 311: Extracted Contextual Features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed article 312: Extracted Contextual Features\n",
      "Processed article 313: Extracted Contextual Features\n",
      "Processed article 314: Extracted Contextual Features\n",
      "Processed article 315: Extracted Contextual Features\n",
      "Processed article 316: Extracted Contextual Features\n",
      "Processed article 317: Extracted Contextual Features\n",
      "Processed article 318: Extracted Contextual Features\n",
      "Processed article 319: Extracted Contextual Features\n",
      "Processed article 320: Extracted Contextual Features\n",
      "Processed article 321: Extracted Contextual Features\n",
      "Processed article 322: Extracted Contextual Features\n",
      "Processed article 323: Extracted Contextual Features\n",
      "Processed article 324: Extracted Contextual Features\n",
      "Processed article 325: Extracted Contextual Features\n",
      "Processed article 326: Extracted Contextual Features\n",
      "Processed article 327: Extracted Contextual Features\n",
      "Processed article 328: Extracted Contextual Features\n",
      "Processed article 329: Extracted Contextual Features\n",
      "Processed article 330: Extracted Contextual Features\n",
      "Processed article 331: Extracted Contextual Features\n",
      "Processed article 332: Extracted Contextual Features\n",
      "Processed article 333: Extracted Contextual Features\n",
      "Processed article 334: Extracted Contextual Features\n",
      "Processed article 335: Extracted Contextual Features\n",
      "Processed article 336: Extracted Contextual Features\n",
      "Processed article 337: Extracted Contextual Features\n",
      "Processed article 338: Extracted Contextual Features\n",
      "Processed article 339: Extracted Contextual Features\n",
      "Processed article 340: Extracted Contextual Features\n",
      "Processed article 341: Extracted Contextual Features\n",
      "Processed article 342: Extracted Contextual Features\n",
      "Processed article 343: Extracted Contextual Features\n",
      "Processed article 344: Extracted Contextual Features\n",
      "Processed article 345: Extracted Contextual Features\n",
      "Processed article 346: Extracted Contextual Features\n",
      "Processed article 347: Extracted Contextual Features\n",
      "Processed article 348: Extracted Contextual Features\n",
      "Processed article 349: Extracted Contextual Features\n",
      "Processed article 350: Extracted Contextual Features\n",
      "Processed article 351: Extracted Contextual Features\n",
      "Processed article 352: Extracted Contextual Features\n",
      "Processed article 353: Extracted Contextual Features\n",
      "Processed article 354: Extracted Contextual Features\n",
      "Processed article 355: Extracted Contextual Features\n",
      "Processed article 356: Extracted Contextual Features\n",
      "Processed article 357: Extracted Contextual Features\n",
      "Processed article 358: Extracted Contextual Features\n",
      "Processed article 359: Extracted Contextual Features\n",
      "Processed article 360: Extracted Contextual Features\n",
      "Processed article 361: Extracted Contextual Features\n",
      "Processed article 362: Extracted Contextual Features\n",
      "Processed article 363: Extracted Contextual Features\n",
      "Processed article 364: Extracted Contextual Features\n",
      "Processed article 365: Extracted Contextual Features\n",
      "Processed article 366: Extracted Contextual Features\n",
      "Processed article 367: Extracted Contextual Features\n",
      "Processed article 368: Extracted Contextual Features\n",
      "Processed article 369: Extracted Contextual Features\n",
      "Processed article 370: Extracted Contextual Features\n",
      "Processed article 371: Extracted Contextual Features\n",
      "Processed article 372: Extracted Contextual Features\n",
      "Processed article 373: Extracted Contextual Features\n",
      "Processed article 374: Extracted Contextual Features\n",
      "Processed article 375: Extracted Contextual Features\n",
      "Processed article 376: Extracted Contextual Features\n",
      "Processed article 377: Extracted Contextual Features\n",
      "Processed article 378: Extracted Contextual Features\n",
      "Processed article 379: Extracted Contextual Features\n",
      "Processed article 380: Extracted Contextual Features\n",
      "Processed article 381: Extracted Contextual Features\n",
      "Processed article 382: Extracted Contextual Features\n",
      "Processed article 383: Extracted Contextual Features\n",
      "Processed article 384: Extracted Contextual Features\n",
      "Processed article 385: Extracted Contextual Features\n",
      "Processed article 386: Extracted Contextual Features\n",
      "Processed article 387: Extracted Contextual Features\n",
      "Processed article 388: Extracted Contextual Features\n",
      "Processed article 389: Extracted Contextual Features\n",
      "Processed article 390: Extracted Contextual Features\n",
      "Processed article 391: Extracted Contextual Features\n",
      "Processed article 392: Extracted Contextual Features\n",
      "Processed article 393: Extracted Contextual Features\n",
      "Processed article 394: Extracted Contextual Features\n",
      "Processed article 395: Extracted Contextual Features\n",
      "Processed article 396: Extracted Contextual Features\n",
      "Processed article 397: Extracted Contextual Features\n",
      "Processed article 398: Extracted Contextual Features\n",
      "Processed article 399: Extracted Contextual Features\n",
      "Processed article 400: Extracted Contextual Features\n",
      "Processed article 401: Extracted Contextual Features\n",
      "Processed article 402: Extracted Contextual Features\n",
      "Processed article 403: Extracted Contextual Features\n",
      "Processed article 404: Extracted Contextual Features\n",
      "Processed article 405: Extracted Contextual Features\n",
      "Processed article 406: Extracted Contextual Features\n",
      "Processed article 407: Extracted Contextual Features\n",
      "Processed article 408: Extracted Contextual Features\n",
      "Processed article 409: Extracted Contextual Features\n",
      "Processed article 410: Extracted Contextual Features\n",
      "Processed article 411: Extracted Contextual Features\n",
      "Processed article 412: Extracted Contextual Features\n",
      "Processed article 413: Extracted Contextual Features\n",
      "Processed article 414: Extracted Contextual Features\n",
      "Processed article 415: Extracted Contextual Features\n",
      "Processed article 416: Extracted Contextual Features\n",
      "Processed article 417: Extracted Contextual Features\n",
      "Processed article 418: Extracted Contextual Features\n",
      "Processed article 419: Extracted Contextual Features\n",
      "Processed article 420: Extracted Contextual Features\n",
      "Processed article 421: Extracted Contextual Features\n",
      "Processed article 422: Extracted Contextual Features\n",
      "Processed article 423: Extracted Contextual Features\n",
      "Processed article 424: Extracted Contextual Features\n",
      "Processed article 425: Extracted Contextual Features\n",
      "Processed article 426: Extracted Contextual Features\n",
      "Processed article 427: Extracted Contextual Features\n",
      "Processed article 428: Extracted Contextual Features\n",
      "Processed article 429: Extracted Contextual Features\n",
      "Processed article 430: Extracted Contextual Features\n",
      "Processed article 431: Extracted Contextual Features\n",
      "Processed article 432: Extracted Contextual Features\n",
      "Processed article 433: Extracted Contextual Features\n",
      "Processed article 434: Extracted Contextual Features\n",
      "Processed article 435: Extracted Contextual Features\n",
      "Processed article 436: Extracted Contextual Features\n",
      "Processed article 437: Extracted Contextual Features\n",
      "Processed article 438: Extracted Contextual Features\n",
      "Processed article 439: Extracted Contextual Features\n",
      "Processed article 440: Extracted Contextual Features\n",
      "Processed article 441: Extracted Contextual Features\n",
      "Processed article 442: Extracted Contextual Features\n",
      "Processed article 443: Extracted Contextual Features\n",
      "Processed article 444: Extracted Contextual Features\n",
      "Processed article 445: Extracted Contextual Features\n",
      "Processed article 446: Extracted Contextual Features\n",
      "Processed article 447: Extracted Contextual Features\n",
      "Processed article 448: Extracted Contextual Features\n",
      "Processed article 449: Extracted Contextual Features\n",
      "Processed article 450: Extracted Contextual Features\n",
      "Processed article 451: Extracted Contextual Features\n",
      "Processed article 452: Extracted Contextual Features\n",
      "Processed article 453: Extracted Contextual Features\n",
      "Processed article 454: Extracted Contextual Features\n",
      "Processed article 455: Extracted Contextual Features\n",
      "Processed article 456: Extracted Contextual Features\n",
      "Processed article 457: Extracted Contextual Features\n",
      "Processed article 458: Extracted Contextual Features\n",
      "Processed article 459: Extracted Contextual Features\n",
      "Processed article 460: Extracted Contextual Features\n",
      "Processed article 461: Extracted Contextual Features\n",
      "Processed article 462: Extracted Contextual Features\n",
      "Processed article 463: Extracted Contextual Features\n",
      "Processed article 464: Extracted Contextual Features\n",
      "Processed article 465: Extracted Contextual Features\n",
      "Processed article 466: Extracted Contextual Features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed article 467: Extracted Contextual Features\n",
      "Processed article 468: Extracted Contextual Features\n",
      "Processed article 469: Extracted Contextual Features\n",
      "Processed article 470: Extracted Contextual Features\n",
      "Processed article 471: Extracted Contextual Features\n",
      "Processed article 472: Extracted Contextual Features\n",
      "Processed article 473: Extracted Contextual Features\n",
      "Processed article 474: Extracted Contextual Features\n",
      "Processed article 475: Extracted Contextual Features\n",
      "Processed article 476: Extracted Contextual Features\n",
      "Processed article 477: Extracted Contextual Features\n",
      "Processed article 478: Extracted Contextual Features\n",
      "Processed article 479: Extracted Contextual Features\n",
      "Processed article 480: Extracted Contextual Features\n",
      "Processed article 481: Extracted Contextual Features\n",
      "Processed article 482: Extracted Contextual Features\n",
      "Processed article 483: Extracted Contextual Features\n",
      "Processed article 484: Extracted Contextual Features\n",
      "Processed article 485: Extracted Contextual Features\n",
      "Processed article 486: Extracted Contextual Features\n",
      "Processed article 487: Extracted Contextual Features\n",
      "Processed article 488: Extracted Contextual Features\n",
      "Processed article 489: Extracted Contextual Features\n",
      "Processed article 490: Extracted Contextual Features\n",
      "Processed article 491: Extracted Contextual Features\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='api.x.ai', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x152c50110>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[1;32m    175\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/util/connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m six\u001b[38;5;241m.\u001b[39mraise_from(\n\u001b[1;32m     69\u001b[0m         LocationParseError(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m host), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     )\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgetaddrinfo(host, port, family, socket\u001b[38;5;241m.\u001b[39mSOCK_STREAM):\n\u001b[1;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/socket.py:962\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    961\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 962\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m _socket\u001b[38;5;241m.\u001b[39mgetaddrinfo(host, port, family, \u001b[38;5;28mtype\u001b[39m, proto, flags):\n\u001b[1;32m    963\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    715\u001b[0m     conn,\n\u001b[1;32m    716\u001b[0m     method,\n\u001b[1;32m    717\u001b[0m     url,\n\u001b[1;32m    718\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    719\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    720\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    721\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    722\u001b[0m )\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:403\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_conn(conn)\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:1053\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1053\u001b[0m     conn\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connection.py:363\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[1;32m    364\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x152c50110>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:798\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    796\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 798\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[1;32m    799\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39me, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    800\u001b[0m )\n\u001b[1;32m    801\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/util/retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.x.ai', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x152c50110>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m batch_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Extract Contextual Features from Each Article\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m batch_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_features\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m batch_df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: extract_dynamic_context_grok(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m], row\u001b[38;5;241m.\u001b[39mname), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     68\u001b[0m )\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Ensure Sorting by Date\u001b[39;00m\n\u001b[1;32m     71\u001b[0m batch_df \u001b[38;5;241m=\u001b[39m batch_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9414\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   9415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9416\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9421\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   9422\u001b[0m )\n\u001b[0;32m-> 9423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(v)\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[7], line 67\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     63\u001b[0m batch_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Extract Contextual Features from Each Article\u001b[39;00m\n\u001b[1;32m     66\u001b[0m batch_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_features\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m batch_df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: extract_dynamic_context_grok(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m], row\u001b[38;5;241m.\u001b[39mname), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     68\u001b[0m )\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Ensure Sorting by Date\u001b[39;00m\n\u001b[1;32m     71\u001b[0m batch_df \u001b[38;5;241m=\u001b[39m batch_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[7], line 42\u001b[0m, in \u001b[0;36mextract_dynamic_context_grok\u001b[0;34m(text, row_index)\u001b[0m\n\u001b[1;32m     40\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(retries):\n\u001b[0;32m---> 42\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(API_URL, headers\u001b[38;5;241m=\u001b[39mheaders, json\u001b[38;5;241m=\u001b[39mpayload)\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     45\u001b[0m         result \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, data\u001b[38;5;241m=\u001b[39mdata, json\u001b[38;5;241m=\u001b[39mjson, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    516\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api.x.ai', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x152c50110>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))"
     ]
    }
   ],
   "source": [
    "# Function to Extract Contextual and Context-Discovered Features Using Grok\n",
    "def extract_dynamic_context_grok(text, row_index):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    # New Prompt for Feature Discovery\n",
    "    prompt = f\"\"\"\n",
    "    You are a cricket performance analyst. Extract features from this cricket article related to predicting a player's future performance.\n",
    "\n",
    "    1. Extract the following features:\n",
    "       - Player Mentioned\n",
    "       - Runs Scored (if any)\n",
    "       - Wickets Taken (if any)\n",
    "       - Match Context (location, opponent)\n",
    "       - Mention of Injuries or Selection Updates\n",
    "       - Predicted Player Confidence Level (0 to 1)\n",
    "       - Reason for Praise or Criticism (short text)\n",
    "\n",
    "    2. Additionally, look for **context-specific features** related to predicting the player's future performance:\n",
    "       - Emerging performance indicators (e.g., tactical mentions, team dynamics).\n",
    "       - Strategy hints (e.g., promotion in batting order, bowling changes).\n",
    "       - Important insights **not listed above**.\n",
    "\n",
    "    3. Provide a **short justification** explaining why these features were selected.\n",
    "\n",
    "    Article: {text}\n",
    "    \"\"\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"grok-beta\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a cricket performance analyst.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "\n",
    "    retries = 3\n",
    "    for attempt in range(retries):\n",
    "        response = requests.post(API_URL, headers=headers, json=payload)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            completion_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "            print(f\"Processed article {row_index}: Extracted Contextual Features\")\n",
    "            return completion_text\n",
    "\n",
    "        elif response.status_code in [429, 500]:  # Retry on rate-limit or server error\n",
    "            print(f\"Rate limit or server error at index {row_index}. Retrying in 30 seconds...\")\n",
    "            time.sleep(30)\n",
    "        else:\n",
    "            print(f\"API Error at index {row_index}: {response.status_code}, {response.text}\")\n",
    "            return \"Error in response\"\n",
    "\n",
    "    return \"Max retries exceeded\"\n",
    "\n",
    "# Batch Processing with Date Sorting\n",
    "batch_size = 500\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch_df = df.iloc[i:i+batch_size].copy()\n",
    "\n",
    "    # Extract Contextual Features from Each Article\n",
    "    batch_df['dynamic_features'] = batch_df.apply(\n",
    "        lambda row: extract_dynamic_context_grok(row['content'], row.name), axis=1\n",
    "    )\n",
    "\n",
    "    # Ensure Sorting by Date\n",
    "    batch_df = batch_df.sort_values(by='date', ascending=True)\n",
    "\n",
    "    # Save Progress After Each Batch\n",
    "    batch_df.to_csv(f'/Users/hemantg/Desktop/sentiment_analysis_batch_{i}.csv', index=False)\n",
    "    print(f\"Saved batch {i} with dynamic context features to CSV (sorted by date).\")\n",
    "\n",
    "print(\"\\nDynamic Contextual Feature Extraction and Date Sorting Completed Successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "                                                 url  \\\n",
      "0  https://www.espncricinfo.com/story/bcci-launch...   \n",
      "1  https://www.espncricinfo.com/story/warne-joins...   \n",
      "2  https://www.espncricinfo.com/story/mcgrath-hop...   \n",
      "3  https://www.espncricinfo.com/story/will-twenty...   \n",
      "4  https://www.espncricinfo.com/story/jayawardene...   \n",
      "\n",
      "                                               title       date  \\\n",
      "0             International Twenty20 league launched  13-Sep-07   \n",
      "1  Warne joins player pool for Indian Twenty20 le...  16-Sep-07   \n",
      "2       McGrath hopes Twenty20 stays as third format  19-Sep-07   \n",
      "3                       Will Twenty20 wreck cricket?  23-Sep-07   \n",
      "4    Jayawardene among eight Sri Lankans to join IPL   1-Oct-07   \n",
      "\n",
      "                                             content Unnamed: 4 Unnamed: 5  \\\n",
      "0  Stephen Fleming and Glenn McGrath at the launc...        NaN        NaN   \n",
      "1  Shane Warne and Glenn McGrath could soon be pl...        NaN        NaN   \n",
      "2  Glenn McGrath has not played cricket since the...        NaN        NaN   \n",
      "3  The fans have lapped up international Twenty20...        NaN        NaN   \n",
      "4  Mahela Jayawardene is keen to be a part of the...        NaN        NaN   \n",
      "\n",
      "  Unnamed: 6  Unnamed: 7  Unnamed: 8 Unnamed: 9 Unnamed: 10 Unnamed: 11  \\\n",
      "0        NaN         NaN         NaN        NaN         NaN         NaN   \n",
      "1        NaN         NaN         NaN        NaN         NaN         NaN   \n",
      "2        NaN         NaN         NaN        NaN         NaN         NaN   \n",
      "3        NaN         NaN         NaN        NaN         NaN         NaN   \n",
      "4        NaN         NaN         NaN        NaN         NaN         NaN   \n",
      "\n",
      "  Unnamed: 12 Unnamed: 13 Unnamed: 14 Unnamed: 15 Unnamed: 16  \n",
      "0         NaN         NaN         NaN         NaN         NaN  \n",
      "1         NaN         NaN         NaN         NaN         NaN  \n",
      "2         NaN         NaN         NaN         NaN         NaN  \n",
      "3         NaN         NaN         NaN         NaN         NaN  \n",
      "4         NaN         NaN         NaN         NaN         NaN  \n",
      "\n",
      "Preprocessed Data:\n",
      "                                                 url  \\\n",
      "0  https://www.espncricinfo.com/story/bcci-launch...   \n",
      "1  https://www.espncricinfo.com/story/warne-joins...   \n",
      "2  https://www.espncricinfo.com/story/mcgrath-hop...   \n",
      "3  https://www.espncricinfo.com/story/will-twenty...   \n",
      "4  https://www.espncricinfo.com/story/jayawardene...   \n",
      "\n",
      "                                               title       date  \\\n",
      "0             International Twenty20 league launched 2007-09-13   \n",
      "1  Warne joins player pool for Indian Twenty20 le... 2007-09-16   \n",
      "2       McGrath hopes Twenty20 stays as third format 2007-09-19   \n",
      "3                       Will Twenty20 wreck cricket? 2007-09-23   \n",
      "4    Jayawardene among eight Sri Lankans to join IPL 2007-10-01   \n",
      "\n",
      "                                             content Unnamed: 4 Unnamed: 5  \\\n",
      "0  Stephen Fleming and Glenn McGrath at the launc...        NaN        NaN   \n",
      "1  Shane Warne and Glenn McGrath could soon be pl...        NaN        NaN   \n",
      "2  Glenn McGrath has not played cricket since the...        NaN        NaN   \n",
      "3  The fans have lapped up international Twenty20...        NaN        NaN   \n",
      "4  Mahela Jayawardene is keen to be a part of the...        NaN        NaN   \n",
      "\n",
      "  Unnamed: 6  Unnamed: 7  Unnamed: 8 Unnamed: 9 Unnamed: 10 Unnamed: 11  \\\n",
      "0        NaN         NaN         NaN        NaN         NaN         NaN   \n",
      "1        NaN         NaN         NaN        NaN         NaN         NaN   \n",
      "2        NaN         NaN         NaN        NaN         NaN         NaN   \n",
      "3        NaN         NaN         NaN        NaN         NaN         NaN   \n",
      "4        NaN         NaN         NaN        NaN         NaN         NaN   \n",
      "\n",
      "  Unnamed: 12 Unnamed: 13 Unnamed: 14 Unnamed: 15 Unnamed: 16  \n",
      "0         NaN         NaN         NaN         NaN         NaN  \n",
      "1         NaN         NaN         NaN         NaN         NaN  \n",
      "2         NaN         NaN         NaN         NaN         NaN  \n",
      "3         NaN         NaN         NaN         NaN         NaN  \n",
      "4         NaN         NaN         NaN         NaN         NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/3szy81ds4mx0klg4kp2z0hrm0000gn/T/ipykernel_31000/3491398415.py:19: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['date'] = pd.to_datetime(df['date'], errors='coerce', dayfirst=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load and Preprocess the CSV File\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/hemantg/Desktop/d-project-scraped-final.csv'  # Update this path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Original Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Preprocessing\n",
    "# Remove extra whitespace and newlines in text columns\n",
    "df['title'] = df['title'].str.strip().replace(r'\\s+', ' ', regex=True)\n",
    "df['content'] = df['content'].str.strip().replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# Standardize the date format\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# Drop rows with invalid dates\n",
    "df = df.dropna(subset=['date'])\n",
    "\n",
    "# Sort the DataFrame by date\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "# Display preprocessed data\n",
    "print(\"\\nPreprocessed Data:\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (Cleaned):\n",
      "                                                 url  \\\n",
      "0  https://www.espncricinfo.com/story/bcci-launch...   \n",
      "1  https://www.espncricinfo.com/story/warne-joins...   \n",
      "2  https://www.espncricinfo.com/story/mcgrath-hop...   \n",
      "3  https://www.espncricinfo.com/story/will-twenty...   \n",
      "4  https://www.espncricinfo.com/story/jayawardene...   \n",
      "\n",
      "                                               title       date  \\\n",
      "0             International Twenty20 league launched  13-Sep-07   \n",
      "1  Warne joins player pool for Indian Twenty20 le...  16-Sep-07   \n",
      "2       McGrath hopes Twenty20 stays as third format  19-Sep-07   \n",
      "3                       Will Twenty20 wreck cricket?  23-Sep-07   \n",
      "4    Jayawardene among eight Sri Lankans to join IPL   1-Oct-07   \n",
      "\n",
      "                                             content  \n",
      "0  Stephen Fleming and Glenn McGrath at the launc...  \n",
      "1  Shane Warne and Glenn McGrath could soon be pl...  \n",
      "2  Glenn McGrath has not played cricket since the...  \n",
      "3  The fans have lapped up international Twenty20...  \n",
      "4  Mahela Jayawardene is keen to be a part of the...  \n",
      "\n",
      "Preprocessed Data:\n",
      "                                                 url  \\\n",
      "0  https://www.espncricinfo.com/story/bcci-launch...   \n",
      "1  https://www.espncricinfo.com/story/warne-joins...   \n",
      "2  https://www.espncricinfo.com/story/mcgrath-hop...   \n",
      "3  https://www.espncricinfo.com/story/will-twenty...   \n",
      "4  https://www.espncricinfo.com/story/jayawardene...   \n",
      "\n",
      "                                               title       date  \\\n",
      "0             International Twenty20 league launched 2007-09-13   \n",
      "1  Warne joins player pool for Indian Twenty20 le... 2007-09-16   \n",
      "2       McGrath hopes Twenty20 stays as third format 2007-09-19   \n",
      "3                       Will Twenty20 wreck cricket? 2007-09-23   \n",
      "4    Jayawardene among eight Sri Lankans to join IPL 2007-10-01   \n",
      "\n",
      "                                             content  \n",
      "0  Stephen Fleming and Glenn McGrath at the launc...  \n",
      "1  Shane Warne and Glenn McGrath could soon be pl...  \n",
      "2  Glenn McGrath has not played cricket since the...  \n",
      "3  The fans have lapped up international Twenty20...  \n",
      "4  Mahela Jayawardene is keen to be a part of the...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/3szy81ds4mx0klg4kp2z0hrm0000gn/T/ipykernel_31000/3453122476.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['date'] = pd.to_datetime(df['date'], errors='coerce', dayfirst=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load and Preprocess the CSV File\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/hemantg/Desktop/d-project-scraped-final.csv'  # Update this path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove unnamed columns\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Original Data (Cleaned):\")\n",
    "print(df.head())\n",
    "\n",
    "# Preprocessing\n",
    "# Remove extra whitespace and newlines in text columns\n",
    "df['title'] = df['title'].str.strip().replace(r'\\s+', ' ', regex=True)\n",
    "df['content'] = df['content'].str.strip().replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# Standardize the date format\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# Drop rows with invalid dates\n",
    "df = df.dropna(subset=['date'])\n",
    "\n",
    "# Sort the DataFrame by date\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "# Display preprocessed data\n",
    "print(\"\\nPreprocessed Data:\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (Cleaned):\n",
      "                                                 url  \\\n",
      "0  https://www.espncricinfo.com/story/bcci-launch...   \n",
      "1  https://www.espncricinfo.com/story/warne-joins...   \n",
      "2  https://www.espncricinfo.com/story/mcgrath-hop...   \n",
      "3  https://www.espncricinfo.com/story/will-twenty...   \n",
      "4  https://www.espncricinfo.com/story/jayawardene...   \n",
      "\n",
      "                                               title       date  \\\n",
      "0             International Twenty20 league launched  13-Sep-07   \n",
      "1  Warne joins player pool for Indian Twenty20 le...  16-Sep-07   \n",
      "2       McGrath hopes Twenty20 stays as third format  19-Sep-07   \n",
      "3                       Will Twenty20 wreck cricket?  23-Sep-07   \n",
      "4    Jayawardene among eight Sri Lankans to join IPL   1-Oct-07   \n",
      "\n",
      "                                             content  \n",
      "0  Stephen Fleming and Glenn McGrath at the launc...  \n",
      "1  Shane Warne and Glenn McGrath could soon be pl...  \n",
      "2  Glenn McGrath has not played cricket since the...  \n",
      "3  The fans have lapped up international Twenty20...  \n",
      "4  Mahela Jayawardene is keen to be a part of the...  \n",
      "\n",
      "Preprocessed Data:\n",
      "                                                 url  \\\n",
      "0  https://www.espncricinfo.com/story/bcci-launch...   \n",
      "1  https://www.espncricinfo.com/story/warne-joins...   \n",
      "2  https://www.espncricinfo.com/story/mcgrath-hop...   \n",
      "3  https://www.espncricinfo.com/story/will-twenty...   \n",
      "4  https://www.espncricinfo.com/story/jayawardene...   \n",
      "\n",
      "                                               title       date  \\\n",
      "0             International Twenty20 league launched 2007-09-13   \n",
      "1  Warne joins player pool for Indian Twenty20 le... 2007-09-16   \n",
      "2       McGrath hopes Twenty20 stays as third format 2007-09-19   \n",
      "3                       Will Twenty20 wreck cricket? 2007-09-23   \n",
      "4    Jayawardene among eight Sri Lankans to join IPL 2007-10-01   \n",
      "\n",
      "                                             content  \n",
      "0  Stephen Fleming and Glenn McGrath at the launc...  \n",
      "1  Shane Warne and Glenn McGrath could soon be pl...  \n",
      "2  Glenn McGrath has not played cricket since the...  \n",
      "3  The fans have lapped up international Twenty20...  \n",
      "4  Mahela Jayawardene is keen to be a part of the...  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load and Preprocess the CSV File\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/hemantg/Desktop/dl-project-scraped-final.csv'  # Update this path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove unnamed columns\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Original Data (Cleaned):\")\n",
    "print(df.head())\n",
    "\n",
    "# Preprocessing\n",
    "# Remove extra whitespace and newlines in text columns\n",
    "df['title'] = df['title'].str.strip().replace(r'\\s+', ' ', regex=True)\n",
    "df['content'] = df['content'].str.strip().replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# Standardize the date format explicitly\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d-%b-%y', errors='coerce')\n",
    "\n",
    "# Drop rows with invalid dates\n",
    "df = df.dropna(subset=['date'])\n",
    "\n",
    "# Sort the DataFrame by date\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "# Display preprocessed data\n",
    "print(\"\\nPreprocessed Data:\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Error: 520, <!DOCTYPE html>\n",
      "<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 8]>    <html class=\"no-js ie8 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if gt IE 8]><!--> <html class=\"no-js\" lang=\"en-US\"> <!--<![endif]-->\n",
      "<head>\n",
      "\n",
      "\n",
      "<title>api.x.ai | 520: Web server is returning an unknown error</title>\n",
      "<meta charset=\"UTF-8\" />\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n",
      "<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\n",
      "<meta name=\"robots\" content=\"noindex, nofollow\" />\n",
      "<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n",
      "<link rel=\"stylesheet\" id=\"cf_styles-css\" href=\"/cdn-cgi/styles/main.css\" />\n",
      "\n",
      "\n",
      "</head>\n",
      "<body>\n",
      "<div id=\"cf-wrapper\">\n",
      "    <div id=\"cf-error-details\" class=\"p-0\">\n",
      "        <header class=\"mx-auto pt-10 lg:pt-6 lg:px-8 w-240 lg:w-full mb-8\">\n",
      "            <h1 class=\"inline-block sm:block sm:mb-2 font-light text-60 lg:text-4xl text-black-dark leading-tight mr-2\">\n",
      "              <span class=\"inline-block\">Web server is returning an unknown error</span>\n",
      "              <span class=\"code-label\">Error code 520</span>\n",
      "            </h1>\n",
      "            <div>\n",
      "               Visit <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_520&utm_campaign=api.x.ai\" target=\"_blank\" rel=\"noopener noreferrer\">cloudflare.com</a> for more information.\n",
      "            </div>\n",
      "            <div class=\"mt-3\">2024-12-09 13:45:33 UTC</div>\n",
      "        </header>\n",
      "        <div class=\"my-8 bg-gradient-gray\">\n",
      "            <div class=\"w-240 lg:w-full mx-auto\">\n",
      "                <div class=\"clearfix md:px-8\">\n",
      "                  \n",
      "<div id=\"cf-browser-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-browser block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">You</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    \n",
      "    Browser\n",
      "    \n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "</div>\n",
      "\n",
      "<div id=\"cf-cloudflare-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_520&utm_campaign=api.x.ai\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    <span class=\"cf-icon-cloud block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    </a>\n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">New Delhi</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_520&utm_campaign=api.x.ai\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    Cloudflare\n",
      "    </a>\n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "</div>\n",
      "\n",
      "<div id=\"cf-host-status\" class=\"cf-error-source relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-server block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-error w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">api.x.ai</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    \n",
      "    Host\n",
      "    \n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-red-error\">Error</span>\n",
      "</div>\n",
      "\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"w-240 lg:w-full mx-auto mb-8 lg:px-8\">\n",
      "            <div class=\"clearfix\">\n",
      "                <div class=\"w-1/2 md:w-full float-left pr-6 md:pb-10 md:pr-0 leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What happened?</h2>\n",
      "                    <p>There is an unknown connection issue between Cloudflare and the origin web server. As a result, the web page can not be displayed.</p>\n",
      "                </div>\n",
      "                <div class=\"w-1/2 md:w-full float-left leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What can I do?</h2>\n",
      "                          <h3 class=\"text-15 font-semibold mb-2\">If you are a visitor of this website:</h3>\n",
      "      <p class=\"mb-6\">Please try again in a few minutes.</p>\n",
      "\n",
      "      <h3 class=\"text-15 font-semibold mb-2\">If you are the owner of this website:</h3>\n",
      "      <p><span>There is an issue between Cloudflare's cache and your origin web server. Cloudflare monitors for these errors and automatically investigates the cause. To help support the investigation, you can pull the corresponding error log from your web server and submit it our support team.  Please include the Ray ID (which is at the bottom of this error page).</span> <a rel=\"noopener noreferrer\" href=\"https://support.cloudflare.com/hc/en-us/articles/200171936-Error-520\">Additional troubleshooting resources</a>.</p>\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"cf-error-footer cf-wrapper w-240 lg:w-full py-10 sm:py-4 sm:px-8 mx-auto text-center sm:text-left border-solid border-0 border-t border-gray-300\">\n",
      "  <p class=\"text-13\">\n",
      "    <span class=\"cf-footer-item sm:block sm:mb-1\">Cloudflare Ray ID: <strong class=\"font-semibold\">8ef56fae7a8f59ac</strong></span>\n",
      "    <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "    <span id=\"cf-footer-item-ip\" class=\"cf-footer-item hidden sm:block sm:mb-1\">\n",
      "      Your IP:\n",
      "      <button type=\"button\" id=\"cf-footer-ip-reveal\" class=\"cf-footer-ip-reveal-btn\">Click to reveal</button>\n",
      "      <span class=\"hidden\" id=\"cf-footer-ip\">202.164.41.66</span>\n",
      "      <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "    </span>\n",
      "    <span class=\"cf-footer-item sm:block sm:mb-1\"><span>Performance &amp; security by</span> <a rel=\"noopener noreferrer\" href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_520&utm_campaign=api.x.ai\" id=\"brand_link\" target=\"_blank\">Cloudflare</a></span>\n",
      "    \n",
      "  </p>\n",
      "  <script>(function(){function d(){var b=a.getElementById(\"cf-footer-item-ip\"),c=a.getElementById(\"cf-footer-ip-reveal\");b&&\"classList\"in b&&(b.classList.remove(\"hidden\"),c.addEventListener(\"click\",function(){c.classList.add(\"hidden\");a.getElementById(\"cf-footer-ip\").classList.remove(\"hidden\")}))}var a=document;document.addEventListener&&a.addEventListener(\"DOMContentLoaded\",d)})();</script>\n",
      "</div><!-- /.error-footer -->\n",
      "\n",
      "\n",
      "    </div>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "API Error: 520, <!DOCTYPE html>\n",
      "<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 8]>    <html class=\"no-js ie8 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if gt IE 8]><!--> <html class=\"no-js\" lang=\"en-US\"> <!--<![endif]-->\n",
      "<head>\n",
      "\n",
      "\n",
      "<title>api.x.ai | 520: Web server is returning an unknown error</title>\n",
      "<meta charset=\"UTF-8\" />\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n",
      "<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\n",
      "<meta name=\"robots\" content=\"noindex, nofollow\" />\n",
      "<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n",
      "<link rel=\"stylesheet\" id=\"cf_styles-css\" href=\"/cdn-cgi/styles/main.css\" />\n",
      "\n",
      "\n",
      "</head>\n",
      "<body>\n",
      "<div id=\"cf-wrapper\">\n",
      "    <div id=\"cf-error-details\" class=\"p-0\">\n",
      "        <header class=\"mx-auto pt-10 lg:pt-6 lg:px-8 w-240 lg:w-full mb-8\">\n",
      "            <h1 class=\"inline-block sm:block sm:mb-2 font-light text-60 lg:text-4xl text-black-dark leading-tight mr-2\">\n",
      "              <span class=\"inline-block\">Web server is returning an unknown error</span>\n",
      "              <span class=\"code-label\">Error code 520</span>\n",
      "            </h1>\n",
      "            <div>\n",
      "               Visit <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_520&utm_campaign=api.x.ai\" target=\"_blank\" rel=\"noopener noreferrer\">cloudflare.com</a> for more information.\n",
      "            </div>\n",
      "            <div class=\"mt-3\">2024-12-09 14:19:15 UTC</div>\n",
      "        </header>\n",
      "        <div class=\"my-8 bg-gradient-gray\">\n",
      "            <div class=\"w-240 lg:w-full mx-auto\">\n",
      "                <div class=\"clearfix md:px-8\">\n",
      "                  \n",
      "<div id=\"cf-browser-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-browser block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">You</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    \n",
      "    Browser\n",
      "    \n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "</div>\n",
      "\n",
      "<div id=\"cf-cloudflare-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_520&utm_campaign=api.x.ai\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    <span class=\"cf-icon-cloud block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    </a>\n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">New Delhi</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_520&utm_campaign=api.x.ai\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    Cloudflare\n",
      "    </a>\n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "</div>\n",
      "\n",
      "<div id=\"cf-host-status\" class=\"cf-error-source relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-server block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-error w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">api.x.ai</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    \n",
      "    Host\n",
      "    \n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-red-error\">Error</span>\n",
      "</div>\n",
      "\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"w-240 lg:w-full mx-auto mb-8 lg:px-8\">\n",
      "            <div class=\"clearfix\">\n",
      "                <div class=\"w-1/2 md:w-full float-left pr-6 md:pb-10 md:pr-0 leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What happened?</h2>\n",
      "                    <p>There is an unknown connection issue between Cloudflare and the origin web server. As a result, the web page can not be displayed.</p>\n",
      "                </div>\n",
      "                <div class=\"w-1/2 md:w-full float-left leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What can I do?</h2>\n",
      "                          <h3 class=\"text-15 font-semibold mb-2\">If you are a visitor of this website:</h3>\n",
      "      <p class=\"mb-6\">Please try again in a few minutes.</p>\n",
      "\n",
      "      <h3 class=\"text-15 font-semibold mb-2\">If you are the owner of this website:</h3>\n",
      "      <p><span>There is an issue between Cloudflare's cache and your origin web server. Cloudflare monitors for these errors and automatically investigates the cause. To help support the investigation, you can pull the corresponding error log from your web server and submit it our support team.  Please include the Ray ID (which is at the bottom of this error page).</span> <a rel=\"noopener noreferrer\" href=\"https://support.cloudflare.com/hc/en-us/articles/200171936-Error-520\">Additional troubleshooting resources</a>.</p>\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"cf-error-footer cf-wrapper w-240 lg:w-full py-10 sm:py-4 sm:px-8 mx-auto text-center sm:text-left border-solid border-0 border-t border-gray-300\">\n",
      "  <p class=\"text-13\">\n",
      "    <span class=\"cf-footer-item sm:block sm:mb-1\">Cloudflare Ray ID: <strong class=\"font-semibold\">8ef5a10c588659c4</strong></span>\n",
      "    <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "    <span id=\"cf-footer-item-ip\" class=\"cf-footer-item hidden sm:block sm:mb-1\">\n",
      "      Your IP:\n",
      "      <button type=\"button\" id=\"cf-footer-ip-reveal\" class=\"cf-footer-ip-reveal-btn\">Click to reveal</button>\n",
      "      <span class=\"hidden\" id=\"cf-footer-ip\">202.164.41.66</span>\n",
      "      <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "    </span>\n",
      "    <span class=\"cf-footer-item sm:block sm:mb-1\"><span>Performance &amp; security by</span> <a rel=\"noopener noreferrer\" href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_520&utm_campaign=api.x.ai\" id=\"brand_link\" target=\"_blank\">Cloudflare</a></span>\n",
      "    \n",
      "  </p>\n",
      "  <script>(function(){function d(){var b=a.getElementById(\"cf-footer-item-ip\"),c=a.getElementById(\"cf-footer-ip-reveal\");b&&\"classList\"in b&&(b.classList.remove(\"hidden\"),c.addEventListener(\"click\",function(){c.classList.add(\"hidden\");a.getElementById(\"cf-footer-ip\").classList.remove(\"hidden\")}))}var a=document;document.addEventListener&&a.addEventListener(\"DOMContentLoaded\",d)})();</script>\n",
      "</div><!-- /.error-footer -->\n",
      "\n",
      "\n",
      "    </div>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    },
    {
     "ename": "ReadTimeout",
     "evalue": "HTTPSConnectionPool(host='api.x.ai', port=443): Read timed out. (read timeout=None)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/urllib3/connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/urllib3/connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1042\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/urllib3/connection.py:419\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    417\u001b[0m     context\u001b[38;5;241m.\u001b[39mload_default_certs()\n\u001b[0;32m--> 419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# If we're using all defaults and the connection\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# for the host.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/urllib3/util/ssl_.py:449\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m send_sni:\n\u001b[0;32m--> 449\u001b[0m     ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/urllib3/util/ssl_.py:493\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m server_hostname:\n\u001b[0;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:517\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    512\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    513\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    514\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1075\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1075\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1346\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 60] Operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/requests/adapters.py:487\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 487\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 787\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    790\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/urllib3/util/retry.py:550\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 550\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/urllib3/packages/six.py:770\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 770\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/urllib3/connectionpool.py:389\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/urllib3/connectionpool.py:340\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m timeout_value\n\u001b[1;32m    342\u001b[0m     )\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3. In Python 2 we have\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# to specifically catch it and throw the timeout error\u001b[39;00m\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='api.x.ai', port=443): Read timed out. (read timeout=None)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeutral\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Apply Sentiment Analysis to the DataFrame\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_label\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_response\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43manalyze_sentiment_grok\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Display Results\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mData with Sentiment Analysis from Grok:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/series.py:4765\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4632\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4633\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4635\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4636\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4762\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4763\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4764\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4765\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/apply.py:1201\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/apply.py:1281\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1281\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1286\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning a DataFrame from Series.apply when the supplied function \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturns a Series is deprecated and will be removed in a future \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1291\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1292\u001b[0m     )  \u001b[38;5;66;03m# GH52116\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/algorithms.py:1812\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1810\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1815\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1816\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2917\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[18], line 47\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeutral\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Apply Sentiment Analysis to the DataFrame\u001b[39;00m\n\u001b[1;32m     46\u001b[0m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_label\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_response\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: pd\u001b[38;5;241m.\u001b[39mSeries(\u001b[43manalyze_sentiment_grok\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Display Results\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mData with Sentiment Analysis from Grok:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 24\u001b[0m, in \u001b[0;36manalyze_sentiment_grok\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     11\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mAPI_KEY\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m }\n\u001b[1;32m     15\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrok-beta\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     22\u001b[0m }\n\u001b[0;32m---> 24\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAPI_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     26\u001b[0m     result \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/requests/adapters.py:533\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='api.x.ai', port=443): Read timed out. (read timeout=None)"
     ]
    }
   ],
   "source": [
    "# Step 2: Sentiment Analysis Using Grok API\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the Grok API Key and Endpoint\n",
    "API_KEY = \"xai-wstXyvOcCGFeQlgy2LtyFzM1GLXDtCiXBrJO1snASustMyqOMWo4uKLwtQgVyYCgCGDOxODvW5RTz6B7\"\n",
    "API_URL = \"https://api.x.ai/v1/chat/completions\"\n",
    "\n",
    "# Function to Analyze Sentiment Using Grok API\n",
    "def analyze_sentiment_grok(text):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"grok-beta\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a sentiment analysis assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Analyze the sentiment of the following text: {text}\"}\n",
    "        ],\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        completion_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "        # Extract sentiment label and score from the response\n",
    "        label = \"Neutral\"\n",
    "        score = 0.0\n",
    "        \n",
    "        # Example logic for extracting sentiment information (adjust if needed)\n",
    "        if \"Positive\" in completion_text:\n",
    "            label = \"Positive\"\n",
    "            score = 0.9\n",
    "        elif \"Negative\" in completion_text:\n",
    "            label = \"Negative\"\n",
    "            score = 0.1\n",
    "        \n",
    "        return label, score, completion_text\n",
    "    else:\n",
    "        print(f\"API Error: {response.status_code}, {response.text}\")\n",
    "        return \"Neutral\", 0.0, \"Error in response\"      \n",
    "\n",
    "# Apply Sentiment Analysis to the DataFrame\n",
    "df[['sentiment_label', 'sentiment_score', 'raw_response']] = df['content'].apply(\n",
    "    lambda x: pd.Series(analyze_sentiment_grok(x))\n",
    ")\n",
    "\n",
    "# Display Results\n",
    "print(\"\\nData with Sentiment Analysis from Grok:\")\n",
    "print(df[['title', 'date', 'sentiment_label', 'sentiment_score', 'raw_response']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define OpenAI Batch API Endpoint and Headers\n",
    "batch_endpoint = 'https://api.openai.com/v1/batches'\n",
    "headers = {\n",
    "    'Authorization': f'Bearer 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',  # Replace with your actual API key\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "# Provide the Cloud Storage URL of Your Uploaded File\n",
    "uploaded_file_url = \"https://YOUR_STORAGE_PROVIDER_URL/batch_input.jsonl\"\n",
    "\n",
    "# Define the Batch Request Payload\n",
    "batch_payload = {\n",
    "    \"input_file\": uploaded_file_url,  # URL of the uploaded .jsonl file\n",
    "    \"output_file\": \"batch_output.jsonl\",  # Desired output file name\n",
    "    \"model\": \"gpt-4.0-mini\",\n",
    "    \"temperature\": 0\n",
    "}\n",
    "\n",
    "# Submit the Batch Request\n",
    "response = requests.post(batch_endpoint, headers=headers, json=batch_payload)\n",
    "\n",
    "# Handle Response\n",
    "if response.status_code == 200:\n",
    "    batch_id = response.json()['id']\n",
    "    print(f\"Batch submitted successfully. Batch ID: {batch_id}\")\n",
    "else:\n",
    "    print(f\"Batch submission failed: {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 3 CSV files\n",
      "Output saved to /Users/hemantg/Downloads/combined_output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def combine_csvs(input_directory, output_filename, merge_method='concat'):\n",
    "    \"\"\"\n",
    "    Combine multiple CSV files from a specified directory.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_directory: Path to the directory containing CSV files\n",
    "    - output_filename: Name of the output combined CSV file\n",
    "    - merge_method: Method of combining CSVs ('concat' or 'merge')\n",
    "    \n",
    "    Returns:\n",
    "    - Combined DataFrame\n",
    "    - Saves combined DataFrame to a CSV file\n",
    "    \"\"\"\n",
    "    # Get a list of all CSV files in the directory\n",
    "    csv_files = [f for f in os.listdir(input_directory) if f.endswith('.csv')]\n",
    "    \n",
    "    if not csv_files:\n",
    "        raise ValueError(\"No CSV files found in the specified directory\")\n",
    "    \n",
    "    # Read all CSV files\n",
    "    dataframes = []\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(input_directory, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    # Combine DataFrames based on merge method\n",
    "    if merge_method == 'concat':\n",
    "        # Simple concatenation (stacks DataFrames vertically)\n",
    "        combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    elif merge_method == 'merge':\n",
    "        # Merge DataFrames (requires a common column)\n",
    "        combined_df = dataframes[0]\n",
    "        for df in dataframes[1:]:\n",
    "            combined_df = pd.merge(combined_df, df, how='outer')\n",
    "    else:\n",
    "        raise ValueError(\"Invalid merge method. Choose 'concat' or 'merge'\")\n",
    "    \n",
    "    # Save combined DataFrame to CSV\n",
    "    combined_df.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(f\"Combined {len(csv_files)} CSV files\")\n",
    "    print(f\"Output saved to {output_filename}\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace these with your actual paths\n",
    "    input_dir = '/Users/hemantg/Downloads/output-3files'\n",
    "    output_file = '/Users/hemantg/Downloads/combined_output.csv'\n",
    "    \n",
    "    # Combine CSVs using concatenation\n",
    "    result_concat = combine_csvs(input_dir, output_file, merge_method='concat')\n",
    "    \n",
    "    # If you need to merge on a specific column, use 'merge' method\n",
    "    # result_merge = combine_csvs(input_dir, output_file, merge_method='merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'natsort'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnatsort\u001b[39;00m  \u001b[38;5;66;03m# for natural sorting of filenames\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_sorted_csvs\u001b[39m(input_directory, output_filename):\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    Combine CSV files from a directory, sorted by filename in a natural order.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    - Saves combined DataFrame to a CSV file\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'natsort'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import natsort  # for natural sorting of filenames\n",
    "\n",
    "def combine_sorted_csvs(input_directory, output_filename):\n",
    "    \"\"\"\n",
    "    Combine CSV files from a directory, sorted by filename in a natural order.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_directory: Path to the directory containing CSV files\n",
    "    - output_filename: Name of the output combined CSV file\n",
    "    \n",
    "    Returns:\n",
    "    - Combined DataFrame\n",
    "    - Saves combined DataFrame to a CSV file\n",
    "    \"\"\"\n",
    "    # Get a list of CSV files, sorted naturally\n",
    "    csv_files = natsort.natsorted(\n",
    "        [f for f in os.listdir(input_directory) if f.endswith('.csv')]\n",
    "    )\n",
    "    \n",
    "    if not csv_files:\n",
    "        raise ValueError(\"No CSV files found in the specified directory\")\n",
    "    \n",
    "    # Read and combine sorted CSV files\n",
    "    dataframes = []\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(input_directory, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Optional: Add a column to track original filename if needed\n",
    "        df['source_file'] = file\n",
    "        \n",
    "        dataframes.append(df)\n",
    "        print(f\"Added file: {file}\")\n",
    "    \n",
    "    # Concatenate DataFrames\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    # Save combined DataFrame to CSV\n",
    "    combined_df.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(f\"\\nCombined {len(csv_files)} CSV files\")\n",
    "    print(f\"Files sorted and combined in order: {', '.join(csv_files)}\")\n",
    "    print(f\"Output saved to {output_filename}\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual directory path\n",
    "    input_dir = '/Users/hemantg/Downloads/output-3files'\n",
    "    output_file = '/Users/hemantg/Downloads/combined_output1.csv'\n",
    "    \n",
    "    # Combine sorted CSVs\n",
    "    result = combine_sorted_csvs(input_dir, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added file: output_1of3.csv\n",
      "Added file: output_2of3.csv\n",
      "Added file: output_3of3.csv\n",
      "\n",
      "Combined 3 CSV files\n",
      "Files sorted and combined in order: output_1of3.csv, output_2of3.csv, output_3of3.csv\n",
      "Output saved to /Users/hemantg/Downloads/combined_output1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def combine_sorted_csvs(input_directory, output_filename):\n",
    "    \"\"\"\n",
    "    Combine CSV files from a directory, sorted by filename.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_directory: Path to the directory containing CSV files\n",
    "    - output_filename: Name of the output combined CSV file\n",
    "    \n",
    "    Returns:\n",
    "    - Combined DataFrame\n",
    "    - Saves combined DataFrame to a CSV file\n",
    "    \"\"\"\n",
    "    # Get a list of CSV files, sorted alphabetically\n",
    "    csv_files = sorted([f for f in os.listdir(input_directory) if f.endswith('.csv')])\n",
    "    \n",
    "    if not csv_files:\n",
    "        raise ValueError(\"No CSV files found in the specified directory\")\n",
    "    \n",
    "    # Read and combine sorted CSV files\n",
    "    dataframes = []\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(input_directory, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Optional: Add a column to track original filename if needed\n",
    "        df['source_file'] = file\n",
    "        \n",
    "        dataframes.append(df)\n",
    "        print(f\"Added file: {file}\")\n",
    "    \n",
    "    # Concatenate DataFrames\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    # Save combined DataFrame to CSV\n",
    "    combined_df.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(f\"\\nCombined {len(csv_files)} CSV files\")\n",
    "    print(f\"Files sorted and combined in order: {', '.join(csv_files)}\")\n",
    "    print(f\"Output saved to {output_filename}\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual directory path\n",
    "    input_dir = '/Users/hemantg/Downloads/output-3files'\n",
    "    output_file = '/Users/hemantg/Downloads/combined_output1.csv'\n",
    "    \n",
    "    # Combine sorted CSVs\n",
    "    result = combine_sorted_csvs(input_dir, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Process each row\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 13\u001b[0m     date \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m     processed_results \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_results\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;66;03m# Load the JSON data\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the CSV\n",
    "input_file = '/Users/hemantg/Desktop/try-combined-output.csv'  # Replace with the actual file path\n",
    "df = pd.read_csv(input_file, sep='\\t')\n",
    "\n",
    "# Initialize a list to store processed rows\n",
    "processed_rows = []\n",
    "\n",
    "# Process each row\n",
    "for index, row in df.iterrows():\n",
    "    date = row['date']\n",
    "    processed_results = row['processed_results']\n",
    "\n",
    "    try:\n",
    "        # Load the JSON data\n",
    "        players_data = json.loads(processed_results)\n",
    "        row_data = {'date': date}\n",
    "        \n",
    "        # Extract player information\n",
    "        for i, player in enumerate(players_data):\n",
    "            row_data[f'player{i+1}_name'] = player['player_name']\n",
    "            row_data[f'player{i+1}_output'] = json.dumps(player)\n",
    "        \n",
    "        processed_rows.append(row_data)\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON for row {index}: {e}\")\n",
    "\n",
    "# Create a new DataFrame\n",
    "output_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Save to a new CSV file\n",
    "output_file = '/Users/hemantg/Desktop/try-processed_output.csv'\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Processed CSV saved at: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['date,original_text,processed_results'], dtype='object')\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Missing column: 'processed_results'\n",
      "Processed CSV saved at: /Users/hemantg/Desktop/try-processed_output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the CSV\n",
    "input_file = '/Users/hemantg/Desktop/try-combined-output.csv'  # Replace with the actual file path\n",
    "df = pd.read_csv(input_file, sep='\\t')\n",
    "\n",
    "# Inspect columns\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# Initialize a list to store processed rows\n",
    "processed_rows = []\n",
    "\n",
    "# Process each row\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        date = row['date'] if 'date' in df.columns else row[df.columns[0]]\n",
    "        processed_results = row['processed_results']\n",
    "\n",
    "        # Load the JSON data\n",
    "        players_data = json.loads(processed_results)\n",
    "        row_data = {'date': date}\n",
    "        \n",
    "        # Extract player information\n",
    "        for i, player in enumerate(players_data):\n",
    "            row_data[f'player{i+1}_name'] = player['player_name']\n",
    "            row_data[f'player{i+1}_output'] = json.dumps(player)\n",
    "        \n",
    "        processed_rows.append(row_data)\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON for row {index}: {e}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing column: {e}\")\n",
    "\n",
    "# Create a new DataFrame\n",
    "output_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Save to a new CSV file\n",
    "output_file = '/Users/hemantg/Desktop/try-processed_output.csv'\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Processed CSV saved at: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['date', 'original_text', 'processed_results'], dtype='object')\n",
      "Error decoding JSON for row 0: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 1: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 2: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 3: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 4: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 5: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 6: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 7: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 8: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 9: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 10: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 11: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 12: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 13: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 14: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 15: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 16: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 17: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 18: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 19: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 20: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 21: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 22: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 23: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 24: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 25: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 26: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 27: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 28: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 29: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 30: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 31: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 32: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 33: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 34: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 35: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 36: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 37: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 38: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 39: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 40: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 41: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 42: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 43: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 44: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 45: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 46: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 47: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 48: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 49: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 50: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 51: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 52: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 53: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 54: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 55: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 56: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 57: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 58: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 59: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 60: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 61: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 62: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 63: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 64: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 65: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 66: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 67: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 68: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 69: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 70: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 71: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 72: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 73: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 74: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 75: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 76: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 77: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 78: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 79: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 80: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 81: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 82: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 83: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 84: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 85: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 86: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 87: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 88: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 89: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 90: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 91: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 92: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 93: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 94: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 95: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 96: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 97: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 98: Expecting value: line 1 column 1 (char 0)\n",
      "Processed CSV saved at: /Users/hemantg/Desktop/try-processed_output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the CSV with the correct delimiter\n",
    "input_file = '/Users/hemantg/Desktop/try-combined-output.csv'  # Replace with the actual file path\n",
    "df = pd.read_csv(input_file, sep=',')\n",
    "\n",
    "# Inspect the first few rows\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# Initialize a list to store processed rows\n",
    "processed_rows = []\n",
    "\n",
    "# Process each row\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        date = row['date']\n",
    "        processed_results = row['processed_results']\n",
    "\n",
    "        # Load the JSON data\n",
    "        players_data = json.loads(processed_results)\n",
    "        row_data = {'date': date}\n",
    "        \n",
    "        # Extract player information\n",
    "        for i, player in enumerate(players_data):\n",
    "            row_data[f'player{i+1}_name'] = player['player_name']\n",
    "            row_data[f'player{i+1}_output'] = json.dumps(player)\n",
    "        \n",
    "        processed_rows.append(row_data)\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON for row {index}: {e}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing column: {e}\")\n",
    "\n",
    "# Create a new DataFrame\n",
    "output_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Save to a new CSV file\n",
    "output_file = '/Users/hemantg/Desktop/try-processed_output.csv'\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Processed CSV saved at: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected Columns in the DataFrame: Index(['date', 'original_text', 'processed_results'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Correct the header if necessary\n",
    "df.columns = ['date', 'original_text', 'processed_results']\n",
    "\n",
    "# Inspect the first few rows\n",
    "print(\"Corrected Columns in the DataFrame:\", df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['date', 'original_text', 'processed_results'], dtype='object')\n",
      "Error decoding JSON for row 0: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 1: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 2: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 3: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 4: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 5: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 6: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 7: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 8: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 9: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 10: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 11: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 12: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 13: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 14: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 15: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 16: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 17: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 18: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 19: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 20: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 21: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 22: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 23: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 24: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 25: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 26: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 27: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 28: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 29: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 30: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 31: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 32: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 33: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 34: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 35: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 36: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 37: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 38: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 39: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 40: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 41: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 42: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 43: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 44: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 45: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 46: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 47: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 48: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 49: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 50: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 51: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 52: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 53: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 54: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 55: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 56: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 57: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 58: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 59: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 60: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 61: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 62: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 63: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 64: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 65: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 66: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 67: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 68: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 69: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 70: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 71: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 72: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 73: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 74: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 75: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 76: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 77: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 78: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 79: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 80: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 81: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 82: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 83: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 84: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 85: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 86: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 87: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 88: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 89: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 90: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 91: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 92: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 93: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 94: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 95: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 96: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 97: Expecting value: line 1 column 1 (char 0)\n",
      "Error decoding JSON for row 98: Expecting value: line 1 column 1 (char 0)\n",
      "Processed CSV saved at: /Users/hemantg/Desktop/try-processed_output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the CSV with the correct delimiter\n",
    "input_file = '/Users/hemantg/Desktop/try-combined-output.csv'  # Replace with the actual file path\n",
    "df = pd.read_csv(input_file, sep=',')\n",
    "\n",
    "# Inspect the first few rows\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# Initialize a list to store processed rows\n",
    "processed_rows = []\n",
    "\n",
    "# Process each row\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        date = row['date']\n",
    "        processed_results = row['processed_results']\n",
    "        \n",
    "        # Check if the processed_results field is not empty\n",
    "        if pd.notna(processed_results) and processed_results.strip():\n",
    "            # Load the JSON data\n",
    "            players_data = json.loads(processed_results)\n",
    "            row_data = {'date': date}\n",
    "            \n",
    "            # Extract player information\n",
    "            for i, player in enumerate(players_data):\n",
    "                row_data[f'player{i+1}_name'] = player['player_name']\n",
    "                row_data[f'player{i+1}_output'] = json.dumps(player)\n",
    "            \n",
    "            processed_rows.append(row_data)\n",
    "        else:\n",
    "            print(f\"Empty processed_results at row {index}\")\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON for row {index}: {e}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing column: {e}\")\n",
    "\n",
    "# Create a new DataFrame\n",
    "output_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Save to a new CSV file\n",
    "output_file = '/Users/hemantg/Desktop/try-processed_output.csv'\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Processed CSV saved at: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ```json\\n[\\n  {\\n    \"player_name\": \"Mohammad_...\n",
      "1    ```json\\n[\\n  {\\n    \"player_name\": \"Shane_War...\n",
      "2    ```json\\n[\\n  {\\n    \"player_name\": \"Brett_Lee...\n",
      "3    ```json\\n[\\n  {\\n    \"player_name\": \"Adam_Gilc...\n",
      "4    ```json\\n[\\n  {\\n    \"player_name\": \"Rohit_Sha...\n",
      "5    ```json\\n[\\n  {\\n    \"player_name\": \"Kevin_Pie...\n",
      "6    ```json\\n[\\n  {\\n    \"player_name\": \"Dimitri_M...\n",
      "7    ```json\\n[\\n  {\\n    \"player_name\": \"Daniel_Ve...\n",
      "8    ```json\\n[\\n  {\\n    \"player_name\": \"Dimitri_M...\n",
      "9    ```json\\n[\\n  {\\n    \"player_name\": \"Nathan_Br...\n",
      "Name: processed_results, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Inspect the first few rows of the processed_results column\n",
    "print(df['processed_results'].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['date', 'original_text', 'processed_results'], dtype='object')\n",
      "Error decoding JSON for row 35: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 82: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Processed CSV saved at: /Users/hemantg/Desktop/try-processed_output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the CSV\n",
    "input_file = '/Users/hemantg/Desktop/try-combined-output.csv'  # Replace with the actual file path\n",
    "df = pd.read_csv(input_file, sep=',')\n",
    "\n",
    "# Inspect columns\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# Initialize a list to store processed rows\n",
    "processed_rows = []\n",
    "\n",
    "# Process each row\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        date = row['date']\n",
    "        processed_results = row['processed_results']\n",
    "\n",
    "        # Ensure the value is not empty\n",
    "        if pd.notna(processed_results) and processed_results.strip():\n",
    "            # Clean and fix the JSON format\n",
    "            cleaned_json = (\n",
    "                processed_results.strip()\n",
    "                .replace(\"```json\", \"\")\n",
    "                .replace(\"```\", \"\")\n",
    "                .strip()\n",
    "            )\n",
    "\n",
    "            # Parse JSON\n",
    "            players_data = json.loads(cleaned_json)\n",
    "            row_data = {'date': date}\n",
    "\n",
    "            # Extract player information\n",
    "            for i, player in enumerate(players_data):\n",
    "                row_data[f'player{i+1}_name'] = player['player_name']\n",
    "                row_data[f'player{i+1}_output'] = json.dumps(player)\n",
    "\n",
    "            processed_rows.append(row_data)\n",
    "        else:\n",
    "            print(f\"Empty or invalid processed_results at row {index}\")\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON for row {index}: {e}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing column: {e}\")\n",
    "\n",
    "# Create a new DataFrame\n",
    "output_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Save to a new CSV file\n",
    "output_file = '/Users/hemantg/Desktop/try-processed_output.csv'\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Processed CSV saved at: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['date', 'original_text', 'processed_results'], dtype='object')\n",
      "Error decoding JSON for row 35: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 82: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Processed CSV saved at: /Users/hemantg/Desktop/try-processed_output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the CSV\n",
    "input_file = '/Users/hemantg/Desktop/try-combined-output.csv'  # Replace with the actual file path\n",
    "df = pd.read_csv(input_file, sep=',')\n",
    "\n",
    "# Inspect columns\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# Initialize a list to store processed rows\n",
    "processed_rows = []\n",
    "\n",
    "# Process each row\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        date = row['date']\n",
    "        processed_results = row['processed_results']\n",
    "\n",
    "        # Ensure the value is not empty\n",
    "        if pd.notna(processed_results) and processed_results.strip():\n",
    "            # Clean and fix the JSON format\n",
    "            cleaned_json = (\n",
    "                processed_results.strip()\n",
    "                .replace(\"```json\", \"\")\n",
    "                .replace(\"```\", \"\")\n",
    "                .replace('\"\"', '\"')  # Fix incorrect quotes\n",
    "                .strip()\n",
    "            )\n",
    "\n",
    "            # Parse JSON\n",
    "            players_data = json.loads(cleaned_json)\n",
    "            row_data = {'date': date}\n",
    "\n",
    "            # Extract player information\n",
    "            for i, player in enumerate(players_data):\n",
    "                row_data[f'player{i+1}_name'] = player['player_name']\n",
    "                row_data[f'player{i+1}_output'] = json.dumps(player)\n",
    "\n",
    "            processed_rows.append(row_data)\n",
    "        else:\n",
    "            print(f\"Empty or invalid processed_results at row {index}\")\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON for row {index}: {e}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing column: {e}\")\n",
    "\n",
    "# Create a new DataFrame\n",
    "output_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Save to a new CSV file\n",
    "output_file = '/Users/hemantg/Desktop/try-processed_output.csv'\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Processed CSV saved at: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['date', 'original_text', 'processed_results'], dtype='object')\n",
      "Error decoding JSON for row 35: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 82: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 112: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 122: Expecting value: line 36 column 16 (char 1690)\n",
      "Error decoding JSON for row 129: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 130: Expecting property name enclosed in double quotes: line 86 column 102 (char 3906)\n",
      "Error decoding JSON for row 133: Unterminated string starting at: line 83 column 20 (char 3934)\n",
      "Error decoding JSON for row 189: Expecting value: line 85 column 16 (char 3813)\n",
      "Error decoding JSON for row 190: Unterminated string starting at: line 84 column 5 (char 4052)\n",
      "Error decoding JSON for row 191: Unterminated string starting at: line 78 column 18 (char 4092)\n",
      "Error decoding JSON for row 208: Unterminated string starting at: line 76 column 16 (char 4077)\n",
      "Error decoding JSON for row 212: Unterminated string starting at: line 76 column 16 (char 4049)\n",
      "Error decoding JSON for row 219: Expecting value: line 79 column 29 (char 4332)\n",
      "Error decoding JSON for row 223: Unterminated string starting at: line 78 column 18 (char 3992)\n",
      "Error decoding JSON for row 224: Unterminated string starting at: line 85 column 17 (char 3849)\n",
      "Error decoding JSON for row 234: Expecting property name enclosed in double quotes: line 74 column 4 (char 3753)\n",
      "Error decoding JSON for row 237: Expecting value: line 79 column 25 (char 4062)\n",
      "Error decoding JSON for row 238: Unterminated string starting at: line 88 column 5 (char 4006)\n",
      "Error decoding JSON for row 242: Expecting value: line 97 column 5 (char 3721)\n",
      "Error decoding JSON for row 245: Unterminated string starting at: line 83 column 20 (char 3920)\n",
      "Error decoding JSON for row 247: Expecting property name enclosed in double quotes: line 85 column 90 (char 3909)\n",
      "Error decoding JSON for row 248: Unterminated string starting at: line 92 column 16 (char 3787)\n",
      "Error decoding JSON for row 253: Unterminated string starting at: line 86 column 18 (char 3732)\n",
      "Error decoding JSON for row 256: Expecting property name enclosed in double quotes: line 3 column 9 (char 16)\n",
      "Error decoding JSON for row 264: Unterminated string starting at: line 87 column 5 (char 3792)\n",
      "Error decoding JSON for row 266: Unterminated string starting at: line 87 column 5 (char 3872)\n",
      "Error decoding JSON for row 267: Unterminated string starting at: line 78 column 18 (char 3870)\n",
      "Error decoding JSON for row 275: Expecting value: line 89 column 5 (char 3781)\n",
      "Error decoding JSON for row 289: Expecting value: line 79 column 25 (char 4099)\n",
      "Error decoding JSON for row 290: Unterminated string starting at: line 77 column 17 (char 3810)\n",
      "Error decoding JSON for row 300: Unterminated string starting at: line 92 column 16 (char 3833)\n",
      "Error decoding JSON for row 301: Expecting property name enclosed in double quotes: line 84 column 61 (char 3745)\n",
      "Error decoding JSON for row 312: Unterminated string starting at: line 80 column 5 (char 4009)\n",
      "Error decoding JSON for row 313: Expecting value: line 71 column 25 (char 4329)\n",
      "Error decoding JSON for row 328: Unterminated string starting at: line 86 column 18 (char 4144)\n",
      "Error decoding JSON for row 331: Unterminated string starting at: line 85 column 17 (char 3970)\n",
      "Error decoding JSON for row 339: Unterminated string starting at: line 86 column 18 (char 3742)\n",
      "Error decoding JSON for row 350: Unterminated string starting at: line 78 column 18 (char 4111)\n",
      "Error decoding JSON for row 359: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 363: Unterminated string starting at: line 79 column 5 (char 4075)\n",
      "Error decoding JSON for row 366: Unterminated string starting at: line 92 column 16 (char 3678)\n",
      "Error decoding JSON for row 369: Unterminated string starting at: line 85 column 5 (char 4043)\n",
      "Error decoding JSON for row 370: Unterminated string starting at: line 93 column 17 (char 3506)\n",
      "Error decoding JSON for row 371: Unterminated string starting at: line 87 column 5 (char 3910)\n",
      "Error decoding JSON for row 372: Unterminated string starting at: line 83 column 20 (char 3973)\n",
      "Error decoding JSON for row 381: Unterminated string starting at: line 86 column 18 (char 3934)\n",
      "Error decoding JSON for row 384: Unterminated string starting at: line 88 column 5 (char 3858)\n",
      "Error decoding JSON for row 398: Unterminated string starting at: line 77 column 21 (char 4287)\n",
      "Error decoding JSON for row 401: Unterminated string starting at: line 80 column 9 (char 4282)\n",
      "Error decoding JSON for row 408: Expecting property name enclosed in double quotes: line 82 column 4 (char 4077)\n",
      "Error decoding JSON for row 411: Unterminated string starting at: line 78 column 18 (char 3989)\n",
      "Error decoding JSON for row 420: Unterminated string starting at: line 78 column 5 (char 3942)\n",
      "Error decoding JSON for row 424: Unterminated string starting at: line 85 column 17 (char 3878)\n",
      "Error decoding JSON for row 432: Unterminated string starting at: line 85 column 17 (char 3966)\n",
      "Error decoding JSON for row 461: Invalid control character at: line 52 column 97 (char 3084)\n",
      "Error decoding JSON for row 466: Expecting ',' delimiter: line 72 column 40 (char 4188)\n",
      "Error decoding JSON for row 476: Expecting property name enclosed in double quotes: line 76 column 77 (char 4112)\n",
      "Error decoding JSON for row 477: Unterminated string starting at: line 68 column 16 (char 3224)\n",
      "Error decoding JSON for row 480: Unterminated string starting at: line 83 column 20 (char 4205)\n",
      "Error decoding JSON for row 496: Expecting property name enclosed in double quotes: line 92 column 65 (char 3791)\n",
      "Error decoding JSON for row 502: Unterminated string starting at: line 77 column 5 (char 3985)\n",
      "Error decoding JSON for row 528: Unterminated string starting at: line 80 column 5 (char 4393)\n",
      "Error decoding JSON for row 534: Unterminated string starting at: line 75 column 20 (char 4121)\n",
      "Error decoding JSON for row 536: Unterminated string starting at: line 86 column 18 (char 3900)\n",
      "Error decoding JSON for row 541: Unterminated string starting at: line 80 column 5 (char 4034)\n",
      "Error decoding JSON for row 550: Expecting ',' delimiter: line 6 column 149 (char 522)\n",
      "Error decoding JSON for row 560: Expecting ',' delimiter: line 80 column 42 (char 4355)\n",
      "Error decoding JSON for row 573: Unterminated string starting at: line 84 column 16 (char 3955)\n",
      "Error decoding JSON for row 576: Invalid control character at: line 12 column 18 (char 560)\n",
      "Error decoding JSON for row 577: Expecting property name enclosed in double quotes: line 84 column 69 (char 3849)\n",
      "Error decoding JSON for row 580: Unterminated string starting at: line 77 column 17 (char 4121)\n",
      "Error decoding JSON for row 589: Unterminated string starting at: line 84 column 16 (char 3985)\n",
      "Error decoding JSON for row 601: Unterminated string starting at: line 76 column 20 (char 4574)\n",
      "Error decoding JSON for row 602: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 604: Unterminated string starting at: line 84 column 16 (char 3892)\n",
      "Error decoding JSON for row 617: Unterminated string starting at: line 76 column 16 (char 3855)\n",
      "Error decoding JSON for row 631: Unterminated string starting at: line 84 column 5 (char 3885)\n",
      "Error decoding JSON for row 640: Unterminated string starting at: line 86 column 22 (char 4309)\n",
      "Error decoding JSON for row 642: Unterminated string starting at: line 93 column 17 (char 3764)\n",
      "Error decoding JSON for row 646: Unterminated string starting at: line 85 column 17 (char 3796)\n",
      "Error decoding JSON for row 649: Unterminated string starting at: line 86 column 18 (char 3926)\n",
      "Error decoding JSON for row 650: Unterminated string starting at: line 63 column 5 (char 3686)\n",
      "Error decoding JSON for row 652: Expecting value: line 83 column 19 (char 3754)\n",
      "Error decoding JSON for row 658: Expecting property name enclosed in double quotes: line 93 column 67 (char 3782)\n",
      "Error decoding JSON for row 679: Expecting property name enclosed in double quotes: line 92 column 87 (char 3974)\n",
      "Error decoding JSON for row 687: Unterminated string starting at: line 75 column 20 (char 4203)\n",
      "Error decoding JSON for row 688: Unterminated string starting at: line 86 column 18 (char 3847)\n",
      "Error decoding JSON for row 693: Expecting property name enclosed in double quotes: line 70 column 75 (char 3575)\n",
      "Error decoding JSON for row 704: Unterminated string starting at: line 76 column 16 (char 3944)\n",
      "Error decoding JSON for row 709: Unterminated string starting at: line 85 column 17 (char 4025)\n",
      "Error decoding JSON for row 711: Unterminated string starting at: line 85 column 17 (char 3934)\n",
      "Error decoding JSON for row 721: Expecting value: line 81 column 5 (char 3632)\n",
      "Error decoding JSON for row 727: Unterminated string starting at: line 77 column 17 (char 4282)\n",
      "Error decoding JSON for row 736: Unterminated string starting at: line 80 column 5 (char 3891)\n",
      "Error decoding JSON for row 741: Unterminated string starting at: line 84 column 16 (char 4066)\n",
      "Error decoding JSON for row 744: Unterminated string starting at: line 92 column 16 (char 3829)\n",
      "Error decoding JSON for row 748: Expecting property name enclosed in double quotes: line 79 column 30 (char 4016)\n",
      "Error decoding JSON for row 758: Unterminated string starting at: line 78 column 18 (char 4062)\n",
      "Error decoding JSON for row 760: Expecting ',' delimiter: line 80 column 40 (char 3977)\n",
      "Error decoding JSON for row 766: Expecting ',' delimiter: line 79 column 27 (char 4026)\n",
      "Error decoding JSON for row 775: Unterminated string starting at: line 79 column 5 (char 4040)\n",
      "Error decoding JSON for row 787: Unterminated string starting at: line 86 column 18 (char 4094)\n",
      "Error decoding JSON for row 791: Expecting property name enclosed in double quotes: line 91 column 35 (char 3842)\n",
      "Error decoding JSON for row 808: Unterminated string starting at: line 80 column 5 (char 4073)\n",
      "Error decoding JSON for row 811: Unterminated string starting at: line 92 column 16 (char 3711)\n",
      "Error decoding JSON for row 813: Expecting property name enclosed in double quotes: line 85 column 84 (char 3900)\n",
      "Error decoding JSON for row 817: Unterminated string starting at: line 71 column 5 (char 3436)\n",
      "Error decoding JSON for row 821: Unterminated string starting at: line 78 column 18 (char 3944)\n",
      "Error decoding JSON for row 825: Expecting ',' delimiter: line 88 column 40 (char 3882)\n",
      "Error decoding JSON for row 838: Unterminated string starting at: line 78 column 18 (char 4205)\n",
      "Error decoding JSON for row 854: Unterminated string starting at: line 85 column 17 (char 3989)\n",
      "Error decoding JSON for row 859: Unterminated string starting at: line 92 column 16 (char 3892)\n",
      "Error decoding JSON for row 861: Unterminated string starting at: line 85 column 17 (char 3894)\n",
      "Error decoding JSON for row 862: Expecting ',' delimiter: line 80 column 40 (char 3908)\n",
      "Error decoding JSON for row 864: Expecting value: line 89 column 5 (char 3634)\n",
      "Error decoding JSON for row 871: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 881: Unterminated string starting at: line 86 column 18 (char 3954)\n",
      "Error decoding JSON for row 896: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 897: Unterminated string starting at: line 78 column 18 (char 4058)\n",
      "Error decoding JSON for row 910: Unterminated string starting at: line 78 column 18 (char 4034)\n",
      "Error decoding JSON for row 911: Unterminated string starting at: line 84 column 16 (char 4053)\n",
      "Error decoding JSON for row 920: Expecting value: line 86 column 17 (char 3863)\n",
      "Error decoding JSON for row 927: Expecting value: line 80 column 36 (char 3965)\n",
      "Error decoding JSON for row 929: Expecting property name enclosed in double quotes: line 79 column 30 (char 4038)\n",
      "Error decoding JSON for row 930: Unterminated string starting at: line 72 column 5 (char 4103)\n",
      "Error decoding JSON for row 933: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 935: Expecting property name enclosed in double quotes: line 74 column 4 (char 4142)\n",
      "Error decoding JSON for row 941: Unterminated string starting at: line 93 column 5 (char 3985)\n",
      "Error decoding JSON for row 952: Unterminated string starting at: line 88 column 5 (char 3911)\n",
      "Error decoding JSON for row 960: Expecting value: line 85 column 16 (char 3952)\n",
      "Error decoding JSON for row 965: Unterminated string starting at: line 77 column 17 (char 3972)\n",
      "Error decoding JSON for row 969: Expecting value: line 85 column 16 (char 3986)\n",
      "Error decoding JSON for row 970: Expecting ',' delimiter: line 88 column 41 (char 4029)\n",
      "Error decoding JSON for row 971: Unterminated string starting at: line 84 column 16 (char 4016)\n",
      "Error decoding JSON for row 999: Unterminated string starting at: line 75 column 20 (char 3940)\n",
      "Error decoding JSON for row 1003: Unterminated string starting at: line 85 column 17 (char 3841)\n",
      "Error decoding JSON for row 1004: Unterminated string starting at: line 85 column 5 (char 4363)\n",
      "Error decoding JSON for row 1008: Expecting value: line 83 column 19 (char 4073)\n",
      "Error decoding JSON for row 1010: Expecting ',' delimiter: line 80 column 38 (char 4116)\n",
      "Error decoding JSON for row 1012: Unterminated string starting at: line 78 column 18 (char 4034)\n",
      "Error decoding JSON for row 1027: Unterminated string starting at: line 85 column 21 (char 4130)\n",
      "Error decoding JSON for row 1034: Unterminated string starting at: line 79 column 5 (char 4053)\n",
      "Error decoding JSON for row 1035: Unterminated string starting at: line 91 column 20 (char 3640)\n",
      "Error decoding JSON for row 1055: Unterminated string starting at: line 79 column 9 (char 4345)\n",
      "Error decoding JSON for row 1063: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 1067: Expecting property name enclosed in double quotes: line 90 column 4 (char 3962)\n",
      "Error decoding JSON for row 1068: Unterminated string starting at: line 76 column 16 (char 3911)\n",
      "Error decoding JSON for row 1073: Unterminated string starting at: line 86 column 18 (char 3996)\n",
      "Error decoding JSON for row 1074: Unterminated string starting at: line 84 column 16 (char 3945)\n",
      "Error decoding JSON for row 1077: Unterminated string starting at: line 92 column 5 (char 3990)\n",
      "Error decoding JSON for row 1079: Unterminated string starting at: line 86 column 5 (char 3840)\n",
      "Error decoding JSON for row 1084: Unterminated string starting at: line 85 column 17 (char 3926)\n",
      "Error decoding JSON for row 1094: Expecting property name enclosed in double quotes: line 85 column 73 (char 3927)\n",
      "Error decoding JSON for row 1095: Unterminated string starting at: line 91 column 20 (char 3888)\n",
      "Error decoding JSON for row 1109: Expecting ',' delimiter: line 88 column 38 (char 3969)\n",
      "Error decoding JSON for row 1115: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 1116: Unterminated string starting at: line 78 column 18 (char 4086)\n",
      "Error decoding JSON for row 1118: Expecting value: line 89 column 5 (char 3859)\n",
      "Error decoding JSON for row 1128: Unterminated string starting at: line 80 column 5 (char 4141)\n",
      "Error decoding JSON for row 1131: Unterminated string starting at: line 88 column 5 (char 3817)\n",
      "Error decoding JSON for row 1139: Unterminated string starting at: line 85 column 17 (char 3944)\n",
      "Error decoding JSON for row 1142: Expecting value: line 80 column 36 (char 3977)\n",
      "Error decoding JSON for row 1146: Unterminated string starting at: line 77 column 17 (char 4004)\n",
      "Error decoding JSON for row 1154: Unterminated string starting at: line 83 column 20 (char 3900)\n",
      "Error decoding JSON for row 1156: Expecting value: line 80 column 36 (char 3843)\n",
      "Error decoding JSON for row 1160: Unterminated string starting at: line 83 column 20 (char 3971)\n",
      "Error decoding JSON for row 1162: Unterminated string starting at: line 84 column 16 (char 3825)\n",
      "Error decoding JSON for row 1167: Unterminated string starting at: line 72 column 5 (char 4027)\n",
      "Error decoding JSON for row 1174: Unterminated string starting at: line 80 column 5 (char 3986)\n",
      "Error decoding JSON for row 1177: Unterminated string starting at: line 88 column 5 (char 3940)\n",
      "Error decoding JSON for row 1178: Unterminated string starting at: line 84 column 16 (char 4006)\n",
      "Error decoding JSON for row 1181: Expecting ',' delimiter: line 88 column 38 (char 3873)\n",
      "Error decoding JSON for row 1185: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 1198: Unterminated string starting at: line 85 column 17 (char 4009)\n",
      "Error decoding JSON for row 1210: Unterminated string starting at: line 88 column 5 (char 3990)\n",
      "Error decoding JSON for row 1227: Expecting value: line 75 column 19 (char 4319)\n",
      "Error decoding JSON for row 1228: Unterminated string starting at: line 79 column 5 (char 4222)\n",
      "Error decoding JSON for row 1237: Unterminated string starting at: line 86 column 22 (char 4227)\n",
      "Error decoding JSON for row 1254: Expecting value: line 92 column 15 (char 3946)\n",
      "Error decoding JSON for row 1255: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 1256: Expecting property name enclosed in double quotes: line 79 column 30 (char 4177)\n",
      "Error decoding JSON for row 1264: Expecting ',' delimiter: line 80 column 40 (char 4079)\n",
      "Error decoding JSON for row 1265: Unterminated string starting at: line 77 column 17 (char 3815)\n",
      "Error decoding JSON for row 1276: Expecting property name enclosed in double quotes: line 71 column 30 (char 4141)\n",
      "Error decoding JSON for row 1285: Expecting ',' delimiter: line 79 column 27 (char 4135)\n",
      "Error decoding JSON for row 1286: Unterminated string starting at: line 85 column 5 (char 4057)\n",
      "Error decoding JSON for row 1291: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 1293: Unterminated string starting at: line 83 column 5 (char 4188)\n",
      "Error decoding JSON for row 1295: Unterminated string starting at: line 78 column 18 (char 4009)\n",
      "Error decoding JSON for row 1296: Unterminated string starting at: line 86 column 18 (char 3966)\n",
      "Error decoding JSON for row 1299: Unterminated string starting at: line 86 column 18 (char 3830)\n",
      "Error decoding JSON for row 1311: Expecting ',' delimiter: line 36 column 22 (char 1863)\n",
      "Error decoding JSON for row 1328: Unterminated string starting at: line 77 column 5 (char 4043)\n",
      "Error decoding JSON for row 1330: Expecting property name enclosed in double quotes: line 71 column 30 (char 4121)\n",
      "Error decoding JSON for row 1332: Unterminated string starting at: line 79 column 5 (char 3941)\n",
      "Error decoding JSON for row 1359: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 1373: Expecting property name enclosed in double quotes: line 69 column 90 (char 3544)\n",
      "Error decoding JSON for row 1381: Expecting ',' delimiter: line 80 column 41 (char 3950)\n",
      "Error decoding JSON for row 1391: Unterminated string starting at: line 79 column 5 (char 4011)\n",
      "Error decoding JSON for row 1396: Unterminated string starting at: line 78 column 18 (char 4005)\n",
      "Error decoding JSON for row 1397: Expecting ',' delimiter: line 30 column 5 (char 1574)\n",
      "Error decoding JSON for row 1402: Expecting ',' delimiter: line 80 column 41 (char 3864)\n",
      "Error decoding JSON for row 1404: Unterminated string starting at: line 77 column 17 (char 4047)\n",
      "Error decoding JSON for row 1406: Unterminated string starting at: line 92 column 16 (char 3885)\n",
      "Error decoding JSON for row 1417: Expecting value: line 89 column 5 (char 4019)\n",
      "Error decoding JSON for row 1423: Unterminated string starting at: line 79 column 5 (char 4064)\n",
      "Error decoding JSON for row 1427: Unterminated string starting at: line 85 column 17 (char 3918)\n",
      "Error decoding JSON for row 1430: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 1432: Unterminated string starting at: line 86 column 5 (char 3990)\n",
      "Error decoding JSON for row 1437: Unterminated string starting at: line 86 column 18 (char 4056)\n",
      "Error decoding JSON for row 1439: Unterminated string starting at: line 70 column 18 (char 3945)\n",
      "Error decoding JSON for row 1440: Unterminated string starting at: line 86 column 18 (char 4011)\n",
      "Error decoding JSON for row 1445: Expecting property name enclosed in double quotes: line 3 column 9 (char 16)\n",
      "Error decoding JSON for row 1450: Expecting ',' delimiter: line 88 column 38 (char 4092)\n",
      "Error decoding JSON for row 1452: Expecting value: line 81 column 5 (char 3914)\n",
      "Error decoding JSON for row 1458: Unterminated string starting at: line 83 column 20 (char 4101)\n",
      "Error decoding JSON for row 1461: Unterminated string starting at: line 85 column 17 (char 3983)\n",
      "Error decoding JSON for row 1469: Expecting property name enclosed in double quotes: line 95 column 30 (char 3901)\n",
      "Error decoding JSON for row 1475: Expecting property name enclosed in double quotes: line 78 column 119 (char 4171)\n",
      "Error decoding JSON for row 1477: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 1481: Unterminated string starting at: line 87 column 5 (char 4054)\n",
      "Error decoding JSON for row 1486: Unterminated string starting at: line 86 column 18 (char 3831)\n",
      "Error decoding JSON for row 1491: Expecting value: line 80 column 36 (char 4113)\n",
      "Error decoding JSON for row 1494: Unterminated string starting at: line 84 column 16 (char 3905)\n",
      "Error decoding JSON for row 1495: Unterminated string starting at: line 83 column 20 (char 4081)\n",
      "Error decoding JSON for row 1513: Unterminated string starting at: line 78 column 5 (char 3852)\n",
      "Error decoding JSON for row 1518: Unterminated string starting at: line 78 column 5 (char 4177)\n",
      "Error decoding JSON for row 1524: Unterminated string starting at: line 93 column 17 (char 3891)\n",
      "Error decoding JSON for row 1525: Unterminated string starting at: line 78 column 18 (char 4163)\n",
      "Error decoding JSON for row 1527: Expecting property name enclosed in double quotes: line 74 column 4 (char 4011)\n",
      "Error decoding JSON for row 1534: Unterminated string starting at: line 86 column 18 (char 3843)\n",
      "Error decoding JSON for row 1535: Unterminated string starting at: line 84 column 16 (char 3997)\n",
      "Error decoding JSON for row 1536: Expecting value: line 77 column 16 (char 4149)\n",
      "Error decoding JSON for row 1543: Unterminated string starting at: line 84 column 5 (char 3372)\n",
      "Error decoding JSON for row 1544: Unterminated string starting at: line 87 column 5 (char 3909)\n",
      "Error decoding JSON for row 1545: Expecting ',' delimiter: line 12 column 51 (char 601)\n",
      "Error decoding JSON for row 1563: Unterminated string starting at: line 85 column 17 (char 3808)\n",
      "Error decoding JSON for row 1580: Unterminated string starting at: line 83 column 20 (char 3862)\n",
      "Error decoding JSON for row 1581: Unterminated string starting at: line 86 column 18 (char 4020)\n",
      "Error decoding JSON for row 1583: Expecting property name enclosed in double quotes: line 87 column 30 (char 3851)\n",
      "Error decoding JSON for row 1593: Unterminated string starting at: line 77 column 17 (char 4057)\n",
      "Error decoding JSON for row 1595: Expecting value: line 73 column 5 (char 4162)\n",
      "Error decoding JSON for row 1606: Expecting property name enclosed in double quotes: line 86 column 106 (char 3934)\n",
      "Error decoding JSON for row 1607: Unterminated string starting at: line 70 column 18 (char 4195)\n",
      "Error decoding JSON for row 1608: Expecting property name enclosed in double quotes: line 79 column 30 (char 4026)\n",
      "Error decoding JSON for row 1615: Expecting ',' delimiter: line 80 column 40 (char 4031)\n",
      "Error decoding JSON for row 1617: Expecting ',' delimiter: line 80 column 40 (char 3934)\n",
      "Error decoding JSON for row 1622: Unterminated string starting at: line 79 column 5 (char 4071)\n",
      "Error decoding JSON for row 1627: Unterminated string starting at: line 83 column 20 (char 3950)\n",
      "Error decoding JSON for row 1637: Unterminated string starting at: line 77 column 17 (char 4079)\n",
      "Error decoding JSON for row 1644: Unterminated string starting at: line 77 column 17 (char 3814)\n",
      "Error decoding JSON for row 1648: Expecting value: line 89 column 5 (char 3842)\n",
      "Error decoding JSON for row 1653: Unterminated string starting at: line 80 column 5 (char 3975)\n",
      "Error decoding JSON for row 1663: Unterminated string starting at: line 84 column 16 (char 4030)\n",
      "Error decoding JSON for row 1671: Unterminated string starting at: line 78 column 18 (char 4069)\n",
      "Error decoding JSON for row 1680: Expecting value: line 94 column 17 (char 3883)\n",
      "Error decoding JSON for row 1695: Expecting property name enclosed in double quotes: line 78 column 133 (char 4197)\n",
      "Error decoding JSON for row 1706: Expecting property name enclosed in double quotes: line 86 column 93 (char 3931)\n",
      "Error decoding JSON for row 1709: Unterminated string starting at: line 77 column 17 (char 4025)\n",
      "Error decoding JSON for row 1720: Unterminated string starting at: line 84 column 16 (char 3919)\n",
      "Error decoding JSON for row 1725: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 1733: Expecting ',' delimiter: line 71 column 27 (char 4288)\n",
      "Error decoding JSON for row 1747: Expecting property name enclosed in double quotes: line 78 column 106 (char 4165)\n",
      "Error decoding JSON for row 1752: Expecting value: line 80 column 36 (char 3990)\n",
      "Error decoding JSON for row 1770: Unterminated string starting at: line 83 column 5 (char 3854)\n",
      "Error decoding JSON for row 1780: Unterminated string starting at: line 91 column 20 (char 3858)\n",
      "Error decoding JSON for row 1786: Unterminated string starting at: line 85 column 17 (char 3917)\n",
      "Error decoding JSON for row 1812: Unterminated string starting at: line 84 column 16 (char 3965)\n",
      "Error decoding JSON for row 1823: Unterminated string starting at: line 86 column 18 (char 3764)\n",
      "Error decoding JSON for row 1839: Expecting property name enclosed in double quotes: line 79 column 31 (char 3964)\n",
      "Error decoding JSON for row 1852: Expecting property name enclosed in double quotes: line 3 column 9 (char 16)\n",
      "Error decoding JSON for row 1857: Unterminated string starting at: line 77 column 17 (char 3860)\n",
      "Error decoding JSON for row 1876: Expecting property name enclosed in double quotes: line 84 column 59 (char 3784)\n",
      "Error decoding JSON for row 1895: Unterminated string starting at: line 84 column 16 (char 3947)\n",
      "Error decoding JSON for row 1917: Expecting ',' delimiter: line 80 column 41 (char 4130)\n",
      "Error decoding JSON for row 1922: Extra data: line 45 column 1 (char 1924)\n",
      "Error decoding JSON for row 1936: Unterminated string starting at: line 80 column 5 (char 3995)\n",
      "Error decoding JSON for row 1977: Expecting ',' delimiter: line 80 column 38 (char 3957)\n",
      "Error decoding JSON for row 1985: Expecting value: line 72 column 36 (char 3403)\n",
      "Error decoding JSON for row 1987: Unterminated string starting at: line 85 column 21 (char 4227)\n",
      "Error decoding JSON for row 2006: Unterminated string starting at: line 84 column 16 (char 3747)\n",
      "Error decoding JSON for row 2012: Expecting ',' delimiter: line 88 column 41 (char 3836)\n",
      "Error decoding JSON for row 2033: Expecting property name enclosed in double quotes: line 82 column 4 (char 4146)\n",
      "Error decoding JSON for row 2040: Expecting value: line 85 column 16 (char 3760)\n",
      "Error decoding JSON for row 2058: Expecting value: line 79 column 25 (char 4311)\n",
      "Error decoding JSON for row 2075: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 2081: Unterminated string starting at: line 86 column 18 (char 4003)\n",
      "Error decoding JSON for row 2085: Unterminated string starting at: line 86 column 18 (char 3928)\n",
      "Error decoding JSON for row 2099: Unterminated string starting at: line 86 column 5 (char 3793)\n",
      "Error decoding JSON for row 2113: Expecting value: line 79 column 25 (char 3708)\n",
      "Error decoding JSON for row 2123: Unterminated string starting at: line 78 column 18 (char 4084)\n",
      "Error decoding JSON for row 2129: Unterminated string starting at: line 91 column 5 (char 3834)\n",
      "Error decoding JSON for row 2138: Unterminated string starting at: line 88 column 5 (char 4031)\n",
      "Error decoding JSON for row 2143: Expecting property name enclosed in double quotes: line 3 column 9 (char 16)\n",
      "Error decoding JSON for row 2150: Unterminated string starting at: line 85 column 17 (char 3966)\n",
      "Error decoding JSON for row 2151: Expecting property name enclosed in double quotes: line 71 column 31 (char 3914)\n",
      "Error decoding JSON for row 2152: Unterminated string starting at: line 76 column 16 (char 3430)\n",
      "Error decoding JSON for row 2156: Unterminated string starting at: line 76 column 20 (char 4085)\n",
      "Error decoding JSON for row 2186: Unterminated string starting at: line 71 column 5 (char 3478)\n",
      "Error decoding JSON for row 2191: Expecting property name enclosed in double quotes: line 91 column 35 (char 3481)\n",
      "Error decoding JSON for row 2193: Expecting property name enclosed in double quotes: line 69 column 113 (char 3578)\n",
      "Error decoding JSON for row 2204: Unterminated string starting at: line 83 column 24 (char 4216)\n",
      "Error decoding JSON for row 2209: Unterminated string starting at: line 84 column 16 (char 3793)\n",
      "Error decoding JSON for row 2227: Unterminated string starting at: line 84 column 16 (char 3894)\n",
      "Error decoding JSON for row 2229: Unterminated string starting at: line 83 column 20 (char 3989)\n",
      "Error decoding JSON for row 2240: Expecting ',' delimiter: line 88 column 40 (char 3911)\n",
      "Error decoding JSON for row 2270: Expecting value: line 93 column 16 (char 3790)\n",
      "Error decoding JSON for row 2284: Unterminated string starting at: line 92 column 16 (char 3838)\n",
      "Error decoding JSON for row 2288: Unterminated string starting at: line 85 column 5 (char 3845)\n",
      "Error decoding JSON for row 2320: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 2357: Unterminated string starting at: line 88 column 5 (char 3892)\n",
      "Error decoding JSON for row 2389: Unterminated string starting at: line 78 column 18 (char 3675)\n",
      "Error decoding JSON for row 2391: Expecting value: line 87 column 25 (char 3781)\n",
      "Error decoding JSON for row 2393: Expecting value: line 93 column 16 (char 3835)\n",
      "Error decoding JSON for row 2396: Unterminated string starting at: line 84 column 20 (char 4291)\n",
      "Error decoding JSON for row 2399: Unterminated string starting at: line 78 column 18 (char 3709)\n",
      "Error decoding JSON for row 2404: Expecting property name enclosed in double quotes: line 83 column 37 (char 4041)\n",
      "Error decoding JSON for row 2409: Unterminated string starting at: line 84 column 20 (char 4039)\n",
      "Error decoding JSON for row 2416: Unterminated string starting at: line 84 column 16 (char 4055)\n",
      "Error decoding JSON for row 2418: Expecting ',' delimiter: line 71 column 27 (char 4248)\n",
      "Error decoding JSON for row 2421: Unterminated string starting at: line 83 column 24 (char 4050)\n",
      "Error decoding JSON for row 2423: Unterminated string starting at: line 77 column 17 (char 3758)\n",
      "Error decoding JSON for row 2424: Unterminated string starting at: line 76 column 16 (char 3771)\n",
      "Error decoding JSON for row 2427: Unterminated string starting at: line 84 column 5 (char 4026)\n",
      "Error decoding JSON for row 2428: Unterminated string starting at: line 80 column 5 (char 3910)\n",
      "Error decoding JSON for row 2430: Unterminated string starting at: line 78 column 18 (char 3680)\n",
      "Error decoding JSON for row 2432: Unterminated string starting at: line 92 column 16 (char 3766)\n",
      "Error decoding JSON for row 2433: Expecting value: line 80 column 36 (char 3952)\n",
      "Error decoding JSON for row 2435: Expecting ',' delimiter: line 88 column 41 (char 4141)\n",
      "Error decoding JSON for row 2436: Expecting ',' delimiter: line 87 column 27 (char 4076)\n",
      "Error decoding JSON for row 2480: Extra data: line 21 column 1 (char 767)\n",
      "Error decoding JSON for row 2517: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 2558: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 2616: Expecting property name enclosed in double quotes: line 84 column 87 (char 4064)\n",
      "Error decoding JSON for row 2776: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 2814: Expecting property name enclosed in double quotes: line 11 column 40 (char 469)\n",
      "Error decoding JSON for row 2819: Unterminated string starting at: line 83 column 20 (char 3925)\n",
      "Error decoding JSON for row 2836: Unterminated string starting at: line 83 column 20 (char 3905)\n",
      "Error decoding JSON for row 2843: Unterminated string starting at: line 91 column 5 (char 3923)\n",
      "Error decoding JSON for row 2860: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 2861: Expecting property name enclosed in double quotes: line 71 column 31 (char 3818)\n",
      "Error decoding JSON for row 2865: Expecting ',' delimiter: line 87 column 27 (char 3597)\n",
      "Error decoding JSON for row 2898: Invalid control character at: line 30 column 78 (char 1462)\n",
      "Error decoding JSON for row 2902: Expecting value: line 81 column 5 (char 4175)\n",
      "Error decoding JSON for row 2906: Unterminated string starting at: line 80 column 5 (char 3511)\n",
      "Error decoding JSON for row 2911: Expecting value: line 78 column 17 (char 4290)\n",
      "Error decoding JSON for row 2918: Unterminated string starting at: line 93 column 5 (char 3875)\n",
      "Error decoding JSON for row 2920: Expecting ',' delimiter: line 87 column 29 (char 3945)\n",
      "Error decoding JSON for row 2922: Unterminated string starting at: line 75 column 20 (char 4135)\n",
      "Error decoding JSON for row 2929: Expecting value: line 88 column 36 (char 3809)\n",
      "Error decoding JSON for row 2930: Expecting ',' delimiter: line 80 column 41 (char 4116)\n",
      "Error decoding JSON for row 2943: Unterminated string starting at: line 80 column 5 (char 3798)\n",
      "Error decoding JSON for row 2948: Unterminated string starting at: line 88 column 5 (char 3732)\n",
      "Error decoding JSON for row 2957: Unterminated string starting at: line 77 column 17 (char 4076)\n",
      "Error decoding JSON for row 2961: Unterminated string starting at: line 80 column 5 (char 3971)\n",
      "Error decoding JSON for row 2967: Unterminated string starting at: line 84 column 16 (char 3928)\n",
      "Error decoding JSON for row 2969: Unterminated string starting at: line 80 column 5 (char 3827)\n",
      "Error decoding JSON for row 2970: Unterminated string starting at: line 75 column 20 (char 3780)\n",
      "Error decoding JSON for row 2972: Unterminated string starting at: line 86 column 5 (char 4106)\n",
      "Error decoding JSON for row 2994: Unterminated string starting at: line 76 column 16 (char 4131)\n",
      "Error decoding JSON for row 2998: Expecting property name enclosed in double quotes: line 85 column 74 (char 3912)\n",
      "Error decoding JSON for row 3009: Unterminated string starting at: line 80 column 5 (char 3990)\n",
      "Error decoding JSON for row 3016: Unterminated string starting at: line 78 column 18 (char 3892)\n",
      "Error decoding JSON for row 3021: Unterminated string starting at: line 84 column 16 (char 3729)\n",
      "Error decoding JSON for row 3027: Expecting value: line 83 column 19 (char 4037)\n",
      "Error decoding JSON for row 3031: Expecting value: line 86 column 17 (char 3904)\n",
      "Error decoding JSON for row 3035: Unterminated string starting at: line 75 column 20 (char 4025)\n",
      "Error decoding JSON for row 3037: Unterminated string starting at: line 93 column 17 (char 3702)\n",
      "Error decoding JSON for row 3038: Unterminated string starting at: line 70 column 5 (char 4307)\n",
      "Error decoding JSON for row 3057: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 3067: Unterminated string starting at: line 83 column 5 (char 3943)\n",
      "Error decoding JSON for row 3079: Expecting value: line 88 column 36 (char 3913)\n",
      "Error decoding JSON for row 3103: Unterminated string starting at: line 80 column 5 (char 3901)\n",
      "Error decoding JSON for row 3108: Unterminated string starting at: line 84 column 5 (char 3870)\n",
      "Error decoding JSON for row 3112: Expecting value: line 80 column 36 (char 3942)\n",
      "Error decoding JSON for row 3121: Expecting value: line 80 column 36 (char 4129)\n",
      "Error decoding JSON for row 3122: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 3124: Unterminated string starting at: line 78 column 18 (char 4051)\n",
      "Error decoding JSON for row 3125: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 3133: Invalid control character at: line 29 column 90 (char 1660)\n",
      "Error decoding JSON for row 3148: Unterminated string starting at: line 78 column 18 (char 3961)\n",
      "Error decoding JSON for row 3154: Expecting property name enclosed in double quotes: line 93 column 71 (char 3877)\n",
      "Error decoding JSON for row 3157: Unterminated string starting at: line 78 column 18 (char 3963)\n",
      "Error decoding JSON for row 3167: Unterminated string starting at: line 76 column 16 (char 3736)\n",
      "Error decoding JSON for row 3168: Unterminated string starting at: line 79 column 9 (char 4388)\n",
      "Error decoding JSON for row 3171: Expecting ',' delimiter: line 80 column 38 (char 4019)\n",
      "Error decoding JSON for row 3191: Unterminated string starting at: line 84 column 16 (char 3858)\n",
      "Error decoding JSON for row 3194: Unterminated string starting at: line 86 column 5 (char 3885)\n",
      "Error decoding JSON for row 3199: Unterminated string starting at: line 77 column 5 (char 3953)\n",
      "Error decoding JSON for row 3200: Unterminated string starting at: line 80 column 5 (char 3902)\n",
      "Error decoding JSON for row 3202: Unterminated string starting at: line 77 column 17 (char 4320)\n",
      "Error decoding JSON for row 3208: Unterminated string starting at: line 72 column 5 (char 3326)\n",
      "Error decoding JSON for row 3216: Unterminated string starting at: line 79 column 5 (char 4121)\n",
      "Error decoding JSON for row 3223: Unterminated string starting at: line 83 column 5 (char 3974)\n",
      "Error decoding JSON for row 3238: Unterminated string starting at: line 88 column 5 (char 3937)\n",
      "Error decoding JSON for row 3241: Unterminated string starting at: line 78 column 5 (char 4110)\n",
      "Error decoding JSON for row 3260: Unterminated string starting at: line 70 column 18 (char 4091)\n",
      "Error decoding JSON for row 3271: Unterminated string starting at: line 85 column 17 (char 3912)\n",
      "Error decoding JSON for row 3272: Unterminated string starting at: line 84 column 16 (char 4011)\n",
      "Error decoding JSON for row 3275: Unterminated string starting at: line 83 column 20 (char 3984)\n",
      "Error decoding JSON for row 3288: Unterminated string starting at: line 77 column 17 (char 3876)\n",
      "Error decoding JSON for row 3291: Expecting value: line 88 column 36 (char 3720)\n",
      "Error decoding JSON for row 3292: Expecting property name enclosed in double quotes: line 84 column 65 (char 3938)\n",
      "Error decoding JSON for row 3302: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 3311: Invalid control character at: line 45 column 93 (char 2178)\n",
      "Error decoding JSON for row 3317: Unterminated string starting at: line 88 column 5 (char 3845)\n",
      "Error decoding JSON for row 3335: Unterminated string starting at: line 79 column 5 (char 4241)\n",
      "Error decoding JSON for row 3345: Unterminated string starting at: line 84 column 16 (char 3906)\n",
      "Error decoding JSON for row 3347: Unterminated string starting at: line 77 column 17 (char 3785)\n",
      "Error decoding JSON for row 3356: Expecting ',' delimiter: line 72 column 40 (char 4219)\n",
      "Error decoding JSON for row 3359: Unterminated string starting at: line 77 column 17 (char 4071)\n",
      "Error decoding JSON for row 3370: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 3376: Expecting value: line 73 column 5 (char 4217)\n",
      "Error decoding JSON for row 3382: Expecting ',' delimiter: line 80 column 40 (char 4070)\n",
      "Error decoding JSON for row 3385: Expecting value: line 80 column 36 (char 3934)\n",
      "Error decoding JSON for row 3389: Unterminated string starting at: line 83 column 20 (char 3762)\n",
      "Error decoding JSON for row 3394: Expecting ',' delimiter: line 80 column 38 (char 3988)\n",
      "Error decoding JSON for row 3398: Unterminated string starting at: line 92 column 16 (char 3799)\n",
      "Error decoding JSON for row 3408: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 3418: Unterminated string starting at: line 77 column 17 (char 3914)\n",
      "Error decoding JSON for row 3420: Unterminated string starting at: line 80 column 5 (char 4074)\n",
      "Error decoding JSON for row 3422: Unterminated string starting at: line 77 column 21 (char 4172)\n",
      "Error decoding JSON for row 3425: Unterminated string starting at: line 78 column 18 (char 3919)\n",
      "Error decoding JSON for row 3438: Expecting ',' delimiter: line 80 column 38 (char 4112)\n",
      "Error decoding JSON for row 3447: Unterminated string starting at: line 86 column 18 (char 3881)\n",
      "Error decoding JSON for row 3450: Unterminated string starting at: line 91 column 20 (char 3577)\n",
      "Error decoding JSON for row 3452: Unterminated string starting at: line 84 column 5 (char 3899)\n",
      "Error decoding JSON for row 3453: Expecting property name enclosed in double quotes: line 77 column 112 (char 4085)\n",
      "Error decoding JSON for row 3454: Unterminated string starting at: line 77 column 17 (char 4038)\n",
      "Error decoding JSON for row 3477: Unterminated string starting at: line 77 column 5 (char 3832)\n",
      "Error decoding JSON for row 3478: Unterminated string starting at: line 94 column 18 (char 3879)\n",
      "Error decoding JSON for row 3480: Unterminated string starting at: line 78 column 18 (char 4067)\n",
      "Error decoding JSON for row 3486: Unterminated string starting at: line 84 column 16 (char 3773)\n",
      "Error decoding JSON for row 3489: Unterminated string starting at: line 77 column 17 (char 4117)\n",
      "Error decoding JSON for row 3490: Expecting property name enclosed in double quotes: line 79 column 31 (char 3842)\n",
      "Error decoding JSON for row 3495: Unterminated string starting at: line 77 column 17 (char 3941)\n",
      "Error decoding JSON for row 3496: Unterminated string starting at: line 86 column 18 (char 3804)\n",
      "Error decoding JSON for row 3501: Unterminated string starting at: line 85 column 17 (char 3882)\n",
      "Error decoding JSON for row 3511: Unterminated string starting at: line 86 column 18 (char 3962)\n",
      "Error decoding JSON for row 3512: Unterminated string starting at: line 85 column 17 (char 3508)\n",
      "Error decoding JSON for row 3517: Expecting value: line 79 column 25 (char 4001)\n",
      "Error decoding JSON for row 3520: Unterminated string starting at: line 88 column 5 (char 3999)\n",
      "Error decoding JSON for row 3521: Unterminated string starting at: line 85 column 5 (char 3944)\n",
      "Error decoding JSON for row 3524: Expecting value: line 84 column 15 (char 3983)\n",
      "Error decoding JSON for row 3530: Expecting property name enclosed in double quotes: line 76 column 63 (char 3467)\n",
      "Error decoding JSON for row 3540: Unterminated string starting at: line 85 column 17 (char 3913)\n",
      "Error decoding JSON for row 3550: Unterminated string starting at: line 84 column 16 (char 3939)\n",
      "Error decoding JSON for row 3555: Unterminated string starting at: line 94 column 18 (char 3907)\n",
      "Error decoding JSON for row 3563: Unterminated string starting at: line 78 column 18 (char 4129)\n",
      "Error decoding JSON for row 3572: Expecting property name enclosed in double quotes: line 92 column 55 (char 3834)\n",
      "Error decoding JSON for row 3589: Expecting value: line 95 column 25 (char 4001)\n",
      "Error decoding JSON for row 3590: Unterminated string starting at: line 77 column 17 (char 3991)\n",
      "Error decoding JSON for row 3593: Unterminated string starting at: line 84 column 16 (char 3909)\n",
      "Error decoding JSON for row 3602: Unterminated string starting at: line 80 column 5 (char 4103)\n",
      "Error decoding JSON for row 3605: Unterminated string starting at: line 83 column 5 (char 3959)\n",
      "Error decoding JSON for row 3607: Expecting value: line 83 column 19 (char 3936)\n",
      "Error decoding JSON for row 3609: Unterminated string starting at: line 84 column 16 (char 3928)\n",
      "Error decoding JSON for row 3616: Unterminated string starting at: line 86 column 18 (char 3764)\n",
      "Error decoding JSON for row 3617: Unterminated string starting at: line 69 column 17 (char 3461)\n",
      "Error decoding JSON for row 3627: Expecting property name enclosed in double quotes: line 91 column 35 (char 3845)\n",
      "Error decoding JSON for row 3628: Unterminated string starting at: line 92 column 16 (char 3895)\n",
      "Error decoding JSON for row 3636: Expecting property name enclosed in double quotes: line 90 column 4 (char 3952)\n",
      "Error decoding JSON for row 3642: Unterminated string starting at: line 83 column 20 (char 3904)\n",
      "Error decoding JSON for row 3650: Expecting ',' delimiter: line 79 column 27 (char 4107)\n",
      "Error decoding JSON for row 3653: Expecting value: line 72 column 36 (char 4174)\n",
      "Error decoding JSON for row 3666: Unterminated string starting at: line 80 column 5 (char 3964)\n",
      "Error decoding JSON for row 3668: Expecting value: line 81 column 5 (char 3926)\n",
      "Error decoding JSON for row 3680: Unterminated string starting at: line 85 column 17 (char 3770)\n",
      "Error decoding JSON for row 3688: Unterminated string starting at: line 68 column 16 (char 4087)\n",
      "Error decoding JSON for row 3699: Unterminated string starting at: line 77 column 17 (char 3945)\n",
      "Error decoding JSON for row 3700: Expecting property name enclosed in double quotes: line 79 column 30 (char 4104)\n",
      "Error decoding JSON for row 3704: Unterminated string starting at: line 86 column 18 (char 3794)\n",
      "Error decoding JSON for row 3714: Expecting value: line 83 column 19 (char 4015)\n",
      "Error decoding JSON for row 3716: Unterminated string starting at: line 84 column 16 (char 3973)\n",
      "Error decoding JSON for row 3732: Unterminated string starting at: line 78 column 18 (char 3914)\n",
      "Error decoding JSON for row 3734: Unterminated string starting at: line 78 column 18 (char 3989)\n",
      "Error decoding JSON for row 3735: Unterminated string starting at: line 80 column 5 (char 3823)\n",
      "Error decoding JSON for row 3737: Expecting value: line 88 column 40 (char 4065)\n",
      "Error decoding JSON for row 3741: Expecting ',' delimiter: line 87 column 27 (char 3894)\n",
      "Error decoding JSON for row 3750: Expecting ',' delimiter: line 80 column 40 (char 3995)\n",
      "Error decoding JSON for row 3753: Expecting property name enclosed in double quotes: line 77 column 131 (char 4082)\n",
      "Error decoding JSON for row 3760: Expecting value: line 89 column 5 (char 3937)\n",
      "Error decoding JSON for row 3776: Unterminated string starting at: line 84 column 16 (char 3861)\n",
      "Error decoding JSON for row 3778: Unterminated string starting at: line 85 column 17 (char 3736)\n",
      "Error decoding JSON for row 3789: Expecting ',' delimiter: line 80 column 40 (char 4096)\n",
      "Error decoding JSON for row 3794: Unterminated string starting at: line 85 column 17 (char 3755)\n",
      "Error decoding JSON for row 3809: Unterminated string starting at: line 85 column 17 (char 3899)\n",
      "Error decoding JSON for row 3822: Expecting ',' delimiter: line 71 column 27 (char 4089)\n",
      "Error decoding JSON for row 3823: Unterminated string starting at: line 84 column 16 (char 3896)\n",
      "Error decoding JSON for row 3824: Unterminated string starting at: line 88 column 5 (char 3839)\n",
      "Error decoding JSON for row 3831: Unterminated string starting at: line 85 column 17 (char 3843)\n",
      "Error decoding JSON for row 3836: Unterminated string starting at: line 85 column 17 (char 3903)\n",
      "Error decoding JSON for row 3840: Expecting ',' delimiter: line 80 column 38 (char 4015)\n",
      "Error decoding JSON for row 3850: Invalid control character at: line 68 column 80 (char 3425)\n",
      "Error decoding JSON for row 3853: Unterminated string starting at: line 85 column 17 (char 3856)\n",
      "Error decoding JSON for row 3861: Unterminated string starting at: line 78 column 18 (char 3946)\n",
      "Error decoding JSON for row 3863: Unterminated string starting at: line 76 column 16 (char 4087)\n",
      "Error decoding JSON for row 3867: Unterminated string starting at: line 83 column 9 (char 4257)\n",
      "Error decoding JSON for row 3873: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 3876: Unterminated string starting at: line 79 column 5 (char 4185)\n",
      "Error decoding JSON for row 3877: Expecting ',' delimiter: line 81 column 4 (char 4026)\n",
      "Error decoding JSON for row 3879: Unterminated string starting at: line 79 column 5 (char 4058)\n",
      "Error decoding JSON for row 3887: Unterminated string starting at: line 78 column 18 (char 3772)\n",
      "Error decoding JSON for row 3892: Expecting property name enclosed in double quotes: line 87 column 31 (char 3972)\n",
      "Error decoding JSON for row 3895: Expecting property name enclosed in double quotes: line 77 column 98 (char 4076)\n",
      "Error decoding JSON for row 3896: Expecting ',' delimiter: line 79 column 27 (char 3973)\n",
      "Error decoding JSON for row 3898: Expecting value: line 87 column 25 (char 3902)\n",
      "Error decoding JSON for row 3899: Unterminated string starting at: line 78 column 18 (char 4063)\n",
      "Error decoding JSON for row 3909: Expecting property name enclosed in double quotes: line 77 column 87 (char 4046)\n",
      "Error decoding JSON for row 3913: Unterminated string starting at: line 70 column 18 (char 4093)\n",
      "Error decoding JSON for row 3915: Unterminated string starting at: line 76 column 16 (char 3643)\n",
      "Error decoding JSON for row 3919: Unterminated string starting at: line 77 column 17 (char 3935)\n",
      "Error decoding JSON for row 3923: Expecting ',' delimiter: line 71 column 30 (char 4201)\n",
      "Error decoding JSON for row 3939: Expecting value: line 80 column 36 (char 4078)\n",
      "Error decoding JSON for row 3951: Unterminated string starting at: line 76 column 16 (char 4091)\n",
      "Error decoding JSON for row 3956: Unterminated string starting at: line 79 column 5 (char 4013)\n",
      "Error decoding JSON for row 3968: Unterminated string starting at: line 76 column 16 (char 3762)\n",
      "Error decoding JSON for row 3970: Unterminated string starting at: line 77 column 17 (char 4026)\n",
      "Error decoding JSON for row 3971: Unterminated string starting at: line 84 column 16 (char 3899)\n",
      "Error decoding JSON for row 3972: Unterminated string starting at: line 78 column 18 (char 3830)\n",
      "Error decoding JSON for row 3976: Expecting value: line 72 column 36 (char 4064)\n",
      "Error decoding JSON for row 3990: Expecting property name enclosed in double quotes: line 85 column 86 (char 3964)\n",
      "Error decoding JSON for row 3996: Expecting ',' delimiter: line 80 column 38 (char 3940)\n",
      "Error decoding JSON for row 4011: Expecting ',' delimiter: line 72 column 38 (char 3712)\n",
      "Error decoding JSON for row 4014: Unterminated string starting at: line 77 column 21 (char 4227)\n",
      "Error decoding JSON for row 4034: Unterminated string starting at: line 77 column 17 (char 4049)\n",
      "Error decoding JSON for row 4035: Expecting value: line 78 column 17 (char 3992)\n",
      "Error decoding JSON for row 4036: Unterminated string starting at: line 84 column 16 (char 3949)\n",
      "Error decoding JSON for row 4053: Unterminated string starting at: line 88 column 5 (char 3715)\n",
      "Error decoding JSON for row 4058: Expecting ',' delimiter: line 80 column 40 (char 4014)\n",
      "Error decoding JSON for row 4061: Expecting ',' delimiter: line 87 column 27 (char 3967)\n",
      "Error decoding JSON for row 4062: Unterminated string starting at: line 85 column 5 (char 3908)\n",
      "Error decoding JSON for row 4071: Unterminated string starting at: line 86 column 18 (char 3887)\n",
      "Error decoding JSON for row 4085: Unterminated string starting at: line 80 column 5 (char 3860)\n",
      "Error decoding JSON for row 4088: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 4095: Expecting ',' delimiter: line 79 column 29 (char 3929)\n",
      "Error decoding JSON for row 4097: Expecting property name enclosed in double quotes: line 79 column 30 (char 4058)\n",
      "Error decoding JSON for row 4102: Unterminated string starting at: line 78 column 18 (char 3849)\n",
      "Error decoding JSON for row 4104: Unterminated string starting at: line 76 column 16 (char 3860)\n",
      "Error decoding JSON for row 4115: Unterminated string starting at: line 78 column 22 (char 4255)\n",
      "Error decoding JSON for row 4116: Unterminated string starting at: line 85 column 5 (char 3951)\n",
      "Error decoding JSON for row 4118: Unterminated string starting at: line 78 column 18 (char 3880)\n",
      "Error decoding JSON for row 4122: Expecting ',' delimiter: line 87 column 27 (char 3766)\n",
      "Error decoding JSON for row 4142: Expecting value: line 72 column 36 (char 4024)\n",
      "Error decoding JSON for row 4144: Expecting ',' delimiter: line 80 column 38 (char 4106)\n",
      "Error decoding JSON for row 4152: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 4153: Unterminated string starting at: line 94 column 5 (char 3793)\n",
      "Error decoding JSON for row 4183: Expecting value: line 80 column 36 (char 4055)\n",
      "Error decoding JSON for row 4203: Unterminated string starting at: line 92 column 16 (char 3861)\n",
      "Error decoding JSON for row 4205: Expecting property name enclosed in double quotes: line 94 column 53 (char 3785)\n",
      "Error decoding JSON for row 4222: Unterminated string starting at: line 84 column 16 (char 3883)\n",
      "Error decoding JSON for row 4227: Expecting property name enclosed in double quotes: line 82 column 4 (char 3822)\n",
      "Error decoding JSON for row 4228: Unterminated string starting at: line 77 column 17 (char 4070)\n",
      "Error decoding JSON for row 4229: Unterminated string starting at: line 76 column 5 (char 3664)\n",
      "Error decoding JSON for row 4236: Unterminated string starting at: line 85 column 5 (char 3932)\n",
      "Error decoding JSON for row 4244: Unterminated string starting at: line 77 column 5 (char 4114)\n",
      "Error decoding JSON for row 4245: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 4247: Unterminated string starting at: line 78 column 18 (char 4091)\n",
      "Error decoding JSON for row 4250: Expecting ',' delimiter: line 88 column 38 (char 3915)\n",
      "Error decoding JSON for row 4265: Expecting property name enclosed in double quotes: line 77 column 105 (char 4219)\n",
      "Error decoding JSON for row 4269: Unterminated string starting at: line 77 column 17 (char 3954)\n",
      "Error decoding JSON for row 4271: Unterminated string starting at: line 77 column 17 (char 3982)\n",
      "Error decoding JSON for row 4274: Unterminated string starting at: line 86 column 18 (char 3924)\n",
      "Error decoding JSON for row 4275: Unterminated string starting at: line 84 column 16 (char 3923)\n",
      "Error decoding JSON for row 4276: Unterminated string starting at: line 76 column 16 (char 3998)\n",
      "Error decoding JSON for row 4279: Expecting ',' delimiter: line 87 column 27 (char 3911)\n",
      "Error decoding JSON for row 4287: Unterminated string starting at: line 78 column 5 (char 4031)\n",
      "Error decoding JSON for row 4290: Unterminated string starting at: line 70 column 18 (char 3628)\n",
      "Error decoding JSON for row 4291: Unterminated string starting at: line 86 column 5 (char 3709)\n",
      "Error decoding JSON for row 4296: Expecting ',' delimiter: line 80 column 40 (char 4164)\n",
      "Error decoding JSON for row 4297: Unterminated string starting at: line 88 column 5 (char 3951)\n",
      "Error decoding JSON for row 4301: Unterminated string starting at: line 78 column 18 (char 3930)\n",
      "Error decoding JSON for row 4309: Unterminated string starting at: line 76 column 5 (char 4046)\n",
      "Error decoding JSON for row 4311: Unterminated string starting at: line 76 column 16 (char 3934)\n",
      "Error decoding JSON for row 4312: Unterminated string starting at: line 72 column 5 (char 3833)\n",
      "Error decoding JSON for row 4315: Unterminated string starting at: line 99 column 5 (char 3621)\n",
      "Error decoding JSON for row 4317: Unterminated string starting at: line 77 column 17 (char 3807)\n",
      "Error decoding JSON for row 4322: Unterminated string starting at: line 83 column 20 (char 3990)\n",
      "Error decoding JSON for row 4323: Expecting ',' delimiter: line 31 column 5 (char 1557)\n",
      "Error decoding JSON for row 4326: Unterminated string starting at: line 85 column 17 (char 3892)\n",
      "Error decoding JSON for row 4336: Unterminated string starting at: line 67 column 5 (char 3741)\n",
      "Error decoding JSON for row 4339: Unterminated string starting at: line 80 column 5 (char 3957)\n",
      "Error decoding JSON for row 4340: Unterminated string starting at: line 77 column 17 (char 4023)\n",
      "Error decoding JSON for row 4345: Unterminated string starting at: line 78 column 18 (char 3895)\n",
      "Error decoding JSON for row 4349: Unterminated string starting at: line 76 column 5 (char 3952)\n",
      "Error decoding JSON for row 4351: Unterminated string starting at: line 85 column 5 (char 3671)\n",
      "Error decoding JSON for row 4355: Expecting property name enclosed in double quotes: line 78 column 123 (char 3986)\n",
      "Error decoding JSON for row 4362: Unterminated string starting at: line 77 column 21 (char 3808)\n",
      "Error decoding JSON for row 4368: Unterminated string starting at: line 77 column 17 (char 4047)\n",
      "Error decoding JSON for row 4384: Unterminated string starting at: line 78 column 18 (char 3873)\n",
      "Error decoding JSON for row 4385: Unterminated string starting at: line 72 column 5 (char 4024)\n",
      "Error decoding JSON for row 4387: Expecting property name enclosed in double quotes: line 85 column 92 (char 3740)\n",
      "Error decoding JSON for row 4388: Unterminated string starting at: line 78 column 18 (char 3694)\n",
      "Error decoding JSON for row 4389: Unterminated string starting at: line 87 column 5 (char 3786)\n",
      "Error decoding JSON for row 4390: Expecting ',' delimiter: line 79 column 27 (char 3642)\n",
      "Error decoding JSON for row 4403: Expecting property name enclosed in double quotes: line 82 column 4 (char 3915)\n",
      "Error decoding JSON for row 4412: Expecting property name enclosed in double quotes: line 77 column 114 (char 4309)\n",
      "Error decoding JSON for row 4418: Unterminated string starting at: line 80 column 5 (char 3806)\n",
      "Error decoding JSON for row 4420: Unterminated string starting at: line 85 column 5 (char 4019)\n",
      "Error decoding JSON for row 4425: Unterminated string starting at: line 92 column 16 (char 3787)\n",
      "Error decoding JSON for row 4430: Unterminated string starting at: line 64 column 5 (char 3425)\n",
      "Error decoding JSON for row 4439: Unterminated string starting at: line 78 column 18 (char 3922)\n",
      "Error decoding JSON for row 4440: Expecting value: line 84 column 15 (char 3943)\n",
      "Error decoding JSON for row 4456: Unterminated string starting at: line 68 column 16 (char 3768)\n",
      "Error decoding JSON for row 4461: Expecting value: line 75 column 19 (char 3995)\n",
      "Error decoding JSON for row 4462: Unterminated string starting at: line 85 column 17 (char 3839)\n",
      "Error decoding JSON for row 4464: Expecting property name enclosed in double quotes: line 79 column 30 (char 3669)\n",
      "Error decoding JSON for row 4467: Expecting ',' delimiter: line 72 column 40 (char 4209)\n",
      "Error decoding JSON for row 4469: Extra data: line 45 column 1 (char 1772)\n",
      "Error decoding JSON for row 4479: Unterminated string starting at: line 71 column 5 (char 3834)\n",
      "Error decoding JSON for row 4484: Expecting ',' delimiter: line 30 column 106 (char 1705)\n",
      "Error decoding JSON for row 4487: Expecting property name enclosed in double quotes: line 75 column 40 (char 4103)\n",
      "Error decoding JSON for row 4498: Unterminated string starting at: line 78 column 18 (char 4004)\n",
      "Error decoding JSON for row 4504: Expecting value: line 80 column 36 (char 3993)\n",
      "Error decoding JSON for row 4505: Unterminated string starting at: line 77 column 17 (char 3782)\n",
      "Error decoding JSON for row 4507: Expecting ',' delimiter: line 80 column 38 (char 3871)\n",
      "Error decoding JSON for row 4509: Unterminated string starting at: line 78 column 18 (char 3876)\n",
      "Error decoding JSON for row 4511: Unterminated string starting at: line 88 column 5 (char 3880)\n",
      "Error decoding JSON for row 4514: Expecting property name enclosed in double quotes: line 78 column 96 (char 3838)\n",
      "Error decoding JSON for row 4515: Unterminated string starting at: line 86 column 5 (char 3926)\n",
      "Error decoding JSON for row 4524: Invalid control character at: line 12 column 18 (char 453)\n",
      "Error decoding JSON for row 4546: Unterminated string starting at: line 85 column 17 (char 3837)\n",
      "Error decoding JSON for row 4550: Expecting ',' delimiter: line 72 column 41 (char 4010)\n",
      "Error decoding JSON for row 4551: Unterminated string starting at: line 78 column 18 (char 3977)\n",
      "Error decoding JSON for row 4556: Unterminated string starting at: line 78 column 5 (char 4117)\n",
      "Error decoding JSON for row 4560: Unterminated string starting at: line 78 column 5 (char 3937)\n",
      "Error decoding JSON for row 4574: Unterminated string starting at: line 83 column 20 (char 4020)\n",
      "Error decoding JSON for row 4577: Unterminated string starting at: line 84 column 16 (char 3911)\n",
      "Error decoding JSON for row 4578: Expecting value: line 80 column 36 (char 3996)\n",
      "Error decoding JSON for row 4580: Unterminated string starting at: line 77 column 17 (char 3953)\n",
      "Error decoding JSON for row 4584: Expecting value: line 78 column 17 (char 3324)\n",
      "Error decoding JSON for row 4585: Unterminated string starting at: line 75 column 20 (char 3879)\n",
      "Error decoding JSON for row 4591: Unterminated string starting at: line 86 column 18 (char 3812)\n",
      "Error decoding JSON for row 4594: Unterminated string starting at: line 91 column 20 (char 3634)\n",
      "Error decoding JSON for row 4600: Expecting property name enclosed in double quotes: line 78 column 80 (char 4005)\n",
      "Error decoding JSON for row 4603: Expecting ',' delimiter: line 88 column 41 (char 3801)\n",
      "Error decoding JSON for row 4609: Expecting property name enclosed in double quotes: line 77 column 72 (char 4161)\n",
      "Error decoding JSON for row 4616: Unterminated string starting at: line 86 column 18 (char 3821)\n",
      "Error decoding JSON for row 4618: Unterminated string starting at: line 85 column 17 (char 4106)\n",
      "Error decoding JSON for row 4626: Expecting ',' delimiter: line 72 column 40 (char 3911)\n",
      "Error decoding JSON for row 4630: Unterminated string starting at: line 83 column 5 (char 3932)\n",
      "Error decoding JSON for row 4631: Unterminated string starting at: line 67 column 20 (char 3600)\n",
      "Error decoding JSON for row 4632: Expecting ',' delimiter: line 18 column 1 (char 915)\n",
      "Error decoding JSON for row 4647: Invalid control character at: line 28 column 18 (char 1743)\n",
      "Error decoding JSON for row 4650: Unterminated string starting at: line 86 column 18 (char 3878)\n",
      "Error decoding JSON for row 4652: Expecting property name enclosed in double quotes: line 82 column 4 (char 3963)\n",
      "Error decoding JSON for row 4654: Expecting property name enclosed in double quotes: line 82 column 4 (char 3869)\n",
      "Error decoding JSON for row 4656: Expecting ',' delimiter: line 87 column 27 (char 3888)\n",
      "Error decoding JSON for row 4665: Unterminated string starting at: line 78 column 18 (char 4094)\n",
      "Error decoding JSON for row 4673: Expecting ',' delimiter: line 79 column 30 (char 3573)\n",
      "Error decoding JSON for row 4676: Unterminated string starting at: line 68 column 16 (char 3573)\n",
      "Error decoding JSON for row 4683: Expecting property name enclosed in double quotes: line 90 column 4 (char 3786)\n",
      "Error decoding JSON for row 4685: Expecting property name enclosed in double quotes: line 78 column 99 (char 3890)\n",
      "Error decoding JSON for row 4690: Unterminated string starting at: line 84 column 5 (char 3866)\n",
      "Error decoding JSON for row 4691: Unterminated string starting at: line 93 column 17 (char 3792)\n",
      "Error decoding JSON for row 4692: Expecting property name enclosed in double quotes: line 86 column 93 (char 3839)\n",
      "Error decoding JSON for row 4693: Expecting property name enclosed in double quotes: line 82 column 4 (char 3873)\n",
      "Error decoding JSON for row 4696: Unterminated string starting at: line 94 column 18 (char 3789)\n",
      "Error decoding JSON for row 4704: Unterminated string starting at: line 86 column 18 (char 3944)\n",
      "Error decoding JSON for row 4709: Unterminated string starting at: line 70 column 18 (char 3906)\n",
      "Error decoding JSON for row 4716: Unterminated string starting at: line 80 column 5 (char 4055)\n",
      "Error decoding JSON for row 4724: Unterminated string starting at: line 86 column 18 (char 3949)\n",
      "Error decoding JSON for row 4727: Unterminated string starting at: line 77 column 17 (char 4084)\n",
      "Error decoding JSON for row 4730: Unterminated string starting at: line 76 column 16 (char 3907)\n",
      "Error decoding JSON for row 4745: Unterminated string starting at: line 77 column 5 (char 3934)\n",
      "Error decoding JSON for row 4748: Expecting value: line 86 column 17 (char 4042)\n",
      "Error decoding JSON for row 4751: Unterminated string starting at: line 77 column 17 (char 3890)\n",
      "Error decoding JSON for row 4765: Unterminated string starting at: line 84 column 16 (char 3954)\n",
      "Error decoding JSON for row 4770: Unterminated string starting at: line 86 column 18 (char 3737)\n",
      "Error decoding JSON for row 4773: Unterminated string starting at: line 78 column 18 (char 3925)\n",
      "Error decoding JSON for row 4777: Unterminated string starting at: line 85 column 21 (char 4195)\n",
      "Error decoding JSON for row 4779: Expecting value: line 81 column 5 (char 4095)\n",
      "Error decoding JSON for row 4782: Expecting value: line 81 column 5 (char 3938)\n",
      "Error decoding JSON for row 4784: Expecting property name enclosed in double quotes: line 83 column 38 (char 3831)\n",
      "Error decoding JSON for row 4785: Unterminated string starting at: line 93 column 5 (char 3754)\n",
      "Error decoding JSON for row 4787: Expecting value: line 81 column 5 (char 3792)\n",
      "Error decoding JSON for row 4789: Unterminated string starting at: line 83 column 5 (char 4111)\n",
      "Error decoding JSON for row 4792: Expecting value: line 97 column 5 (char 3618)\n",
      "Error decoding JSON for row 4793: Unterminated string starting at: line 78 column 5 (char 4153)\n",
      "Error decoding JSON for row 4795: Unterminated string starting at: line 84 column 5 (char 3931)\n",
      "Error decoding JSON for row 4800: Unterminated string starting at: line 94 column 18 (char 3533)\n",
      "Error decoding JSON for row 4801: Unterminated string starting at: line 85 column 17 (char 3904)\n",
      "Error decoding JSON for row 4805: Unterminated string starting at: line 77 column 17 (char 4014)\n",
      "Error decoding JSON for row 4806: Unterminated string starting at: line 85 column 17 (char 3716)\n",
      "Error decoding JSON for row 4811: Unterminated string starting at: line 91 column 5 (char 4084)\n",
      "Error decoding JSON for row 4814: Invalid control character at: line 37 column 72 (char 1586)\n",
      "Error decoding JSON for row 4816: Unterminated string starting at: line 79 column 5 (char 4048)\n",
      "Error decoding JSON for row 4817: Unterminated string starting at: line 91 column 20 (char 3699)\n",
      "Error decoding JSON for row 4818: Unterminated string starting at: line 78 column 18 (char 4089)\n",
      "Error decoding JSON for row 4820: Expecting ',' delimiter: line 15 column 5 (char 766)\n",
      "Error decoding JSON for row 4822: Expecting value: line 88 column 36 (char 3937)\n",
      "Error decoding JSON for row 4826: Unterminated string starting at: line 77 column 17 (char 3819)\n",
      "Error decoding JSON for row 4831: Unterminated string starting at: line 84 column 16 (char 4115)\n",
      "Error decoding JSON for row 4832: Unterminated string starting at: line 94 column 18 (char 3818)\n",
      "Error decoding JSON for row 4836: Expecting property name enclosed in double quotes: line 86 column 86 (char 3863)\n",
      "Error decoding JSON for row 4843: Unterminated string starting at: line 80 column 5 (char 3818)\n",
      "Error decoding JSON for row 4847: Expecting value: line 80 column 36 (char 3955)\n",
      "Error decoding JSON for row 4853: Expecting property name enclosed in double quotes: line 95 column 31 (char 3892)\n",
      "Error decoding JSON for row 4855: Unterminated string starting at: line 91 column 24 (char 4099)\n",
      "Error decoding JSON for row 4856: Expecting value: line 81 column 5 (char 3904)\n",
      "Error decoding JSON for row 4861: Unterminated string starting at: line 78 column 5 (char 3709)\n",
      "Error decoding JSON for row 4867: Expecting ',' delimiter: line 81 column 4 (char 3999)\n",
      "Error decoding JSON for row 4868: Unterminated string starting at: line 86 column 18 (char 3865)\n",
      "Error decoding JSON for row 4873: Unterminated string starting at: line 85 column 17 (char 3780)\n",
      "Error decoding JSON for row 4880: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 4882: Unterminated string starting at: line 88 column 5 (char 3874)\n",
      "Error decoding JSON for row 4894: Unterminated string starting at: line 84 column 5 (char 4002)\n",
      "Error decoding JSON for row 4895: Unterminated string starting at: line 77 column 5 (char 4013)\n",
      "Error decoding JSON for row 4902: Expecting ',' delimiter: line 81 column 4 (char 3879)\n",
      "Error decoding JSON for row 4909: Expecting value: line 80 column 36 (char 3937)\n",
      "Error decoding JSON for row 4910: Unterminated string starting at: line 84 column 16 (char 3819)\n",
      "Error decoding JSON for row 4911: Expecting property name enclosed in double quotes: line 90 column 4 (char 3987)\n",
      "Error decoding JSON for row 4912: Unterminated string starting at: line 83 column 5 (char 4032)\n",
      "Error decoding JSON for row 4917: Unterminated string starting at: line 84 column 16 (char 3907)\n",
      "Error decoding JSON for row 4923: Expecting value: line 72 column 36 (char 4133)\n",
      "Error decoding JSON for row 4936: Expecting property name enclosed in double quotes: line 85 column 61 (char 3869)\n",
      "Error decoding JSON for row 4943: Unterminated string starting at: line 77 column 17 (char 3748)\n",
      "Error decoding JSON for row 4949: Unterminated string starting at: line 86 column 18 (char 4156)\n",
      "Error decoding JSON for row 4950: Unterminated string starting at: line 88 column 5 (char 3708)\n",
      "Error decoding JSON for row 4954: Unterminated string starting at: line 84 column 16 (char 4023)\n",
      "Error decoding JSON for row 4955: Unterminated string starting at: line 78 column 18 (char 3991)\n",
      "Error decoding JSON for row 4958: Expecting property name enclosed in double quotes: line 86 column 78 (char 3698)\n",
      "Error decoding JSON for row 4961: Expecting ',' delimiter: line 72 column 40 (char 3962)\n",
      "Error decoding JSON for row 4962: Unterminated string starting at: line 80 column 5 (char 4227)\n",
      "Error decoding JSON for row 4964: Unterminated string starting at: line 78 column 18 (char 3949)\n",
      "Error decoding JSON for row 4965: Expecting property name enclosed in double quotes: line 85 column 68 (char 3798)\n",
      "Error decoding JSON for row 4967: Expecting value: line 81 column 5 (char 3872)\n",
      "Error decoding JSON for row 4971: Unterminated string starting at: line 84 column 16 (char 3920)\n",
      "Error decoding JSON for row 4973: Unterminated string starting at: line 95 column 5 (char 3760)\n",
      "Error decoding JSON for row 4974: Expecting property name enclosed in double quotes: line 77 column 85 (char 3840)\n",
      "Error decoding JSON for row 4978: Unterminated string starting at: line 76 column 16 (char 4055)\n",
      "Error decoding JSON for row 4980: Expecting ',' delimiter: line 87 column 27 (char 3842)\n",
      "Error decoding JSON for row 4986: Unterminated string starting at: line 85 column 17 (char 3803)\n",
      "Error decoding JSON for row 4990: Unterminated string starting at: line 77 column 17 (char 3879)\n",
      "Error decoding JSON for row 4992: Expecting property name enclosed in double quotes: line 11 column 52 (char 481)\n",
      "Error decoding JSON for row 5004: Unterminated string starting at: line 79 column 5 (char 3990)\n",
      "Error decoding JSON for row 5006: Unterminated string starting at: line 77 column 5 (char 4096)\n",
      "Error decoding JSON for row 5007: Expecting ',' delimiter: line 80 column 40 (char 3743)\n",
      "Error decoding JSON for row 5010: Expecting ',' delimiter: line 72 column 40 (char 3521)\n",
      "Error decoding JSON for row 5011: Unterminated string starting at: line 86 column 22 (char 4183)\n",
      "Error decoding JSON for row 5014: Expecting value: line 88 column 36 (char 3864)\n",
      "Error decoding JSON for row 5019: Unterminated string starting at: line 85 column 17 (char 3856)\n",
      "Error decoding JSON for row 5020: Unterminated string starting at: line 77 column 17 (char 3804)\n",
      "Error decoding JSON for row 5021: Unterminated string starting at: line 85 column 17 (char 3666)\n",
      "Error decoding JSON for row 5027: Unterminated string starting at: line 93 column 17 (char 3661)\n",
      "Error decoding JSON for row 5030: Unterminated string starting at: line 83 column 20 (char 3622)\n",
      "Error decoding JSON for row 5047: Expecting value: line 79 column 25 (char 4097)\n",
      "Error decoding JSON for row 5057: Unterminated string starting at: line 72 column 5 (char 4035)\n",
      "Error decoding JSON for row 5058: Unterminated string starting at: line 79 column 5 (char 4197)\n",
      "Error decoding JSON for row 5059: Unterminated string starting at: line 86 column 18 (char 3709)\n",
      "Error decoding JSON for row 5066: Unterminated string starting at: line 76 column 16 (char 4051)\n",
      "Error decoding JSON for row 5067: Unterminated string starting at: line 77 column 17 (char 3915)\n",
      "Error decoding JSON for row 5068: Unterminated string starting at: line 83 column 20 (char 3960)\n",
      "Error decoding JSON for row 5071: Expecting value: line 81 column 5 (char 3939)\n",
      "Error decoding JSON for row 5072: Expecting property name enclosed in double quotes: line 83 column 37 (char 3916)\n",
      "Error decoding JSON for row 5080: Expecting property name enclosed in double quotes: line 77 column 103 (char 4252)\n",
      "Error decoding JSON for row 5081: Expecting property name enclosed in double quotes: line 68 column 99 (char 3726)\n",
      "Error decoding JSON for row 5106: Unterminated string starting at: line 71 column 5 (char 3661)\n",
      "Error decoding JSON for row 5108: Unterminated string starting at: line 75 column 20 (char 3995)\n",
      "Error decoding JSON for row 5111: Expecting ',' delimiter: line 80 column 40 (char 3983)\n",
      "Error decoding JSON for row 5118: Unterminated string starting at: line 76 column 16 (char 3962)\n",
      "Error decoding JSON for row 5119: Unterminated string starting at: line 76 column 16 (char 4103)\n",
      "Error decoding JSON for row 5124: Expecting property name enclosed in double quotes: line 77 column 90 (char 4082)\n",
      "Error decoding JSON for row 5127: Expecting value: line 88 column 36 (char 3898)\n",
      "Error decoding JSON for row 5128: Unterminated string starting at: line 84 column 16 (char 3893)\n",
      "Error decoding JSON for row 5130: Unterminated string starting at: line 63 column 5 (char 4310)\n",
      "Error decoding JSON for row 5132: Expecting ',' delimiter: line 72 column 38 (char 4078)\n",
      "Error decoding JSON for row 5133: Unterminated string starting at: line 86 column 18 (char 3795)\n",
      "Error decoding JSON for row 5134: Unterminated string starting at: line 78 column 18 (char 4103)\n",
      "Error decoding JSON for row 5135: Expecting ',' delimiter: line 88 column 40 (char 3852)\n",
      "Error decoding JSON for row 5139: Unterminated string starting at: line 79 column 5 (char 3781)\n",
      "Error decoding JSON for row 5144: Unterminated string starting at: line 86 column 18 (char 3910)\n",
      "Error decoding JSON for row 5147: Unterminated string starting at: line 77 column 17 (char 3790)\n",
      "Error decoding JSON for row 5149: Unterminated string starting at: line 78 column 18 (char 4015)\n",
      "Error decoding JSON for row 5153: Unterminated string starting at: line 84 column 16 (char 3977)\n",
      "Error decoding JSON for row 5157: Unterminated string starting at: line 87 column 9 (char 4166)\n",
      "Error decoding JSON for row 5159: Expecting value: line 83 column 19 (char 3964)\n",
      "Error decoding JSON for row 5160: Unterminated string starting at: line 85 column 17 (char 3663)\n",
      "Error decoding JSON for row 5161: Unterminated string starting at: line 78 column 18 (char 4005)\n",
      "Error decoding JSON for row 5162: Expecting property name enclosed in double quotes: line 74 column 4 (char 4132)\n",
      "Error decoding JSON for row 5165: Unterminated string starting at: line 78 column 18 (char 3962)\n",
      "Error decoding JSON for row 5167: Unterminated string starting at: line 77 column 17 (char 4184)\n",
      "Error decoding JSON for row 5173: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 5175: Unterminated string starting at: line 85 column 5 (char 3733)\n",
      "Error decoding JSON for row 5180: Unterminated string starting at: line 85 column 17 (char 3909)\n",
      "Error decoding JSON for row 5182: Unterminated string starting at: line 84 column 16 (char 3902)\n",
      "Error decoding JSON for row 5184: Unterminated string starting at: line 85 column 17 (char 3941)\n",
      "Error decoding JSON for row 5185: Expecting ',' delimiter: line 79 column 27 (char 4145)\n",
      "Error decoding JSON for row 5186: Expecting value: line 81 column 5 (char 3940)\n",
      "Error decoding JSON for row 5187: Unterminated string starting at: line 78 column 5 (char 4074)\n",
      "Error decoding JSON for row 5188: Invalid control character at: line 38 column 92 (char 2164)\n",
      "Error decoding JSON for row 5190: Unterminated string starting at: line 78 column 18 (char 3977)\n",
      "Error decoding JSON for row 5191: Unterminated string starting at: line 68 column 16 (char 4156)\n",
      "Error decoding JSON for row 5192: Unterminated string starting at: line 86 column 18 (char 3877)\n",
      "Error decoding JSON for row 5193: Expecting property name enclosed in double quotes: line 71 column 31 (char 3770)\n",
      "Error decoding JSON for row 5195: Unterminated string starting at: line 86 column 18 (char 3740)\n",
      "Error decoding JSON for row 5198: Unterminated string starting at: line 84 column 5 (char 3800)\n",
      "Error decoding JSON for row 5201: Unterminated string starting at: line 83 column 20 (char 4015)\n",
      "Error decoding JSON for row 5202: Expecting ',' delimiter: line 72 column 41 (char 3911)\n",
      "Error decoding JSON for row 5206: Expecting value: line 78 column 17 (char 3994)\n",
      "Error decoding JSON for row 5208: Expecting value: line 96 column 36 (char 4090)\n",
      "Error decoding JSON for row 5209: Unterminated string starting at: line 84 column 16 (char 3823)\n",
      "Error decoding JSON for row 5210: Unterminated string starting at: line 92 column 16 (char 3709)\n",
      "Error decoding JSON for row 5212: Expecting value: line 87 column 25 (char 3837)\n",
      "Error decoding JSON for row 5213: Expecting property name enclosed in double quotes: line 87 column 31 (char 3898)\n",
      "Error decoding JSON for row 5214: Expecting value: line 80 column 36 (char 4127)\n",
      "Error decoding JSON for row 5215: Unterminated string starting at: line 84 column 9 (char 3867)\n",
      "Error decoding JSON for row 5216: Expecting property name enclosed in double quotes: line 77 column 84 (char 3929)\n",
      "Error decoding JSON for row 5217: Unterminated string starting at: line 88 column 5 (char 3872)\n",
      "Error decoding JSON for row 5218: Expecting value: line 73 column 5 (char 4096)\n",
      "Error decoding JSON for row 5219: Unterminated string starting at: line 84 column 16 (char 3934)\n",
      "Error decoding JSON for row 5220: Unterminated string starting at: line 84 column 16 (char 3980)\n",
      "Error decoding JSON for row 5221: Unterminated string starting at: line 84 column 16 (char 3704)\n",
      "Error decoding JSON for row 5225: Unterminated string starting at: line 86 column 18 (char 3877)\n",
      "Error decoding JSON for row 5226: Expecting value: line 75 column 19 (char 4015)\n",
      "Error decoding JSON for row 5229: Expecting property name enclosed in double quotes: line 95 column 31 (char 3706)\n",
      "Error decoding JSON for row 5231: Unterminated string starting at: line 83 column 24 (char 4292)\n",
      "Error decoding JSON for row 5232: Unterminated string starting at: line 83 column 20 (char 3906)\n",
      "Error decoding JSON for row 5234: Expecting value: line 75 column 19 (char 3883)\n",
      "Error decoding JSON for row 5236: Unterminated string starting at: line 69 column 17 (char 4186)\n",
      "Error decoding JSON for row 5238: Unterminated string starting at: line 85 column 5 (char 3961)\n",
      "Error decoding JSON for row 5241: Unterminated string starting at: line 85 column 17 (char 3907)\n",
      "Error decoding JSON for row 5244: Unterminated string starting at: line 86 column 18 (char 3669)\n",
      "Error decoding JSON for row 5442: Expecting ',' delimiter: line 80 column 38 (char 4081)\n",
      "Error decoding JSON for row 5476: Expecting value: line 72 column 36 (char 4055)\n",
      "Error decoding JSON for row 5487: Unterminated string starting at: line 83 column 5 (char 4084)\n",
      "Error decoding JSON for row 5497: Unterminated string starting at: line 78 column 22 (char 4282)\n",
      "Error decoding JSON for row 5508: Unterminated string starting at: line 77 column 17 (char 3640)\n",
      "Error decoding JSON for row 5509: Unterminated string starting at: line 78 column 18 (char 3805)\n",
      "Error decoding JSON for row 5516: Unterminated string starting at: line 76 column 16 (char 3886)\n",
      "Error decoding JSON for row 5519: Expecting ',' delimiter: line 88 column 38 (char 3917)\n",
      "Error decoding JSON for row 5520: Unterminated string starting at: line 85 column 21 (char 4087)\n",
      "Error decoding JSON for row 5527: Unterminated string starting at: line 75 column 20 (char 4116)\n",
      "Error decoding JSON for row 5528: Unterminated string starting at: line 86 column 18 (char 3883)\n",
      "Error decoding JSON for row 5535: Unterminated string starting at: line 78 column 18 (char 3982)\n",
      "Error decoding JSON for row 5541: Unterminated string starting at: line 85 column 17 (char 3916)\n",
      "Error decoding JSON for row 5550: Expecting value: line 84 column 15 (char 4041)\n",
      "Error decoding JSON for row 5559: Unterminated string starting at: line 67 column 20 (char 3451)\n",
      "Error decoding JSON for row 5576: Unterminated string starting at: line 86 column 5 (char 3883)\n",
      "Error decoding JSON for row 5579: Unterminated string starting at: line 78 column 5 (char 3962)\n",
      "Error decoding JSON for row 5580: Unterminated string starting at: line 70 column 18 (char 4047)\n",
      "Error decoding JSON for row 5584: Expecting value: line 80 column 36 (char 4042)\n",
      "Error decoding JSON for row 5589: Expecting property name enclosed in double quotes: line 83 column 36 (char 3906)\n",
      "Error decoding JSON for row 5590: Unterminated string starting at: line 85 column 17 (char 3750)\n",
      "Error decoding JSON for row 5592: Expecting value: line 80 column 36 (char 3924)\n",
      "Error decoding JSON for row 5597: Unterminated string starting at: line 85 column 17 (char 3885)\n",
      "Error decoding JSON for row 5598: Unterminated string starting at: line 86 column 18 (char 3905)\n",
      "Error decoding JSON for row 5611: Expecting ',' delimiter: line 80 column 40 (char 3829)\n",
      "Error decoding JSON for row 5613: Expecting value: line 81 column 5 (char 3902)\n",
      "Error decoding JSON for row 5622: Unterminated string starting at: line 84 column 16 (char 3811)\n",
      "Error decoding JSON for row 5626: Expecting ',' delimiter: line 73 column 4 (char 4074)\n",
      "Error decoding JSON for row 5627: Expecting property name enclosed in double quotes: line 76 column 95 (char 4073)\n",
      "Error decoding JSON for row 5629: Unterminated string starting at: line 84 column 9 (char 4234)\n",
      "Error decoding JSON for row 5630: Expecting ',' delimiter: line 79 column 27 (char 3984)\n",
      "Error decoding JSON for row 5634: Expecting ',' delimiter: line 72 column 38 (char 4141)\n",
      "Error decoding JSON for row 5638: Unterminated string starting at: line 85 column 17 (char 3816)\n",
      "Error decoding JSON for row 5640: Expecting property name enclosed in double quotes: line 82 column 4 (char 3859)\n",
      "Error decoding JSON for row 5649: Unterminated string starting at: line 84 column 16 (char 3937)\n",
      "Error decoding JSON for row 5650: Unterminated string starting at: line 88 column 5 (char 3730)\n",
      "Error decoding JSON for row 5651: Unterminated string starting at: line 78 column 18 (char 4025)\n",
      "Error decoding JSON for row 5653: Unterminated string starting at: line 78 column 18 (char 4247)\n",
      "Error decoding JSON for row 5655: Unterminated string starting at: line 85 column 17 (char 3911)\n",
      "Error decoding JSON for row 5656: Unterminated string starting at: line 78 column 18 (char 3956)\n",
      "Error decoding JSON for row 5657: Unterminated string starting at: line 84 column 16 (char 3867)\n",
      "Error decoding JSON for row 5658: Unterminated string starting at: line 84 column 16 (char 3891)\n",
      "Error decoding JSON for row 5659: Expecting value: line 73 column 5 (char 4102)\n",
      "Error decoding JSON for row 5662: Unterminated string starting at: line 85 column 17 (char 3910)\n",
      "Error decoding JSON for row 5663: Unterminated string starting at: line 76 column 5 (char 4113)\n",
      "Error decoding JSON for row 5665: Unterminated string starting at: line 91 column 5 (char 3767)\n",
      "Error decoding JSON for row 5667: Expecting value: line 79 column 25 (char 4025)\n",
      "Error decoding JSON for row 5671: Expecting property name enclosed in double quotes: line 87 column 30 (char 3716)\n",
      "Error decoding JSON for row 5673: Unterminated string starting at: line 78 column 18 (char 3870)\n",
      "Error decoding JSON for row 5675: Unterminated string starting at: line 83 column 20 (char 3830)\n",
      "Error decoding JSON for row 5676: Expecting ',' delimiter: line 80 column 41 (char 4028)\n",
      "Error decoding JSON for row 5684: Unterminated string starting at: line 77 column 17 (char 3865)\n",
      "Error decoding JSON for row 5687: Unterminated string starting at: line 88 column 5 (char 4050)\n",
      "Error decoding JSON for row 5691: Expecting value: line 88 column 36 (char 3938)\n",
      "Error decoding JSON for row 5693: Unterminated string starting at: line 76 column 16 (char 3936)\n",
      "Error decoding JSON for row 5696: Unterminated string starting at: line 92 column 16 (char 3792)\n",
      "Error decoding JSON for row 5697: Unterminated string starting at: line 91 column 20 (char 3851)\n",
      "Error decoding JSON for row 5698: Unterminated string starting at: line 85 column 17 (char 3811)\n",
      "Error decoding JSON for row 5699: Expecting property name enclosed in double quotes: line 71 column 30 (char 4242)\n",
      "Error decoding JSON for row 5701: Unterminated string starting at: line 92 column 16 (char 3762)\n",
      "Error decoding JSON for row 5702: Unterminated string starting at: line 80 column 5 (char 3720)\n",
      "Error decoding JSON for row 5704: Unterminated string starting at: line 86 column 18 (char 3857)\n",
      "Error decoding JSON for row 5708: Unterminated string starting at: line 85 column 5 (char 3306)\n",
      "Error decoding JSON for row 5709: Unterminated string starting at: line 78 column 18 (char 4042)\n",
      "Error decoding JSON for row 5716: Unterminated string starting at: line 79 column 5 (char 4086)\n",
      "Error decoding JSON for row 5717: Unterminated string starting at: line 75 column 5 (char 3979)\n",
      "Error decoding JSON for row 5718: Expecting property name enclosed in double quotes: line 82 column 4 (char 3852)\n",
      "Error decoding JSON for row 5719: Expecting property name enclosed in double quotes: line 71 column 30 (char 4102)\n",
      "Error decoding JSON for row 5721: Expecting ',' delimiter: line 87 column 27 (char 3881)\n",
      "Error decoding JSON for row 5724: Expecting ',' delimiter: line 80 column 45 (char 4306)\n",
      "Error decoding JSON for row 5727: Unterminated string starting at: line 84 column 16 (char 3737)\n",
      "Error decoding JSON for row 5730: Unterminated string starting at: line 78 column 18 (char 3878)\n",
      "Error decoding JSON for row 5738: Expecting property name enclosed in double quotes: line 77 column 118 (char 4053)\n",
      "Error decoding JSON for row 5739: Expecting ',' delimiter: line 72 column 41 (char 3992)\n",
      "Error decoding JSON for row 5742: Expecting property name enclosed in double quotes: line 77 column 107 (char 4095)\n",
      "Error decoding JSON for row 5744: Unterminated string starting at: line 77 column 17 (char 3736)\n",
      "Error decoding JSON for row 5749: Unterminated string starting at: line 75 column 20 (char 4022)\n",
      "Error decoding JSON for row 5751: Expecting property name enclosed in double quotes: line 87 column 30 (char 3938)\n",
      "Error decoding JSON for row 5754: Unterminated string starting at: line 68 column 16 (char 4029)\n",
      "Error decoding JSON for row 5756: Unterminated string starting at: line 88 column 5 (char 3897)\n",
      "Error decoding JSON for row 5757: Unterminated string starting at: line 84 column 16 (char 3818)\n",
      "Error decoding JSON for row 5758: Unterminated string starting at: line 85 column 17 (char 3939)\n",
      "Error decoding JSON for row 5761: Unterminated string starting at: line 87 column 5 (char 3928)\n",
      "Error decoding JSON for row 5764: Expecting value: line 83 column 19 (char 4043)\n",
      "Error decoding JSON for row 5766: Unterminated string starting at: line 76 column 16 (char 4143)\n",
      "Error decoding JSON for row 5767: Unterminated string starting at: line 71 column 5 (char 3327)\n",
      "Error decoding JSON for row 5768: Expecting property name enclosed in double quotes: line 79 column 30 (char 3935)\n",
      "Error decoding JSON for row 5772: Unterminated string starting at: line 85 column 17 (char 3947)\n",
      "Error decoding JSON for row 5774: Unterminated string starting at: line 84 column 5 (char 3991)\n",
      "Error decoding JSON for row 5775: Unterminated string starting at: line 91 column 20 (char 3886)\n",
      "Error decoding JSON for row 5784: Expecting property name enclosed in double quotes: line 79 column 30 (char 4012)\n",
      "Error decoding JSON for row 5786: Unterminated string starting at: line 88 column 5 (char 3841)\n",
      "Error decoding JSON for row 5793: Unterminated string starting at: line 94 column 18 (char 3682)\n",
      "Error decoding JSON for row 5794: Unterminated string starting at: line 84 column 16 (char 3873)\n",
      "Error decoding JSON for row 5796: Expecting property name enclosed in double quotes: line 74 column 4 (char 3978)\n",
      "Error decoding JSON for row 5800: Unterminated string starting at: line 70 column 18 (char 3784)\n",
      "Error decoding JSON for row 5807: Expecting property name enclosed in double quotes: line 87 column 30 (char 3891)\n",
      "Error decoding JSON for row 5812: Expecting ',' delimiter: line 87 column 27 (char 3887)\n",
      "Error decoding JSON for row 5814: Unterminated string starting at: line 91 column 20 (char 3768)\n",
      "Error decoding JSON for row 5815: Unterminated string starting at: line 84 column 16 (char 3770)\n",
      "Error decoding JSON for row 5820: Unterminated string starting at: line 78 column 18 (char 3980)\n",
      "Error decoding JSON for row 5823: Expecting value: line 83 column 19 (char 4094)\n",
      "Error decoding JSON for row 5826: Unterminated string starting at: line 83 column 20 (char 4010)\n",
      "Error decoding JSON for row 5831: Unterminated string starting at: line 88 column 5 (char 3844)\n",
      "Error decoding JSON for row 5833: Expecting value: line 77 column 16 (char 4024)\n",
      "Error decoding JSON for row 5840: Expecting ',' delimiter: line 88 column 38 (char 3783)\n",
      "Error decoding JSON for row 5844: Expecting property name enclosed in double quotes: line 85 column 79 (char 3861)\n",
      "Error decoding JSON for row 5846: Unterminated string starting at: line 85 column 17 (char 3693)\n",
      "Error decoding JSON for row 5854: Unterminated string starting at: line 86 column 18 (char 3805)\n",
      "Error decoding JSON for row 5855: Expecting property name enclosed in double quotes: line 82 column 4 (char 3747)\n",
      "Error decoding JSON for row 5856: Expecting ',' delimiter: line 72 column 38 (char 4118)\n",
      "Error decoding JSON for row 5862: Unterminated string starting at: line 94 column 18 (char 3743)\n",
      "Error decoding JSON for row 5878: Unterminated string starting at: line 83 column 20 (char 3952)\n",
      "Error decoding JSON for row 5884: Expecting property name enclosed in double quotes: line 68 column 126 (char 4024)\n",
      "Error decoding JSON for row 5889: Unterminated string starting at: line 78 column 18 (char 3869)\n",
      "Error decoding JSON for row 5890: Expecting value: line 88 column 36 (char 3818)\n",
      "Error decoding JSON for row 5892: Expecting property name enclosed in double quotes: line 74 column 4 (char 4071)\n",
      "Error decoding JSON for row 5897: Unterminated string starting at: line 86 column 18 (char 3779)\n",
      "Error decoding JSON for row 5900: Unterminated string starting at: line 76 column 16 (char 3875)\n",
      "Error decoding JSON for row 5905: Expecting ',' delimiter: line 72 column 38 (char 4048)\n",
      "Error decoding JSON for row 5906: Unterminated string starting at: line 78 column 18 (char 3894)\n",
      "Error decoding JSON for row 5914: Unterminated string starting at: line 70 column 18 (char 4164)\n",
      "Error decoding JSON for row 5919: Unterminated string starting at: line 72 column 5 (char 3943)\n",
      "Error decoding JSON for row 5920: Expecting property name enclosed in double quotes: line 85 column 84 (char 3960)\n",
      "Error decoding JSON for row 5922: Expecting ',' delimiter: line 80 column 41 (char 3936)\n",
      "Error decoding JSON for row 5926: Unterminated string starting at: line 75 column 20 (char 3656)\n",
      "Error decoding JSON for row 5932: Unterminated string starting at: line 85 column 5 (char 4069)\n",
      "Error decoding JSON for row 5939: Unterminated string starting at: line 77 column 5 (char 4042)\n",
      "Error decoding JSON for row 5941: Unterminated string starting at: line 76 column 16 (char 4043)\n",
      "Error decoding JSON for row 5942: Unterminated string starting at: line 85 column 21 (char 4130)\n",
      "Error decoding JSON for row 5947: Unterminated string starting at: line 88 column 5 (char 3964)\n",
      "Error decoding JSON for row 5951: Expecting property name enclosed in double quotes: line 79 column 31 (char 3829)\n",
      "Error decoding JSON for row 5955: Unterminated string starting at: line 85 column 17 (char 3847)\n",
      "Error decoding JSON for row 5958: Expecting value: line 83 column 19 (char 4013)\n",
      "Error decoding JSON for row 5959: Unterminated string starting at: line 84 column 16 (char 3368)\n",
      "Error decoding JSON for row 5962: Unterminated string starting at: line 85 column 17 (char 3907)\n",
      "Error decoding JSON for row 5968: Unterminated string starting at: line 76 column 16 (char 3957)\n",
      "Error decoding JSON for row 5993: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 5998: Expecting ',' delimiter: line 80 column 41 (char 3924)\n",
      "Error decoding JSON for row 6002: Unterminated string starting at: line 92 column 5 (char 3702)\n",
      "Error decoding JSON for row 6010: Unterminated string starting at: line 91 column 20 (char 3827)\n",
      "Error decoding JSON for row 6017: Unterminated string starting at: line 85 column 17 (char 3930)\n",
      "Error decoding JSON for row 6021: Unterminated string starting at: line 88 column 5 (char 3868)\n",
      "Error decoding JSON for row 6035: Unterminated string starting at: line 78 column 18 (char 3985)\n",
      "Error decoding JSON for row 6042: Unterminated string starting at: line 78 column 18 (char 3926)\n",
      "Error decoding JSON for row 6043: Unterminated string starting at: line 80 column 5 (char 3894)\n",
      "Error decoding JSON for row 6053: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 6054: Expecting value: line 87 column 25 (char 3865)\n",
      "Error decoding JSON for row 6056: Unterminated string starting at: line 78 column 18 (char 3961)\n",
      "Error decoding JSON for row 6058: Unterminated string starting at: line 84 column 16 (char 3976)\n",
      "Error decoding JSON for row 6061: Unterminated string starting at: line 93 column 17 (char 3897)\n",
      "Error decoding JSON for row 6065: Unterminated string starting at: line 76 column 16 (char 4122)\n",
      "Error decoding JSON for row 6074: Unterminated string starting at: line 69 column 17 (char 3911)\n",
      "Error decoding JSON for row 6078: Unterminated string starting at: line 86 column 18 (char 3926)\n",
      "Error decoding JSON for row 6083: Unterminated string starting at: line 93 column 17 (char 3828)\n",
      "Error decoding JSON for row 6087: Expecting ',' delimiter: line 87 column 29 (char 4003)\n",
      "Error decoding JSON for row 6103: Expecting value: line 80 column 36 (char 4050)\n",
      "Error decoding JSON for row 6105: Unterminated string starting at: line 84 column 20 (char 4199)\n",
      "Error decoding JSON for row 6110: Expecting ',' delimiter: line 79 column 27 (char 3973)\n",
      "Error decoding JSON for row 6111: Expecting ',' delimiter: line 88 column 40 (char 3795)\n",
      "Error decoding JSON for row 6114: Unterminated string starting at: line 77 column 17 (char 3932)\n",
      "Error decoding JSON for row 6116: Unterminated string starting at: line 83 column 20 (char 3927)\n",
      "Error decoding JSON for row 6118: Expecting ',' delimiter: line 79 column 27 (char 3972)\n",
      "Error decoding JSON for row 6123: Unterminated string starting at: line 77 column 5 (char 4048)\n",
      "Error decoding JSON for row 6129: Unterminated string starting at: line 70 column 18 (char 4013)\n",
      "Error decoding JSON for row 6134: Expecting property name enclosed in double quotes: line 84 column 65 (char 3930)\n",
      "Error decoding JSON for row 6137: Expecting property name enclosed in double quotes: line 85 column 76 (char 4016)\n",
      "Error decoding JSON for row 6143: Unterminated string starting at: line 78 column 18 (char 3867)\n",
      "Error decoding JSON for row 6145: Expecting ',' delimiter: line 87 column 29 (char 3695)\n",
      "Error decoding JSON for row 6146: Unterminated string starting at: line 75 column 20 (char 4032)\n",
      "Error decoding JSON for row 6147: Unterminated string starting at: line 76 column 5 (char 4090)\n",
      "Error decoding JSON for row 6157: Unterminated string starting at: line 85 column 17 (char 3862)\n",
      "Error decoding JSON for row 6160: Expecting property name enclosed in double quotes: line 75 column 41 (char 3990)\n",
      "Error decoding JSON for row 6171: Unterminated string starting at: line 84 column 20 (char 4218)\n",
      "Error decoding JSON for row 6172: Unterminated string starting at: line 69 column 17 (char 3620)\n",
      "Error decoding JSON for row 6177: Unterminated string starting at: line 72 column 5 (char 4168)\n",
      "Error decoding JSON for row 6181: Expecting ',' delimiter: line 46 column 5 (char 2073)\n",
      "Error decoding JSON for row 6183: Unterminated string starting at: line 77 column 17 (char 3979)\n",
      "Error decoding JSON for row 6185: Unterminated string starting at: line 85 column 17 (char 3790)\n",
      "Error decoding JSON for row 6188: Unterminated string starting at: line 88 column 5 (char 3898)\n",
      "Error decoding JSON for row 6194: Unterminated string starting at: line 86 column 18 (char 3861)\n",
      "Error decoding JSON for row 6195: Unterminated string starting at: line 86 column 18 (char 3797)\n",
      "Error decoding JSON for row 6196: Expecting ',' delimiter: line 80 column 40 (char 3965)\n",
      "Error decoding JSON for row 6203: Unterminated string starting at: line 80 column 5 (char 4025)\n",
      "Error decoding JSON for row 6204: Expecting property name enclosed in double quotes: line 85 column 90 (char 3847)\n",
      "Error decoding JSON for row 6209: Expecting ',' delimiter: line 80 column 41 (char 3879)\n",
      "Error decoding JSON for row 6210: Expecting property name enclosed in double quotes: line 84 column 82 (char 4170)\n",
      "Error decoding JSON for row 6219: Expecting property name enclosed in double quotes: line 86 column 89 (char 4002)\n",
      "Error decoding JSON for row 6225: Unterminated string starting at: line 92 column 5 (char 3945)\n",
      "Error decoding JSON for row 6226: Unterminated string starting at: line 70 column 22 (char 4217)\n",
      "Error decoding JSON for row 6234: Unterminated string starting at: line 77 column 17 (char 3989)\n",
      "Error decoding JSON for row 6235: Unterminated string starting at: line 83 column 20 (char 3897)\n",
      "Error decoding JSON for row 6237: Unterminated string starting at: line 79 column 5 (char 3928)\n",
      "Error decoding JSON for row 6238: Unterminated string starting at: line 85 column 17 (char 3802)\n",
      "Error decoding JSON for row 6239: Expecting ',' delimiter: line 88 column 40 (char 3948)\n",
      "Error decoding JSON for row 6240: Unterminated string starting at: line 92 column 16 (char 3673)\n",
      "Error decoding JSON for row 6245: Expecting property name enclosed in double quotes: line 69 column 117 (char 4163)\n",
      "Error decoding JSON for row 6247: Unterminated string starting at: line 79 column 5 (char 4045)\n",
      "Error decoding JSON for row 6248: Expecting ',' delimiter: line 79 column 29 (char 3951)\n",
      "Error decoding JSON for row 6249: Unterminated string starting at: line 92 column 16 (char 3675)\n",
      "Error decoding JSON for row 6251: Unterminated string starting at: line 78 column 5 (char 4079)\n",
      "Error decoding JSON for row 6256: Expecting ',' delimiter: line 88 column 41 (char 3849)\n",
      "Error decoding JSON for row 6257: Expecting ',' delimiter: line 79 column 27 (char 4003)\n",
      "Error decoding JSON for row 6265: Expecting value: line 80 column 36 (char 4137)\n",
      "Error decoding JSON for row 6268: Expecting value: line 80 column 36 (char 4131)\n",
      "Error decoding JSON for row 6269: Unterminated string starting at: line 86 column 18 (char 3829)\n",
      "Error decoding JSON for row 6273: Unterminated string starting at: line 76 column 16 (char 3758)\n",
      "Error decoding JSON for row 6276: Unterminated string starting at: line 77 column 17 (char 3888)\n",
      "Error decoding JSON for row 6280: Unterminated string starting at: line 72 column 5 (char 4169)\n",
      "Error decoding JSON for row 6281: Unterminated string starting at: line 87 column 5 (char 3767)\n",
      "Error decoding JSON for row 6282: Expecting property name enclosed in double quotes: line 82 column 4 (char 3842)\n",
      "Error decoding JSON for row 6284: Unterminated string starting at: line 80 column 5 (char 4093)\n",
      "Error decoding JSON for row 6285: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Error decoding JSON for row 6289: Unterminated string starting at: line 68 column 16 (char 3519)\n",
      "Error decoding JSON for row 6292: Expecting value: line 87 column 25 (char 3842)\n",
      "Error decoding JSON for row 6293: Expecting ',' delimiter: line 80 column 41 (char 4010)\n",
      "Error decoding JSON for row 6296: Expecting value: line 81 column 5 (char 3993)\n",
      "Error decoding JSON for row 6297: Unterminated string starting at: line 86 column 18 (char 4072)\n",
      "Error decoding JSON for row 6300: Unterminated string starting at: line 86 column 18 (char 3874)\n",
      "Error decoding JSON for row 6302: Expecting ',' delimiter: line 88 column 38 (char 3844)\n",
      "Error decoding JSON for row 6303: Unterminated string starting at: line 78 column 18 (char 3948)\n",
      "Error decoding JSON for row 6306: Expecting property name enclosed in double quotes: line 78 column 114 (char 3970)\n",
      "Error decoding JSON for row 6307: Unterminated string starting at: line 92 column 16 (char 3756)\n",
      "Error decoding JSON for row 6310: Unterminated string starting at: line 76 column 16 (char 4026)\n",
      "Error decoding JSON for row 6313: Expecting value: line 85 column 16 (char 4162)\n",
      "Error decoding JSON for row 6314: Expecting value: line 73 column 5 (char 4274)\n",
      "Error decoding JSON for row 6316: Unterminated string starting at: line 93 column 17 (char 3805)\n",
      "Error decoding JSON for row 6318: Expecting property name enclosed in double quotes: line 86 column 92 (char 3901)\n",
      "Error decoding JSON for row 6320: Unterminated string starting at: line 78 column 18 (char 3938)\n",
      "Error decoding JSON for row 6322: Unterminated string starting at: line 87 column 5 (char 3797)\n",
      "Error decoding JSON for row 6327: Unterminated string starting at: line 70 column 9 (char 3602)\n",
      "Error decoding JSON for row 6329: Expecting value: line 80 column 36 (char 3922)\n",
      "Error decoding JSON for row 6331: Unterminated string starting at: line 84 column 16 (char 3796)\n",
      "Error decoding JSON for row 6334: Unterminated string starting at: line 85 column 21 (char 4281)\n",
      "Processed CSV saved at: /Users/hemantg/Desktop/processed_output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the CSV\n",
    "input_file = '/Users/hemantg/Downloads/combined_output1.csv'  # Replace with the actual file path\n",
    "df = pd.read_csv(input_file, sep=',')\n",
    "\n",
    "# Inspect columns\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# Initialize a list to store processed rows\n",
    "processed_rows = []\n",
    "\n",
    "# Process each row\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        date = row['date']\n",
    "        processed_results = row['processed_results']\n",
    "\n",
    "        # Ensure the value is not empty\n",
    "        if pd.notna(processed_results) and processed_results.strip():\n",
    "            # Clean and fix the JSON format\n",
    "            cleaned_json = (\n",
    "                processed_results.strip()\n",
    "                .replace(\"```json\", \"\")\n",
    "                .replace(\"```\", \"\")\n",
    "                .replace('\"\"', '\"')  # Fix incorrect quotes\n",
    "                .strip()\n",
    "            )\n",
    "\n",
    "            # Parse JSON\n",
    "            players_data = json.loads(cleaned_json)\n",
    "            row_data = {'date': date}\n",
    "\n",
    "            # Extract player information\n",
    "            for i, player in enumerate(players_data):\n",
    "                row_data[f'player{i+1}_name'] = player['player_name']\n",
    "                row_data[f'player{i+1}_output'] = json.dumps(player)\n",
    "\n",
    "            processed_rows.append(row_data)\n",
    "        else:\n",
    "            print(f\"Empty or invalid processed_results at row {index}\")\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON for row {index}: {e}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing column: {e}\")\n",
    "\n",
    "# Create a new DataFrame\n",
    "output_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Save to a new CSV file\n",
    "output_file = '/Users/hemantg/Desktop/processed_output.csv'\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Processed CSV saved at: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['date', 'original_text', 'processed_results'], dtype='object')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Extract player information\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, player \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(players_data):\n\u001b[0;32m---> 47\u001b[0m     row_data[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mplayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mplayer_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     48\u001b[0m     row_data[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_output\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(player)\n\u001b[1;32m     50\u001b[0m processed_rows\u001b[38;5;241m.\u001b[39mappend(row_data)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Load the CSV\n",
    "input_file = '/Users/hemantg/Desktop/try-combined-output.csv'  # Replace with the actual file path\n",
    "df = pd.read_csv(input_file, sep=',')\n",
    "\n",
    "# Inspect columns\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# Initialize a list to store processed rows\n",
    "processed_rows = []\n",
    "\n",
    "# Function to clean JSON\n",
    "def clean_json_string(json_string):\n",
    "    cleaned = (\n",
    "        json_string.strip()\n",
    "        .replace(\"```json\", \"\")\n",
    "        .replace(\"```\", \"\")\n",
    "        .replace(\"“\", '\"')  # Smart quotes to standard\n",
    "        .replace(\"”\", '\"')\n",
    "        .replace(\"‘\", \"'\")\n",
    "        .replace(\"’\", \"'\")\n",
    "        .replace(\"'\", '\"')  # Fix single quotes\n",
    "    )\n",
    "    # Remove any non-JSON text outside braces\n",
    "    cleaned = re.sub(r'^[^{]*|[^}]*$', '', cleaned, flags=re.DOTALL)\n",
    "    return cleaned\n",
    "\n",
    "# Process each row\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        date = row['date']\n",
    "        processed_results = row['processed_results']\n",
    "\n",
    "        # Ensure the value is not empty\n",
    "        if pd.notna(processed_results) and processed_results.strip():\n",
    "            cleaned_json = clean_json_string(processed_results)\n",
    "\n",
    "            # Parse JSON\n",
    "            players_data = json.loads(cleaned_json)\n",
    "            row_data = {'date': date}\n",
    "\n",
    "            # Extract player information\n",
    "            for i, player in enumerate(players_data):\n",
    "                row_data[f'player{i+1}_name'] = player['player_name']\n",
    "                row_data[f'player{i+1}_output'] = json.dumps(player)\n",
    "\n",
    "            processed_rows.append(row_data)\n",
    "        else:\n",
    "            print(f\"Empty or invalid processed_results at row {index}\")\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON for row {index}: {e}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing column: {e}\")\n",
    "\n",
    "# Create a new DataFrame\n",
    "output_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Save to a new CSV file\n",
    "output_file = '/Users/hemantg/Desktop/try-processed_output.csv'\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Processed CSV saved at: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['date', 'original_text', 'processed_results'], dtype='object')\n",
      "Error decoding JSON for row 2: Expecting ',' delimiter: line 6 column 85 (char 346)\n",
      "Error decoding JSON for row 12: Expecting ',' delimiter: line 5 column 137 (char 270)\n",
      "Error decoding JSON for row 14: Expecting ',' delimiter: line 5 column 85 (char 256)\n",
      "Error decoding JSON for row 16: Expecting ',' delimiter: line 4 column 53 (char 94)\n",
      "Error decoding JSON for row 17: Expecting ',' delimiter: line 14 column 38 (char 825)\n",
      "Error decoding JSON for row 30: Expecting ',' delimiter: line 22 column 59 (char 1177)\n",
      "Error decoding JSON for row 32: Expecting ',' delimiter: line 21 column 151 (char 1407)\n",
      "Error decoding JSON for row 33: Expecting ',' delimiter: line 6 column 49 (char 365)\n",
      "Error decoding JSON for row 36: Expecting ',' delimiter: line 6 column 33 (char 286)\n",
      "Error decoding JSON for row 37: Expecting ',' delimiter: line 5 column 88 (char 191)\n",
      "Error decoding JSON for row 38: Expecting ',' delimiter: line 14 column 121 (char 966)\n",
      "Error decoding JSON for row 45: Expecting ',' delimiter: line 6 column 50 (char 330)\n",
      "Error decoding JSON for row 47: Expecting ',' delimiter: line 6 column 52 (char 335)\n",
      "Error decoding JSON for row 50: Expecting ',' delimiter: line 13 column 125 (char 733)\n",
      "Error decoding JSON for row 52: Expecting ',' delimiter: line 5 column 56 (char 200)\n",
      "Error decoding JSON for row 54: Expecting ',' delimiter: line 12 column 134 (char 735)\n",
      "Error decoding JSON for row 56: Expecting ',' delimiter: line 12 column 83 (char 716)\n",
      "Error decoding JSON for row 66: Expecting ',' delimiter: line 20 column 63 (char 1030)\n",
      "Error decoding JSON for row 69: Expecting ',' delimiter: line 13 column 109 (char 759)\n",
      "Error decoding JSON for row 77: Expecting ',' delimiter: line 4 column 62 (char 104)\n",
      "Error decoding JSON for row 78: Expecting ',' delimiter: line 6 column 140 (char 452)\n",
      "Error decoding JSON for row 82: Expecting ',' delimiter: line 22 column 63 (char 1267)\n",
      "Error decoding JSON for row 85: Expecting ',' delimiter: line 21 column 69 (char 1105)\n",
      "Error decoding JSON for row 86: Expecting ',' delimiter: line 21 column 125 (char 1269)\n",
      "Error decoding JSON for row 87: Expecting ',' delimiter: line 4 column 33 (char 80)\n",
      "Error decoding JSON for row 91: Expecting ',' delimiter: line 5 column 75 (char 204)\n",
      "Error decoding JSON for row 92: Expecting ',' delimiter: line 4 column 43 (char 84)\n",
      "Error decoding JSON for row 94: Expecting ',' delimiter: line 29 column 66 (char 1337)\n",
      "Error decoding JSON for row 96: Expecting ',' delimiter: line 13 column 129 (char 750)\n",
      "Error decoding JSON for row 98: Expecting ',' delimiter: line 12 column 57 (char 532)\n",
      "Processed CSV saved at: /Users/hemantg/Desktop/try-processed_output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Load the CSV\n",
    "input_file = '/Users/hemantg/Desktop/try-combined-output.csv'  # Replace with the actual file path\n",
    "df = pd.read_csv(input_file, sep=',')\n",
    "\n",
    "# Inspect columns\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# Initialize a list to store processed rows\n",
    "processed_rows = []\n",
    "\n",
    "# Function to clean JSON\n",
    "def clean_json_string(json_string):\n",
    "    cleaned = (\n",
    "        json_string.strip()\n",
    "        .replace(\"```json\", \"\")\n",
    "        .replace(\"```\", \"\")\n",
    "        .replace(\"“\", '\"')  # Smart quotes to standard\n",
    "        .replace(\"”\", '\"')\n",
    "        .replace(\"‘\", \"'\")\n",
    "        .replace(\"’\", \"'\")\n",
    "        .replace(\"'\", '\"')  # Fix single quotes\n",
    "    )\n",
    "    # Remove any non-JSON text outside braces\n",
    "    cleaned = re.sub(r'^[^{\\[]*|[^}\\]]*$', '', cleaned, flags=re.DOTALL)\n",
    "    return cleaned\n",
    "\n",
    "# Process each row\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        date = row['date']\n",
    "        processed_results = row['processed_results']\n",
    "\n",
    "        # Ensure the value is not empty\n",
    "        if pd.notna(processed_results) and processed_results.strip():\n",
    "            cleaned_json = clean_json_string(processed_results)\n",
    "\n",
    "            # Parse JSON\n",
    "            players_data = json.loads(cleaned_json)\n",
    "            \n",
    "            # Ensure it's a list\n",
    "            if isinstance(players_data, list):\n",
    "                row_data = {'date': date}\n",
    "\n",
    "                # Extract player information\n",
    "                for i, player in enumerate(players_data):\n",
    "                    row_data[f'player{i+1}_name'] = player['player_name']\n",
    "                    row_data[f'player{i+1}_output'] = json.dumps(player)\n",
    "\n",
    "                processed_rows.append(row_data)\n",
    "            else:\n",
    "                print(f\"Unexpected data type at row {index}: {type(players_data)}\")\n",
    "        else:\n",
    "            print(f\"Empty or invalid processed_results at row {index}\")\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON for row {index}: {e}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing column: {e}\")\n",
    "    except TypeError as e:\n",
    "        print(f\"TypeError at row {index}: {e}\")\n",
    "\n",
    "# Create a new DataFrame\n",
    "output_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Save to a new CSV file\n",
    "output_file = '/Users/hemantg/Desktop/try-processed_output.csv'\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Processed CSV saved at: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON cleaning completed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Load your DataFrame\n",
    "df = pd.read_csv(\"/Users/hemantg/Downloads/combined_output1.csv\")  # Replace with your actual file\n",
    "\n",
    "# Function to clean JSON strings\n",
    "def clean_json_string(json_str):\n",
    "    try:\n",
    "        # Attempt to decode the original JSON string\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        # Fix common issues in JSON string\n",
    "        fixed_str = json_str\n",
    "\n",
    "        # Fix missing double quotes around property names\n",
    "        fixed_str = re.sub(r\"(\\{|,)(\\s*)(\\w+)(\\s*):\", r'\\1 \"\\3\":', fixed_str)\n",
    "\n",
    "        # Fix unterminated strings by closing quotes\n",
    "        fixed_str = re.sub(r'(\".*?)(?<!\\\\)(\")(?!:|,|})', r'\\1\\\\\"', fixed_str)\n",
    "\n",
    "        # Remove extra commas\n",
    "        fixed_str = re.sub(r\",\\s*([}\\]])\", r\"\\1\", fixed_str)\n",
    "\n",
    "        # Remove invalid control characters\n",
    "        fixed_str = re.sub(r\"[\\x00-\\x1F]+\", \"\", fixed_str)\n",
    "\n",
    "        # Attempt to load the fixed JSON string\n",
    "        try:\n",
    "            return json.loads(fixed_str)\n",
    "        except json.JSONDecodeError:\n",
    "            return None\n",
    "\n",
    "# Apply the cleaning function\n",
    "df[\"cleaned_results\"] = df[\"processed_results\"].apply(clean_json_string)\n",
    "\n",
    "# Drop rows with invalid JSON if needed\n",
    "df.dropna(subset=[\"cleaned_results\"], inplace=True)\n",
    "\n",
    "# Save the cleaned DataFrame\n",
    "df.to_csv(\"/Users/hemantg/Downloads/cleaned_file.csv\", index=False)\n",
    "\n",
    "print(\"JSON cleaning completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_json_string(json_string):\n",
    "    cleaned = (\n",
    "        json_string.strip()\n",
    "        .replace(\"```json\", \"\")\n",
    "        .replace(\"```\", \"\")\n",
    "        .replace(\"“\", '\"')  # Smart quotes to standard\n",
    "        .replace(\"”\", '\"')\n",
    "        .replace(\"‘\", \"'\")\n",
    "        .replace(\"’\", \"'\")\n",
    "        .replace(\"'\", '\"')  # Fix single quotes\n",
    "    )\n",
    "    \n",
    "    # Correct missing commas using regex\n",
    "    cleaned = re.sub(r'(\\}\\s*)(\\{)', r'\\1,\\2', cleaned)\n",
    "    \n",
    "    # Remove non-JSON text outside braces\n",
    "    cleaned = re.sub(r'^[^{\\[]*|[^}\\]]*$', '', cleaned, flags=re.DOTALL)\n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Safer JSON parsing\n",
    "def safe_json_loads(json_string):\n",
    "    try:\n",
    "        return json.loads(json_string, strict=False)\n",
    "    except json.JSONDecodeError:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['date', 'original_text', 'processed_results'], dtype='object')\n",
      "Error decoding JSON for row 2: Invalid JSON structure\n",
      "Error decoding JSON for row 12: Invalid JSON structure\n",
      "Error decoding JSON for row 14: Invalid JSON structure\n",
      "Error decoding JSON for row 16: Invalid JSON structure\n",
      "Error decoding JSON for row 17: Invalid JSON structure\n",
      "Error decoding JSON for row 30: Invalid JSON structure\n",
      "Error decoding JSON for row 32: Invalid JSON structure\n",
      "Error decoding JSON for row 33: Invalid JSON structure\n",
      "Error decoding JSON for row 36: Invalid JSON structure\n",
      "Error decoding JSON for row 37: Invalid JSON structure\n",
      "Error decoding JSON for row 38: Invalid JSON structure\n",
      "Error decoding JSON for row 45: Invalid JSON structure\n",
      "Error decoding JSON for row 47: Invalid JSON structure\n",
      "Error decoding JSON for row 50: Invalid JSON structure\n",
      "Error decoding JSON for row 52: Invalid JSON structure\n",
      "Error decoding JSON for row 54: Invalid JSON structure\n",
      "Error decoding JSON for row 56: Invalid JSON structure\n",
      "Error decoding JSON for row 66: Invalid JSON structure\n",
      "Error decoding JSON for row 69: Invalid JSON structure\n",
      "Error decoding JSON for row 77: Invalid JSON structure\n",
      "Error decoding JSON for row 78: Invalid JSON structure\n",
      "Error decoding JSON for row 82: Invalid JSON structure\n",
      "Error decoding JSON for row 85: Invalid JSON structure\n",
      "Error decoding JSON for row 86: Invalid JSON structure\n",
      "Error decoding JSON for row 87: Invalid JSON structure\n",
      "Error decoding JSON for row 91: Invalid JSON structure\n",
      "Error decoding JSON for row 92: Invalid JSON structure\n",
      "Error decoding JSON for row 94: Invalid JSON structure\n",
      "Error decoding JSON for row 96: Invalid JSON structure\n",
      "Error decoding JSON for row 98: Invalid JSON structure\n",
      "Processed CSV saved at: /Users/hemantg/Desktop/try-processed_output2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Load the CSV\n",
    "input_file = '/Users/hemantg/Desktop/try-combined-output.csv'  # Replace with the actual file path\n",
    "df = pd.read_csv(input_file, sep=',')\n",
    "\n",
    "# Inspect columns\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# Initialize a list to store processed rows\n",
    "processed_rows = []\n",
    "\n",
    "# Function to clean JSON strings\n",
    "def clean_json_string(json_string):\n",
    "    cleaned = (\n",
    "        json_string.strip()\n",
    "        .replace(\"```json\", \"\")\n",
    "        .replace(\"```\", \"\")\n",
    "        .replace(\"“\", '\"')  # Smart quotes to standard\n",
    "        .replace(\"”\", '\"')\n",
    "        .replace(\"‘\", \"'\")\n",
    "        .replace(\"’\", \"'\")\n",
    "        .replace(\"'\", '\"')  # Fix single quotes\n",
    "    )\n",
    "    \n",
    "    # Correct missing commas between JSON objects\n",
    "    cleaned = re.sub(r'(\\}\\s*)(\\{)', r'\\1,\\2', cleaned)\n",
    "    \n",
    "    # Remove non-JSON text outside braces\n",
    "    cleaned = re.sub(r'^[^{\\[]*|[^}\\]]*$', '', cleaned, flags=re.DOTALL)\n",
    "    return cleaned\n",
    "\n",
    "# Safer JSON loading function\n",
    "def safe_json_loads(json_string):\n",
    "    try:\n",
    "        return json.loads(json_string, strict=False)\n",
    "    except json.JSONDecodeError:\n",
    "        return None\n",
    "\n",
    "# Process each row\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        date = row['date']\n",
    "        processed_results = row['processed_results']\n",
    "\n",
    "        # Ensure the value is not empty\n",
    "        if pd.notna(processed_results) and processed_results.strip():\n",
    "            cleaned_json = clean_json_string(processed_results)\n",
    "            players_data = safe_json_loads(cleaned_json)\n",
    "\n",
    "            if players_data is None:\n",
    "                print(f\"Error decoding JSON for row {index}: Invalid JSON structure\")\n",
    "                continue\n",
    "\n",
    "            # Ensure it's a list\n",
    "            if isinstance(players_data, list):\n",
    "                row_data = {'date': date}\n",
    "\n",
    "                # Extract player information\n",
    "                for i, player in enumerate(players_data):\n",
    "                    row_data[f'player{i+1}_name'] = player.get('player_name', 'N/A')\n",
    "                    row_data[f'player{i+1}_output'] = json.dumps(player, ensure_ascii=False)\n",
    "\n",
    "                processed_rows.append(row_data)\n",
    "            else:\n",
    "                print(f\"Unexpected data type at row {index}: {type(players_data)}\")\n",
    "        else:\n",
    "            print(f\"Empty or invalid processed_results at row {index}\")\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing column: {e}\")\n",
    "    except TypeError as e:\n",
    "        print(f\"TypeError at row {index}: {e}\")\n",
    "\n",
    "# Create a new DataFrame\n",
    "output_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Save to a new CSV file\n",
    "output_file = '/Users/hemantg/Desktop/try-processed_output2.csv'\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Processed CSV saved at: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['date', 'original_text', 'processed_results'], dtype='object')\n",
      "Error decoding JSON for row 2: Expecting ',' delimiter: line 6 column 85 (char 346)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Brett_Lee\",\n",
      "    \"Metrics\": \"No specific metrics provided; known for fast bowling and Twenty20 experience.\",\n",
      "    \"Insights\": \"Former fast bowler, strong T20 presence, experienced in international cricket, adaptable to various formats.\",\n",
      "    \"Arguments\": \"Positively framed; believes IPL could enhance Australian players\" opportunities in T20 cricket.\",\n",
      "    \"match_performance\": 0.8,\n",
      "    \"predicted_future_performance\": 0.7\n",
      "  }\n",
      "]\n",
      "Error decoding JSON for row 12: Expecting ',' delimiter: line 5 column 137 (char 270)\n",
      "Problematic content: [\n",
      "    {\n",
      "        \"player_name\": \"Lalit_Modi\",\n",
      "        \"Metrics\": \"N/A - IPL Commissioner, no specific performance metrics discussed.\",\n",
      "        \"Insights\": \"Involved in negotiations; understands player concerns and restrictions. Not a player but crucial to the tournament\"s operation.\",\n",
      "        \"Arguments\": \"Has insisted on registration deadlines; past conditions affect Australian players.\",\n",
      "        \"match_performance\": 0.5,\n",
      "        \"predicted_future_performance\": 0.5\n",
      "    },\n",
      "    {\n",
      "        \"player_n\n",
      "Error decoding JSON for row 14: Expecting ',' delimiter: line 5 column 85 (char 256)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Adam_Gilchrist\",\n",
      "    \"Metrics\": \"Recently retired, previously exceptional wicketkeeper-batsman, known for aggressive batting, high strike rate.\",\n",
      "    \"Insights\": \"Aggressive opener, known for quick runs, played vital role in team\"s success throughout career, skillful in adapting to T20 format.\",\n",
      "    \"Arguments\": \"Highly regarded for his explosive batting in T20s, retirement raises questions about current form; potential to influence IPL despite retirement.\",\n",
      "    \"match_\n",
      "Error decoding JSON for row 16: Expecting ',' delimiter: line 4 column 53 (char 94)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Praveen_Kumar\",\n",
      "    \"Metrics\": \"US$ 300,000 contract; part of India\"s one-day squad; strong domestic performances; Under-22 category player\",\n",
      "    \"Insights\": \"Allrounder role; rising stock due to domestic form; younger player likely to have adaptability in formats; potential to impact games\",\n",
      "    \"Arguments\": \"Strong performance in domestic cricket; demand increased; confusion over team signing clarified, shows interest from multiple franchises\",\n",
      "    \"match_performance\"\n",
      "Error decoding JSON for row 17: Expecting ',' delimiter: line 14 column 38 (char 825)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Matthew_Hayden\",\n",
      "    \"Metrics\": \"Aimed for 2009 Ashes, past success in county cricket, averages mid-30s in Tests.\",\n",
      "    \"Insights\": \"Aggressive opening batsman, experienced, looking to refine skills in IPL ahead of international series. Facing tension in rivalry but keen to move forward.\",\n",
      "    \"Arguments\": \"Admits to past errors in remarks about Harbhajan, believes competitive edge is vital for fan engagement.\",\n",
      "    \"match_performance\": 0.8,\n",
      "    \"predicted_future_perfor\n",
      "Error decoding JSON for row 30: Expecting ',' delimiter: line 22 column 59 (char 1177)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Adam_Gilchrist\",\n",
      "    \"Metrics\": \"Retired in March, could play if two-year clause waived; known for explosive batting.\",\n",
      "    \"Insights\": \"Aggressive opening batsman, expert in T20 format; potential to impact matches immediately post-retirement, versatile game style.\",\n",
      "    \"Arguments\": \"High potential to adapt quickly after retirement; may struggle with timing in professional cricket again initially.\",\n",
      "    \"match_performance\": 0.8,\n",
      "    \"predicted_future_performance\": 0.9\n",
      "\n",
      "Error decoding JSON for row 32: Expecting ',' delimiter: line 21 column 151 (char 1407)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"David_Hussey\",\n",
      "    \"Metrics\": \"Contracted player for Nottinghamshire, has recently signed for IPL, expected absence of at least six weeks.\",\n",
      "    \"Insights\": \"Known for his versatility, experience in T20 format, strong batting skills, good adaptability. Currently unavailable at the start of the season which may affect team balance.\",\n",
      "    \"Arguments\": \"Positive argument regarding future commitment to Nottinghamshire, but negative due to current absence leaving a gap in th\n",
      "Error decoding JSON for row 33: Expecting ',' delimiter: line 6 column 49 (char 365)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Kevin_Pietersen\",\n",
      "    \"Metrics\": \"Strong T20 player, expressed desire to play in IPL, potential high impact in limited overs.\",\n",
      "    \"Insights\": \"Aggressive batting style, adaptable to various formats, key player for England. Recent interest in IPL indicates desire for higher competition.\",\n",
      "    \"Arguments\": \"Positive interest in Stanford\"s proposals, excitement for players and spectators, valuing opportunity for both formats.\",\n",
      "    \"match_performance\": 0.8,\n",
      "    \"predicte\n",
      "Error decoding JSON for row 36: Expecting ',' delimiter: line 6 column 33 (char 286)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Kevin_Pietersen\",\n",
      "    \"Metrics\": \"No specific stats mentioned; known for being a prize signing for IPL franchises.\",\n",
      "    \"Insights\": \"Dynamic batsman, excels in T20; may struggle with fatigue due to international commitments.\",\n",
      "    \"Arguments\": \"Described as \"silly\" to choose between international career and IPL riches; his profile suggests strong T20 capability.\",\n",
      "    \"match_performance\": 0.7,\n",
      "    \"predicted_future_performance\": 0.8\n",
      "  },\n",
      "  {\n",
      "    \"player_name\": \"Andrew_\n",
      "Error decoding JSON for row 37: Expecting ',' delimiter: line 5 column 88 (char 191)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Shane_Warne\",\n",
      "    \"Metrics\": \"Most expensive player, $400,000 for one year.\",\n",
      "    \"Insights\": \"Experienced spinner, strong Twenty20 record, key player for franchise\"s bowling unit.\",\n",
      "    \"Arguments\": \"High expectations due to pricing, valued for leadership and performance in shorter formats.\",\n",
      "    \"match_performance\": 0.9,\n",
      "    \"predicted_future_performance\": 0.8\n",
      "  },\n",
      "  {\n",
      "    \"player_name\": \"Glenn_McGrath\",\n",
      "    \"Metrics\": \"Second highest fee, $350,000.\",\n",
      "    \"Insights\": \n",
      "Error decoding JSON for row 38: Expecting ',' delimiter: line 14 column 121 (char 966)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Kevin_Pietersen\",\n",
      "    \"Metrics\": \"No specific stats mentioned, focus on IPL earnings and match availability\",\n",
      "    \"Insights\": \"Key England player with strong T20 background; prioritizes England career but hints at potential IPL involvement; values financial aspect of T20 leagues.\",\n",
      "    \"Arguments\": \"Frustrated by lack of IPL participation; believes scheduling issues need resolution; strong T20 player but committed to national duty.\",\n",
      "    \"match_performance\": 0.7,\n",
      "    \"p\n",
      "Error decoding JSON for row 45: Expecting ',' delimiter: line 6 column 50 (char 330)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Glenn_McGrath\",\n",
      "    \"Metrics\": \"No recent match performance since World Cup; previously a key player in ODIs and Tests\",\n",
      "    \"Insights\": \"Experienced fast bowler; ambassador role; form uncertain post-retirement; potential for credibility in T20 leagues\",\n",
      "    \"Arguments\": \"Positive impact on T20 cricket\"s growth; concerns about shorter format overshadowing Tests and ODIs; wishes for balance among formats\",\n",
      "    \"match_performance\": 0.6,\n",
      "    \"predicted_future_performance\":\n",
      "Error decoding JSON for row 47: Expecting ',' delimiter: line 6 column 52 (char 335)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Lou_Vincent\",\n",
      "    \"Metrics\": \"Recent departure from New Zealand cricket, joining rebel league ICL\",\n",
      "    \"Insights\": \"Former player for New Zealand, known for explosive batting in limited-overs; currently in a controversial transition, impacting team depth\",\n",
      "    \"Arguments\": \"Negatively impacting New Zealand\"s team strength; questions raised about commitment to national cricket\",\n",
      "    \"match_performance\": 0.2,\n",
      "    \"predicted_future_performance\": 0.3\n",
      "  },\n",
      "  {\n",
      "    \"player_n\n",
      "Error decoding JSON for row 50: Expecting ',' delimiter: line 13 column 125 (char 733)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Daniel_Vettori\",\n",
      "    \"Metrics\": \"Player keen on IPL inclusion in FTP; leadership role in New Zealand team\",\n",
      "    \"Insights\": \"Experienced all-rounder; adaptable to different formats; leadership in discussions; faces tough decisions on retirement under IPL pressures.\",\n",
      "    \"Arguments\": \"Supports balanced inclusion of IPL in FTP for player ease; suggests sustainability across formats.\",\n",
      "    \"match_performance\": 0.7,\n",
      "    \"predicted_future_performance\": 0.75\n",
      "  },\n",
      "  {\n",
      "    \"pl\n",
      "Error decoding JSON for row 52: Expecting ',' delimiter: line 5 column 56 (char 200)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Ross_Taylor\",\n",
      "    \"Metrics\": \"Notable signing for Bangalore franchise, historically strong in limited-overs cricket.\",\n",
      "    \"Insights\": \"Aggressive batting style, known as a \"biffer\". Complements team with ability to score quickly. Limited experience in IPL context.\",\n",
      "    \"Arguments\": \"Great signing to complement traditional players like Dravid, but may struggle with IPL pressure.\",\n",
      "    \"match_performance\": 0.7,\n",
      "    \"predicted_future_performance\": 0.6\n",
      "  },\n",
      "  {\n",
      "    \"playe\n",
      "Error decoding JSON for row 54: Expecting ',' delimiter: line 12 column 134 (char 735)\n",
      "Problematic content: [\n",
      "    {\n",
      "        \"player_name\": \"Greg_Shipperd\",\n",
      "        \"Metrics\": \"Unparalleled Twenty20 coaching record; Victoria won 3 titles in 3 years; only 1 loss\",\n",
      "        \"Insights\": \"Strong management skills; effective with international players; experience with high-pressure situations; focuses on team dynamics and performance adaptation\",\n",
      "        \"Arguments\": \"First priority is Cricket Victoria; positive coaching experience but potential conflict with IPL responsibilities\",\n",
      "        \"match_performance\n",
      "Error decoding JSON for row 56: Expecting ',' delimiter: line 12 column 83 (char 716)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Shoaib_Akhtar\",\n",
      "    \"Metrics\": \"5-year ban by PCB; previously banned for 13 matches; over US$50,000 fine; 2-year probation following incident with Asif.\",\n",
      "    \"Insights\": \"Aggressive fast bowler; known for his speed and impact; faced issues with discipline; strong in T20 formats but struggles within team dynamics.\",\n",
      "    \"Arguments\": \"Criticism of PCB led to harsh penalties; previously strong performances overshadowed by off-field controversies; perception as a victim of\n",
      "Error decoding JSON for row 66: Expecting ',' delimiter: line 20 column 63 (char 1030)\n",
      "Problematic content: [\n",
      "    {\n",
      "        \"player_name\": \"Dimitri_Mascarenhas\",\n",
      "        \"Metrics\": \"Notable coaching appointment; led where bigger names hesitated\",\n",
      "        \"Insights\": \"Experienced player; shows potential as a leader; valuable for lower-order contributions.\",\n",
      "        \"Arguments\": \"Positive: proactive in taking leadership roles; Negative: overshadowed by more famous players who want to follow.\",\n",
      "        \"match_performance\": 0.7,\n",
      "        \"predicted_future_performance\": 0.6\n",
      "    },\n",
      "    {\n",
      "        \"player_name\n",
      "Error decoding JSON for row 69: Expecting ',' delimiter: line 13 column 109 (char 759)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Darren_Lehmann\",\n",
      "    \"Metrics\": \"More than 25,000 runs, batting average 57.83, retired after 2007-08 season\",\n",
      "    \"Insights\": \"Experienced batsman, likely to bring stability; not played professional cricket recently; adapting to T20 format may be challenging\",\n",
      "    \"Arguments\": \"Positive: strong first-class record; Negative: long absence from competitive cricket, may struggle with match fitness and T20 demands\",\n",
      "    \"match_performance\": 0.7,\n",
      "    \"predicted_future_perform\n",
      "Error decoding JSON for row 77: Expecting ',' delimiter: line 4 column 62 (char 104)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Michael_Clarke\",\n",
      "    \"Metrics\": \"Recent focus on international career; father\"s health impacting decisions\",\n",
      "    \"Insights\": \"Strong batsman with leadership qualities; prioritizing family time over IPL participation; aiming for long-term fitness and health\",\n",
      "    \"Arguments\": \"Positive emphasis on family values; dedication to international cricket; potential distractions from IPL money\",\n",
      "    \"match_performance\": 0.8,\n",
      "    \"predicted_future_performance\": 0.85\n",
      "  },\n",
      "  {\n",
      "    \n",
      "Error decoding JSON for row 78: Expecting ',' delimiter: line 6 column 140 (char 452)\n",
      "Problematic content: [\n",
      "    {\n",
      "        \"player_name\": \"Shane_Warne\",\n",
      "        \"Metrics\": \"Most expensive player at US$400,000; reputation of strong Twenty20 performance\",\n",
      "        \"Insights\": \"Legendary spin bowler; experienced in high-pressure situations; can influence matches significantly; playing style effective in limited overs.\",\n",
      "        \"Arguments\": \"High expectations due to past performances and high price; leadership qualities and vast experience may elevate team\"s performance.\",\n",
      "        \"match_performance\": 0.\n",
      "Error decoding JSON for row 82: Expecting ',' delimiter: line 22 column 63 (char 1267)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Jacques_Kallis\",\n",
      "    \"Metrics\": \"High batting average, versatile allrounder, recognized for both batting and bowling\",\n",
      "    \"Insights\": \"Experienced player with strong technique, balanced skill set in both formats, currently concerned about workload affecting performance\",\n",
      "    \"Arguments\": \"Concerns about the decline of allrounders due to increased workload; suggests a window for IPL to help manage player fatigue\",\n",
      "    \"match_performance\": 0.8,\n",
      "    \"predicted_future_perf\n",
      "Error decoding JSON for row 85: Expecting ',' delimiter: line 21 column 69 (char 1105)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Michael_Vaughan\",\n",
      "    \"Metrics\": \"Notable leadership, expressed desire to play in IPL, past record as Test captain.\",\n",
      "    \"Insights\": \"Experienced Test captain, strong analytical abilities, likely to adapt well to T20 format; currently not participating.\",\n",
      "    \"Arguments\": \"Positively advocates for IPL; indicates a strong interest in being part of the league.\",\n",
      "    \"match_performance\": 0.4,\n",
      "    \"predicted_future_performance\": 0.7\n",
      "  },\n",
      "  {\n",
      "    \"player_name\": \"Kevin_Piete\n",
      "Error decoding JSON for row 86: Expecting ',' delimiter: line 21 column 125 (char 1269)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Jacques_Kallis\",\n",
      "    \"Metrics\": \"Test average: 55.37, ODI average: 44.83, purchased for US$ 900,000\",\n",
      "    \"Insights\": \"Experienced allrounder, strong in multiple formats, historically adapts well to various cricket forms, good at handling difficult situations with bat.\",\n",
      "    \"Arguments\": \"Experience as a Test player is a definite asset; concerns about adapting to the faster pace of T20.\",\n",
      "    \"match_performance\": 0.8,\n",
      "    \"predicted_future_performance\": 0.75\n",
      "  },\n",
      "  {\n",
      "  \n",
      "Error decoding JSON for row 87: Expecting ',' delimiter: line 4 column 33 (char 80)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Dimitri_Mascarenhas\",\n",
      "    \"Metrics\": \"Part of England\"s one-day squad, recently signed with Jaipur for IPL, non-centrally contracted player, captain of Hampshire.\",\n",
      "    \"Insights\": \"Bowler with experience, likely to improve through exposure to world-class players, strong support from Hampshire management.\",\n",
      "    \"Arguments\": \"Has opportunity to play in IPL without jeopardizing international career; ECB\"s supportive stance on his participation.\",\n",
      "    \"match_performance\": \n",
      "Error decoding JSON for row 91: Expecting ',' delimiter: line 5 column 75 (char 204)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Pradeep_Sangwan\",\n",
      "    \"Metrics\": \"Young talent, promising fast bowler, no specific metrics mentioned.\",\n",
      "    \"Insights\": \"Role as a fast bowler, potential for growth under Lillee\"s mentorship, young and upcoming.\",\n",
      "    \"Arguments\": \"Positive outlook due to mentorship, opportunities for development.\",\n",
      "    \"match_performance\": 0.7,\n",
      "    \"predicted_future_performance\": 0.75\n",
      "  },\n",
      "  {\n",
      "    \"player_name\": \"Yo_Mahesh\",\n",
      "    \"Metrics\": \"Emerging fast bowler, recent form not detaile\n",
      "Error decoding JSON for row 92: Expecting ',' delimiter: line 4 column 43 (char 84)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Ashley_Noffke\",\n",
      "    \"Metrics\": \"Part of Cricket Australia\"s contracted players for 2008-09, recent international honors, expected to gain experience from IPL.\",\n",
      "    \"Insights\": \"Bowler with focus on development, likely to utilize IPL exposure for skills enhancement, may have adaptability to T20 format.\",\n",
      "    \"Arguments\": \"Positive: Opportunity to bowl against top players, gain match experience; Negative: Came in as a last-minute replacement, may lack match readiness.\",\n",
      "\n",
      "Error decoding JSON for row 94: Expecting ',' delimiter: line 29 column 66 (char 1337)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Shoaib_Akhtar\",\n",
      "    \"Metrics\": \"Banned for five years by PCB; $450,000 bid in IPL.\",\n",
      "    \"Insights\": \"Known for his express fast bowling; has faced disciplinary issues; currently unfit to play in IPL due to ban.\",\n",
      "    \"Arguments\": \"Plans to appeal ban; questions about disciplinary record despite being selected by Kolkata.\",\n",
      "    \"match_performance\": 0,\n",
      "    \"predicted_future_performance\": 0.2\n",
      "  },\n",
      "  {\n",
      "    \"player_name\": \"Shahrukh_Khan\",\n",
      "    \"Metrics\": \"Owner of Kolkata Kn\n",
      "Error decoding JSON for row 96: Expecting ',' delimiter: line 13 column 129 (char 750)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Daniel_Vettori\",\n",
      "    \"Metrics\": \"Key player for New Zealand, missed warm-up matches due to IPL commitments.\",\n",
      "    \"Insights\": \"Experienced captain, known for spin bowling and lower-order batting. Leadership role; may struggle with focus due to league distractions.\",\n",
      "    \"Arguments\": \"Negative sentiment regarding prioritization of IPL over national duties; possible impact on team dynamics.\",\n",
      "    \"match_performance\": 0.6,\n",
      "    \"predicted_future_performance\": 0.65\n",
      "  },\n",
      "  {\n",
      "\n",
      "Error decoding JSON for row 98: Expecting ',' delimiter: line 12 column 57 (char 532)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \"player_name\": \"Rahul_Dravid\",\n",
      "    \"Metrics\": \"Captain of Royal Challengers, notable leadership skills, experience in T20 format.\",\n",
      "    \"Insights\": \"Experienced batsman, solid technique, key leader for the team, adapting to shorter formats.\",\n",
      "    \"Arguments\": \"Positive narrative around leadership; expected to utilize experience effectively in T20.\",\n",
      "    \"match_performance\": 0.8,\n",
      "    \"predicted_future_performance\": 0.75\n",
      "  },\n",
      "  {\n",
      "    \"player_name\": \"Zaheer_Khan\",\n",
      "    \"Metrics\": \"Recently\n",
      "Processed CSV saved at: /Users/hemantg/Desktop/try-processed_output3.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Load the CSV\n",
    "input_file = '/Users/hemantg/Desktop/try-combined-output.csv'  # Replace with the actual file path\n",
    "df = pd.read_csv(input_file, sep=',')\n",
    "\n",
    "# Inspect columns\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# Initialize a list to store processed rows\n",
    "processed_rows = []\n",
    "\n",
    "# Function to clean JSON strings\n",
    "def clean_json_string(json_string):\n",
    "    cleaned = (\n",
    "        json_string.strip()\n",
    "        .replace(\"```json\", \"\")\n",
    "        .replace(\"```\", \"\")\n",
    "        .replace(\"“\", '\"')  # Smart quotes to standard\n",
    "        .replace(\"”\", '\"')\n",
    "        .replace(\"‘\", \"'\")\n",
    "        .replace(\"’\", \"'\")\n",
    "        .replace(\"'\", '\"')  # Fix single quotes\n",
    "    )\n",
    "    \n",
    "    # Correct missing commas between JSON objects\n",
    "    cleaned = re.sub(r'(\\}\\s*)(\\{)', r'\\1,\\2', cleaned)\n",
    "    \n",
    "    # Remove non-JSON text outside braces\n",
    "    cleaned = re.sub(r'^[^{\\[]*|[^}\\]]*$', '', cleaned, flags=re.DOTALL)\n",
    "    return cleaned\n",
    "\n",
    "# Safer JSON loading function\n",
    "def safe_json_loads(json_string, row_index):\n",
    "    try:\n",
    "        return json.loads(json_string, strict=False)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON for row {row_index}: {e}\")\n",
    "        print(f\"Problematic content: {json_string[:500]}\")  # Show first 500 chars\n",
    "        return None\n",
    "\n",
    "# Process each row\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        date = row['date']\n",
    "        processed_results = row['processed_results']\n",
    "\n",
    "        # Ensure the value is not empty\n",
    "        if pd.notna(processed_results) and processed_results.strip():\n",
    "            cleaned_json = clean_json_string(processed_results)\n",
    "            players_data = safe_json_loads(cleaned_json, index)\n",
    "\n",
    "            if players_data is None:\n",
    "                continue\n",
    "\n",
    "            # Ensure it's a list\n",
    "            if isinstance(players_data, list):\n",
    "                row_data = {'date': date}\n",
    "\n",
    "                # Extract player information\n",
    "                for i, player in enumerate(players_data):\n",
    "                    row_data[f'player{i+1}_name'] = player.get('player_name', 'N/A')\n",
    "                    row_data[f'player{i+1}_output'] = json.dumps(player, ensure_ascii=False)\n",
    "\n",
    "                processed_rows.append(row_data)\n",
    "            else:\n",
    "                print(f\"Unexpected data type at row {index}: {type(players_data)}\")\n",
    "        else:\n",
    "            print(f\"Empty or invalid processed_results at row {index}\")\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing column: {e}\")\n",
    "    except TypeError as e:\n",
    "        print(f\"TypeError at row {index}: {e}\")\n",
    "\n",
    "# Create a new DataFrame\n",
    "output_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Save to a new CSV file\n",
    "output_file = '/Users/hemantg/Desktop/try-processed_output3.csv'\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Processed CSV saved at: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['date', 'original_text', 'processed_results'], dtype='object')\n",
      "Error decoding JSON for row 0: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Mohammad_Yousuf\",\n",
      "    \\\"Metrics\": \\\"Pending IPL participation due to ICL contract dispute; prior good performance in T20 leagues.\",\n",
      "    \\\"Insights\": \\\"Known for aggressive batting style; past record includes high averages; currently facing contract issues affecting form.\",\n",
      "    \\\"Arguments\": \\\"Negative sentiment due to ongoing legal challenges; uncertainty impacting selling in IPL auction.\",\n",
      "    \\\"match_performance\": 0,\n",
      "    \\\"predicted_future_performance\": 0.3\n",
      "  }\n",
      "]\n",
      "Error decoding JSON for row 1: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Shane_Warne\",\n",
      "    \\\"Metrics\": \\\"Notable player with a strong leadership role; promotes personal sponsor effectively.\",\n",
      "    \\\"Insights\": \\\"Experienced franchise leader with vast cricket knowledge; shines in T20 formats; seeks business opportunities through cricket.\",\n",
      "    \\\"Arguments\": \\\"Positively impacts team dynamics; potential challenges with timing due to scheduling conflicts with county cricket.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_future_performance\":\n",
      "Error decoding JSON for row 2: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Brett_Lee\",\n",
      "    \\\"Metrics\": \\\"No specific metrics provided; known for fast bowling and Twenty20 experience.\",\n",
      "    \\\"Insights\": \\\"Former fast bowler, strong T20 presence, experienced in international cricket, adaptable to various formats.\",\n",
      "    \\\"Arguments\": \\\"Positively framed; believes IPL could enhance Australian players\\\" opportunities in T20 cricket.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_future_performance\": 0.7\n",
      "  }\n",
      "]\n",
      "Error decoding JSON for row 3: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Adam_Gilchrist\",\n",
      "    \\\"Metrics\": \\\"Retirement from international cricket; participation contingent on No Objection Certificate; affected by two-year hiatus rule.\",\n",
      "    \\\"Insights\": \\\"Explosive wicketkeeper-batsman; strong Twenty20 format potential; known for aggressive batting.\",\n",
      "    \\\"Arguments\": \\\"Confident he will find a way to participate despite retirement; significant asset to IPL teams with his experience.\",\n",
      "    \\\"match_performance\": 0.7,\n",
      "    \\\"predicted_future\n",
      "Error decoding JSON for row 4: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Rohit_Sharma\",\n",
      "    \\\"Metrics\": \\\"Excellent batting technique, capable of powerful shots, well-rounded skills, adaptable in all formats.\",\n",
      "    \\\"Insights\": \\\"Modern cricket citizen, strong technique, effective in T20s, ODIs, and Tests. History of being well-coached and developed.\",\n",
      "    \\\"Arguments\": \\\"Positive - has shown ability to adapt and perform across formats. Concerns if senior players prioritize IPL over international duties.\",\n",
      "    \\\"match_performance\": 0.85,\n",
      " \n",
      "Error decoding JSON for row 5: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Kevin_Pietersen\",\n",
      "    \\\"Metrics\": \\\"High profile England batsman, known for a strong T20 record, focus on England career rather than T20 leagues.\",\n",
      "    \\\"Insights\": \\\"Aggressive batting style, capable of big runs in short formats, prefers international commitments over leagues.\",\n",
      "    \\\"Arguments\": \\\"Prioritizes England career over IPL, commitment to national team may affect league participation.\",\n",
      "    \\\"match_performance\": 0.9,\n",
      "    \\\"predicted_future_performance\": 0.8\n",
      "Error decoding JSON for row 6: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Dimitri_Mascarenhas\",\n",
      "    \\\"Metrics\": \\\"Hard-hitting player, sought after for T20 format, expected to have strong impact.\",\n",
      "    \\\"Insights\": \\\"Aggressive batting style, versatile all-rounder, adapts well to different formats, currently contracted with Hampshire.\",\n",
      "    \\\"Arguments\": \\\"High demand in IPL suggests strong form; potential for exemplary performance. Contract status might impact immediate participation.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_future\n",
      "Error decoding JSON for row 7: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Daniel_Vettori\",\n",
      "    \\\"Metrics\": \\\"Concerns about contract clauses, no specific recent performance metrics mentioned.\",\n",
      "    \\\"Insights\": \\\"Experienced player, leader in the team. Strong tactical mind but hesitating due to contractual obligations.\",\n",
      "    \\\"Arguments\": \\\"Concerned about the contract implications and participation in Champions League affecting NZC commitment.\",\n",
      "    \\\"match_performance\": 0.6,\n",
      "    \\\"predicted_future_performance\": 0.5\n",
      "  },\n",
      "  {\n",
      "    \\\"player_n\n",
      "Error decoding JSON for row 8: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Dimitri_Mascarenhas\",\n",
      "    \\\"Metrics\": \\\"First English player in IPL, limited exposure in 2008 (May 12-26), contracted for 2009-2010, Hampshire priority in Champions League.\",\n",
      "    \\\"Insights\": \\\"Allrounder, may excel in T20 format, potential to adapt to Indian pitches, recent form not detailed.\",\n",
      "    \\\"Arguments\": \\\"Positive: valuable T20 experience, good fit for Jaipur. Negative: limited time with Hampshire might affect form.\",\n",
      "    \\\"match_performance\": 0.75,\n",
      "    \\\"pr\n",
      "Error decoding JSON for row 9: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Nathan_Bracken\",\n",
      "    \\\"Metrics\": \\\"21 wickets in CB Series, Man-of-the-Series award.\",\n",
      "    \\\"Insights\": \\\"Fast bowler, known for resilience despite injuries. Struggled with knee issues yet performed well in the series.\",\n",
      "    \\\"Arguments\": \\\"Showed strong performance through injury, but significant knee damage raises concerns about future fitness.\",\n",
      "    \\\"match_performance\": 0.6,\n",
      "    \\\"predicted_future_performance\": 0.5\n",
      "  }\n",
      "]\n",
      "Error decoding JSON for row 10: Expecting property name enclosed in double quotes: line 3 column 9 (char 16)\n",
      "Problematic content: [\n",
      "    {\n",
      "        \\\"player_name\": \\\"Andrew_Symonds\",\n",
      "        \\\"Metrics\": \\\"Strong allrounder; noted for ability to earn more in shorter formats; previously averaged strong performance in Tests and ODIs.\",\n",
      "        \\\"Insights\": \\\"Aggressive batting style; flexible in adapting to various formats; pivotal middle-order player.\",\n",
      "        \\\"Arguments\": \\\"Raises concerns about loyalty due to financial temptations; potential to retire early for lucrative T20 contracts.\",\n",
      "        \\\"match_performance\": 0.8,\n",
      "\n",
      "Error decoding JSON for row 11: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"David_Hussey\",\n",
      "    \\\"Metrics\": \\\"Signed for US$625,000 per year; on a two-year contract with Nottinghamshire; will miss first five County Championship matches and eight Friends Provident Trophy games.\",\n",
      "    \\\"Insights\": \\\"Experienced batsman with a solid track record; ability to perform in T20 format; expected to adapt quickly after India series.\",\n",
      "    \\\"Arguments\": \\\"Positive sentiment regarding participation in IPL; successful negotiation with Nottinghamshire; may a\n",
      "Error decoding JSON for row 12: Expecting property name enclosed in double quotes: line 3 column 9 (char 16)\n",
      "Problematic content: [\n",
      "    {\n",
      "        \\\"player_name\": \\\"Lalit_Modi\",\n",
      "        \\\"Metrics\": \\\"N/A - IPL Commissioner, no specific performance metrics discussed.\",\n",
      "        \\\"Insights\": \\\"Involved in negotiations; understands player concerns and restrictions. Not a player but crucial to the tournament\\\"s operation.\",\n",
      "        \\\"Arguments\": \\\"Has insisted on registration deadlines; past conditions affect Australian players.\",\n",
      "        \\\"match_performance\": 0.5,\n",
      "        \\\"predicted_future_performance\": 0.5\n",
      "    },\n",
      "    {\n",
      "      \n",
      "Error decoding JSON for row 13: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Virat_Kohli\",\n",
      "    \\\"Metrics\": \\\"Recent World Cup member, high-profile player, potential for high run scores, experience in IPL\",\n",
      "    \\\"Insights\": \\\"Aggressive batsman, strong run chaser, good adaptability to formats, pivotal role in batting order\",\n",
      "    \\\"Arguments\": \\\"Potential to excel, risks of being drafted to a different franchise, may disrupt team synergy\",\n",
      "    \\\"match_performance\": 0.85,\n",
      "    \\\"predicted_future_performance\": 0.80\n",
      "  }\n",
      "]\n",
      "Error decoding JSON for row 14: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Adam_Gilchrist\",\n",
      "    \\\"Metrics\": \\\"Recently retired, previously exceptional wicketkeeper-batsman, known for aggressive batting, high strike rate.\",\n",
      "    \\\"Insights\": \\\"Aggressive opener, known for quick runs, played vital role in team\\\"s success throughout career, skillful in adapting to T20 format.\",\n",
      "    \\\"Arguments\": \\\"Highly regarded for his explosive batting in T20s, retirement raises questions about current form; potential to influence IPL despite retirement.\",\n",
      "  \n",
      "Error decoding JSON for row 15: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Ricky_Ponting\",\n",
      "    \\\"Metrics\": \\\"Notable achievements as captain, experience in T20s.\",\n",
      "    \\\"Insights\": \\\"Experienced batsman, strong leadership, aggressive playing style.\",\n",
      "    \\\"Arguments\": \\\"Positivity around leadership contributions; doubts on adapting to T20 pace.\",\n",
      "    \\\"match_performance\": 0.7,\n",
      "    \\\"predicted_future_performance\": 0.75\n",
      "  },\n",
      "  {\n",
      "    \\\"player_name\": \\\"Brett_Lee\",\n",
      "    \\\"Metrics\": \\\"High wicket-taking ability, proven record in T20.\",\n",
      "    \\\"Insigh\n",
      "Error decoding JSON for row 16: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Praveen_Kumar\",\n",
      "    \\\"Metrics\": \\\"US$ 300,000 contract; part of India\\\"s one-day squad; strong domestic performances; Under-22 category player\",\n",
      "    \\\"Insights\": \\\"Allrounder role; rising stock due to domestic form; younger player likely to have adaptability in formats; potential to impact games\",\n",
      "    \\\"Arguments\": \\\"Strong performance in domestic cricket; demand increased; confusion over team signing clarified, shows interest from multiple franchises\",\n",
      "    \\\"match_pe\n",
      "Error decoding JSON for row 17: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Matthew_Hayden\",\n",
      "    \\\"Metrics\": \\\"Aimed for 2009 Ashes, past success in county cricket, averages mid-30s in Tests.\",\n",
      "    \\\"Insights\": \\\"Aggressive opening batsman, experienced, looking to refine skills in IPL ahead of international series. Facing tension in rivalry but keen to move forward.\",\n",
      "    \\\"Arguments\": \\\"Admits to past errors in remarks about Harbhajan, believes competitive edge is vital for fan engagement.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_fut\n",
      "Error decoding JSON for row 18: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Mohammad_Yousuf\",\n",
      "    \\\"Metrics\": \\\"Previously signed with ICL; facing legal complications preventing participation; not currently active in IPL.\",\n",
      "    \\\"Insights\": \\\"Experienced batsman, skilled in pressure situations; recent form unknown due to legal issues; previous success in international formats.\",\n",
      "    \\\"Arguments\": \\\"Legal issues preventing participation in IPL; potential loss of momentum and match fitness; strong experience but currently in a difficult positio\n",
      "Error decoding JSON for row 19: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Mohammad_Yousuf\",\n",
      "    \\\"Metrics\": \\\"Signed with ICL, subsequently lured back by PCB; unsold at IPL auctions.\",\n",
      "    \\\"Insights\": \\\"Previously a mainstay in the Pakistan team; strong T20 player with powerful batting; currently facing legal issues affecting participation.\",\n",
      "    \\\"Arguments\": \\\"Negatively impacted by ongoing legal dispute; board supports his IPL participation despite lack of current contracts; previous records suggest potential but uncertain outcome.\",\n",
      "  \n",
      "Error decoding JSON for row 20: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"David_Hussey\",\n",
      "    \\\"Metrics\": \\\"$625,000 IPL contract; played for Kolkata franchise; significant draw with IPL\",\n",
      "    \\\"Insights\": \\\"Strong T20 player; excels in high-pressure matches; been a top performer; his commitment to IPL indicates strong current form\",\n",
      "    \\\"Arguments\": \\\"Prefers IPL over county cricket; financial incentive overshadows county commitments\",\n",
      "    \\\"match_performance\": 0.9,\n",
      "    \\\"predicted_future_performance\": 0.8\n",
      "  }\n",
      "]\n",
      "Error decoding JSON for row 21: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Adam_Gilchrist\",\n",
      "    \\\"Metrics\": \\\"36 years old; Retiring from internationals in March; Contracted to Cricket Australia\",\n",
      "    \\\"Insights\": \\\"Experienced player; Key role as a wicketkeeper-batsman; adapting to shorter formats; history of notable achievements\",\n",
      "    \\\"Arguments\": \\\"No current performance issues mentioned; potential marketable asset for coaching; likely to participate in IPL despite restrictions\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_future_perf\n",
      "Error decoding JSON for row 22: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Michael_Clarke\",\n",
      "    \\\"Metrics\": \\\"Faced 4 balls in 5 matches during World Twenty20, low involvement in matches.\",\n",
      "    \\\"Insights\": \\\"Known for solid batting, struggles with limited play in T20; needs longer formats for better engagement.\",\n",
      "    \\\"Arguments\": \\\"Negative sentiment about being denied serious match involvement affects performance; may struggle with shorter formats.\",\n",
      "    \\\"match_performance\": 0.2,\n",
      "    \\\"predicted_future_performance\": 0.4\n",
      "  }\n",
      "]\n",
      "Error decoding JSON for row 23: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Dimitri_Mascarenhas\",\n",
      "    \\\"Metrics\": \\\"Current IPL player, limited exposure due to County Championship clashes.\",\n",
      "    \\\"Insights\": \\\"All-rounder, known for his versatility in T20 formats, currently the only England player in IPL, adapting to competitive cricket.\",\n",
      "    \\\"Arguments\": \\\"Limited exposure could benefit his adaptability; however, lack of consistent play could hinder performance.\",\n",
      "    \\\"match_performance\": 0.7,\n",
      "    \\\"predicted_future_performance\": 0.6\n",
      "  }\n",
      "\n",
      "Error decoding JSON for row 24: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Kevin_Pietersen\",\n",
      "    \\\"Metrics\": \\\"Frustration about inability to play IPL due to international schedule\",\n",
      "    \\\"Insights\": \\\"Key player with experience; known for aggressive batting and leadership; currently facing scheduling conflicts preventing participation in IPL.\",\n",
      "    \\\"Arguments\": \\\"Positive: High-profile player; Negative: Frustration over not capitalizing on IPL money.\",\n",
      "    \\\"match_performance\": 0.5,\n",
      "    \\\"predicted_future_performance\": 0.6\n",
      "  },\n",
      "  {\n",
      "    \\\"p\n",
      "Error decoding JSON for row 25: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Kevin_Pietersen\",\n",
      "    \\\"Metrics\": \\\"Recent offers for IPL; focus on England career; scoring thousands more runs expected.\",\n",
      "    \\\"Insights\": \\\"Strong commitment to England; enjoys playing for spectators; high personal motivation; performing well and thrives under pressure.\",\n",
      "    \\\"Arguments\": \\\"Positive commitment to England over financial gain; emphasis on current enjoyment of cricket; suggests high value placed on his international career.\",\n",
      "    \\\"match_performance\"\n",
      "Error decoding JSON for row 26: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Andrew_Flintoff\",\n",
      "    \\\"Metrics\": \\\"Test averages, performance in past series, strong all-rounder statistics\",\n",
      "    \\\"Insights\": \\\"Excellent all-round capabilities, strong in both batting and bowling, experienced player but might shift focus towards IPL\",\n",
      "    \\\"Arguments\": \\\"Potential loss to IPL could diminish Test cricket quality, financial motivations may lead to reduced commitment to national duties\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_future_performanc\n",
      "Error decoding JSON for row 27: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Shane_Bond\",\n",
      "    \\\"Metrics\": \\\"Forced to terminate national deal due to ICL participation.\",\n",
      "    \\\"Insights\": \\\"Former New Zealand fast bowler, known for his pace and ability to take wickets. Previously held national deals; potential impact on younger players.\",\n",
      "    \\\"Arguments\": \\\"Negative outcome of ICL participation led to contract termination.\",\n",
      "    \\\"match_performance\": 0.0,\n",
      "    \\\"predicted_future_performance\": 0.1\n",
      "  },\n",
      "  {\n",
      "    \\\"player_name\": \\\"Stuart_Law\",\n",
      "    \n",
      "Error decoding JSON for row 28: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Ishant_Sharma\",\n",
      "    \\\"Metrics\": \\\"High auction bid; recently started international career\",\n",
      "    \\\"Insights\": \\\"Young fast bowler; potential but inexperienced; concerns about handling sudden wealth\",\n",
      "    \\\"Arguments\": \\\"Concerns about maturity and ability to stay grounded; high expectations placed on him too early\",\n",
      "    \\\"match_performance\": 0.6,\n",
      "    \\\"predicted_future_performance\": 0.5\n",
      "  },\n",
      "  {\n",
      "    \\\"player_name\": \\\"Mahendra_Singh_Dhoni\",\n",
      "    \\\"Metrics\": \\\"Top player \n",
      "Error decoding JSON for row 29: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Adam_Gilchrist\",\n",
      "    \\\"Metrics\": \\\"36 years old; IPL participation; professional player since the early era.\",\n",
      "    \\\"Insights\": \\\"Experienced wicketkeeper-batsman; strong T20 player; likely to make an impact due to his age and past performances.\",\n",
      "    \\\"Arguments\": \\\"Believes passion for the game will prevent players from cutting short their careers for money; provides opportunities for older players.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_future_performance\n",
      "Error decoding JSON for row 30: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Adam_Gilchrist\",\n",
      "    \\\"Metrics\": \\\"Retired in March, could play if two-year clause waived; known for explosive batting.\",\n",
      "    \\\"Insights\": \\\"Aggressive opening batsman, expert in T20 format; potential to impact matches immediately post-retirement, versatile game style.\",\n",
      "    \\\"Arguments\": \\\"High potential to adapt quickly after retirement; may struggle with timing in professional cricket again initially.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_future_performa\n",
      "Error decoding JSON for row 31: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Ricky_Ponting\",\n",
      "    \\\"Metrics\": \\\"Team captain, experienced player, leadership role, notable achievements in T20 and Tests.\",\n",
      "    \\\"Insights\": \\\"Strong leader, good adaptability in T20 format, aggressive batting style, recent form uncertain due to IPL participation discussions.\",\n",
      "    \\\"Arguments\": \\\"Positive: captaincy experience; Negative: unclear participation due to ongoing contract issues.\",\n",
      "    \\\"match_performance\": 0.7,\n",
      "    \\\"predicted_future_performance\": 0.8\n",
      " \n",
      "Error decoding JSON for row 32: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"David_Hussey\",\n",
      "    \\\"Metrics\": \\\"Contracted player for Nottinghamshire, has recently signed for IPL, expected absence of at least six weeks.\",\n",
      "    \\\"Insights\": \\\"Known for his versatility, experience in T20 format, strong batting skills, good adaptability. Currently unavailable at the start of the season which may affect team balance.\",\n",
      "    \\\"Arguments\": \\\"Positive argument regarding future commitment to Nottinghamshire, but negative due to current absence leaving a g\n",
      "Error decoding JSON for row 33: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Kevin_Pietersen\",\n",
      "    \\\"Metrics\": \\\"Strong T20 player, expressed desire to play in IPL, potential high impact in limited overs.\",\n",
      "    \\\"Insights\": \\\"Aggressive batting style, adaptable to various formats, key player for England. Recent interest in IPL indicates desire for higher competition.\",\n",
      "    \\\"Arguments\": \\\"Positive interest in Stanford\\\"s proposals, excitement for players and spectators, valuing opportunity for both formats.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "   \n",
      "Error decoding JSON for row 34: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Adam_Gilchrist\",\n",
      "    \\\"Metrics\": \\\"Retiring player; notable achievements include key innings in past IPL matches.\",\n",
      "    \\\"Insights\": \\\"Explosive opening batsman; known for aggressive batting style; experience in T20 format.\",\n",
      "    \\\"Arguments\": \\\"Potential to contribute significantly in his final IPL season; sentiment of farewell may boost performance.\",\n",
      "    \\\"match_performance\": 0.75,\n",
      "    \\\"predicted_future_performance\": 0.65\n",
      "  },\n",
      "  {\n",
      "    \\\"player_name\": \\\"Ricky_Ponti\n",
      "Error decoding JSON for row 35: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"David_Hussey\",\n",
      "    \\\"Metrics\": \\\"Sold for US$625,000; 15% payment due; no initial IPL payment yet\",\n",
      "    \\\"Insights\": \\\"Experienced batsman; known for strong performance in T20 formats; potential impact player; currently facing uncertainty due to payment issues\",\n",
      "    \\\"Arguments\": \\\"Ongoing payment issues might affect focus and readiness; otherwise strong T20 player; expected to play well once issues resolved\",\n",
      "    \\\"match_performance\": 0.7,\n",
      "    \\\"predicted_future_perf\n",
      "Error decoding JSON for row 36: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Kevin_Pietersen\",\n",
      "    \\\"Metrics\": \\\"No specific stats mentioned; known for being a prize signing for IPL franchises.\",\n",
      "    \\\"Insights\": \\\"Dynamic batsman, excels in T20; may struggle with fatigue due to international commitments.\",\n",
      "    \\\"Arguments\": \\\"Described as \\\"silly\\\" to choose between international career and IPL riches; his profile suggests strong T20 capability.\",\n",
      "    \\\"match_performance\": 0.7,\n",
      "    \\\"predicted_future_performance\": 0.8\n",
      "  },\n",
      "  {\n",
      "    \\\"player_na\n",
      "Error decoding JSON for row 37: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Shane_Warne\",\n",
      "    \\\"Metrics\": \\\"Most expensive player, $400,000 for one year.\",\n",
      "    \\\"Insights\": \\\"Experienced spinner, strong Twenty20 record, key player for franchise\\\"s bowling unit.\",\n",
      "    \\\"Arguments\": \\\"High expectations due to pricing, valued for leadership and performance in shorter formats.\",\n",
      "    \\\"match_performance\": 0.9,\n",
      "    \\\"predicted_future_performance\": 0.8\n",
      "  },\n",
      "  {\n",
      "    \\\"player_name\": \\\"Glenn_McGrath\",\n",
      "    \\\"Metrics\": \\\"Second highest fee, $350,000.\",\n",
      " \n",
      "Error decoding JSON for row 38: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Kevin_Pietersen\",\n",
      "    \\\"Metrics\": \\\"No specific stats mentioned, focus on IPL earnings and match availability\",\n",
      "    \\\"Insights\": \\\"Key England player with strong T20 background; prioritizes England career but hints at potential IPL involvement; values financial aspect of T20 leagues.\",\n",
      "    \\\"Arguments\": \\\"Frustrated by lack of IPL participation; believes scheduling issues need resolution; strong T20 player but committed to national duty.\",\n",
      "    \\\"match_performance\": 0.\n",
      "Error decoding JSON for row 39: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Aakash_Chopra\",\n",
      "    \\\"Metrics\": \\\"Average: 332 in recent Ranji one-dayers; Strike-rate: above 100; 3 centuries in 4 innings\",\n",
      "    \\\"Insights\": \\\"Good in limited formats; adapting well to T20; demonstrated improvement; strong batsman for Kolkata Knight Riders\",\n",
      "    \\\"Arguments\": \\\"Overcame stereotype of being a Test player; performance in IPL could challenge previous perceptions\",\n",
      "    \\\"match_performance\": 0.9,\n",
      "    \\\"predicted_future_performance\": 0.8\n",
      "  },\n",
      "  {\n",
      "    \\\"pl\n",
      "Error decoding JSON for row 40: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Lasith_Malinga\",\n",
      "    \\\"Metrics\": \\\"No recent stats available due to injury; previous IPL success; bought for US$350,000.\",\n",
      "    \\\"Insights\": \\\"Experienced fast bowler; historically strong in T20 formats; currently battling a knee injury affecting form; key player for Mumbai Indians.\",\n",
      "    \\\"Arguments\": \\\"Struggling with fitness impacts chances; worked through injuries before, but missed West Indies tour raises concerns.\",\n",
      "    \\\"match_performance\": 0.4,\n",
      "    \\\"predicted_\n",
      "Error decoding JSON for row 41: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Jason_Gillespie\",\n",
      "    \\\"Metrics\": \\\"Player auction available, significant interest in IPL, known for pace bowling, potential for high IPL earnings\",\n",
      "    \\\"Insights\": \\\"Former Test player who is likely transitioning to shorter formats, adaptable player, experience in varying formats, concern on fit in T20\",\n",
      "    \\\"Arguments\": \\\"Positively embracing T20 format, believes IPL will thrive, uncertainty over transitioning to pure T20 play\",\n",
      "    \\\"match_performance\": 0.7,\n",
      "    \n",
      "Error decoding JSON for row 42: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Mike_Hussey\",\n",
      "    \\\"Metrics\": \\\"Notable achievements in IPL; high batting average; strong T20 performer.\",\n",
      "    \\\"Insights\": \\\"Consistent middle-order batsman; known for adaptability across formats; possesses experience and leadership qualities.\",\n",
      "    \\\"Arguments\": \\\"Positive reputation in T20 leagues; potential impact player for IPL teams.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_future_performance\": 0.75\n",
      "  },\n",
      "  {\n",
      "    \\\"player_name\": \\\"Michael_Clarke\",\n",
      "    \\\"M\n",
      "Error decoding JSON for row 43: Expecting property name enclosed in double quotes: line 3 column 9 (char 16)\n",
      "Problematic content: [\n",
      "    {\n",
      "        \\\"player_name\": \\\"Arjuna_Ranatunga\",\n",
      "        \\\"Metrics\": \\\"Former captain, key strategist, significant impact on Sri Lanka cricket history\",\n",
      "        \\\"Insights\": \\\"Leadership qualities, major role in developing players, strategic decision-maker for SLC\",\n",
      "        \\\"Arguments\": \\\"Positive influence on Sri Lankan cricket, valued experience; focus on series without IPL clash shows prioritization of player availability\",\n",
      "        \\\"match_performance\": 0.8,\n",
      "        \\\"predicted_future_pe\n",
      "Error decoding JSON for row 44: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Brett_Lee\",\n",
      "    \\\"Metrics\": \\\"Auction price: $900,000; known for pace bowling, pivotal in T20 format\",\n",
      "    \\\"Insights\": \\\"Excited about T20, values fun, strong in pressure situations, skilled bowler.\",\n",
      "    \\\"Arguments\": \\\"Believes IPL will not replace traditional formats, views T20 as a different challenge.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_future_performance\": 0.75\n",
      "  },\n",
      "  {\n",
      "    \\\"player_name\": \\\"Matthew_Hayden\",\n",
      "    \\\"Metrics\": \\\"Auction price: $375,00\n",
      "Error decoding JSON for row 45: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Glenn_McGrath\",\n",
      "    \\\"Metrics\": \\\"No recent match performance since World Cup; previously a key player in ODIs and Tests\",\n",
      "    \\\"Insights\": \\\"Experienced fast bowler; ambassador role; form uncertain post-retirement; potential for credibility in T20 leagues\",\n",
      "    \\\"Arguments\": \\\"Positive impact on T20 cricket\\\"s growth; concerns about shorter format overshadowing Tests and ODIs; wishes for balance among formats\",\n",
      "    \\\"match_performance\": 0.6,\n",
      "    \\\"predicted_future_pe\n",
      "Error decoding JSON for row 46: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Kevin_Pietersen\",\n",
      "    \\\"Metrics\": \\\"Basic salary around ¬£400,000, commitment to England, strong batting skills, experienced in T20.\",\n",
      "    \\\"Insights\": \\\"Key player for England, known for aggressive batting style and ability to adapt to formats. Strong desire to play for national team over IPL.\",\n",
      "    \\\"Arguments\": \\\"Wants to play for England, against the draw of IPL despite lucrative offers; positive reputation for national performances.\",\n",
      "    \\\"match_performance\": 0.\n",
      "Error decoding JSON for row 47: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Lou_Vincent\",\n",
      "    \\\"Metrics\": \\\"Recent departure from New Zealand cricket, joining rebel league ICL\",\n",
      "    \\\"Insights\": \\\"Former player for New Zealand, known for explosive batting in limited-overs; currently in a controversial transition, impacting team depth\",\n",
      "    \\\"Arguments\": \\\"Negatively impacting New Zealand\\\"s team strength; questions raised about commitment to national cricket\",\n",
      "    \\\"match_performance\": 0.2,\n",
      "    \\\"predicted_future_performance\": 0.3\n",
      "  },\n",
      "  {\n",
      "  \n",
      "Error decoding JSON for row 48: Expecting property name enclosed in double quotes: line 3 column 9 (char 16)\n",
      "Problematic content: [\n",
      "    {\n",
      "        \\\"player_name\": \\\"Shane_Warne\",\n",
      "        \\\"Metrics\": \\\"Top dollar player; exceptional T20 record; key player in team branding.\",\n",
      "        \\\"Insights\": \\\"Star cricketer; strong in short formats; likely to be a crowd puller.\",\n",
      "        \\\"Arguments\": \\\"Strong potential as both player and brand ambassador; high expectations but faced competition.\",\n",
      "        \\\"match_performance\": 0.8,\n",
      "        \\\"predicted_future_performance\": 0.7\n",
      "    },\n",
      "    {\n",
      "        \\\"player_name\": \\\"Vijay_Mallya\",\n",
      "      \n",
      "Error decoding JSON for row 49: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Ishant_Sharma\",\n",
      "    \\\"Metrics\": \\\"Recent high auction price, critical role in IPL, potential for growth\",\n",
      "    \\\"Insights\": \\\"Fast bowler, inconsistent form historically, can excel if provided with proper training and support\",\n",
      "    \\\"Arguments\": \\\"Investment in player shows confidence in his ability to perform; critiques about price versus performance\",\n",
      "    \\\"match_performance\": 0.7,\n",
      "    \\\"predicted_future_performance\": 0.65\n",
      "  },\n",
      "  {\n",
      "    \\\"player_name\": \\\"Andrew_Symond\n",
      "Error decoding JSON for row 50: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Daniel_Vettori\",\n",
      "    \\\"Metrics\": \\\"Player keen on IPL inclusion in FTP; leadership role in New Zealand team\",\n",
      "    \\\"Insights\": \\\"Experienced all-rounder; adaptable to different formats; leadership in discussions; faces tough decisions on retirement under IPL pressures.\",\n",
      "    \\\"Arguments\": \\\"Supports balanced inclusion of IPL in FTP for player ease; suggests sustainability across formats.\",\n",
      "    \\\"match_performance\": 0.7,\n",
      "    \\\"predicted_future_performance\": 0.75\n",
      "  },\n",
      " \n",
      "Error decoding JSON for row 51: Expecting property name enclosed in double quotes: line 3 column 9 (char 16)\n",
      "Problematic content: [\n",
      "    {\n",
      "        \\\"player_name\": \\\"Michael_Kasprowicz\",\n",
      "        \\\"Metrics\": \\\"Former Test player, recently retired, played last game for Queensland.\",\n",
      "        \\\"Insights\": \\\"Bowler with experience, likely to adapt to formats, strong in domestic cricket.\",\n",
      "        \\\"Arguments\": \\\"Ready to join ICL, suggesting a shift to a competing league may impact local performance narratives.\",\n",
      "        \\\"match_performance\": 0.6,\n",
      "        \\\"predicted_future_performance\": 0.5\n",
      "    },\n",
      "    {\n",
      "        \\\"player_name\": \\\n",
      "Error decoding JSON for row 52: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Ross_Taylor\",\n",
      "    \\\"Metrics\": \\\"Notable signing for Bangalore franchise, historically strong in limited-overs cricket.\",\n",
      "    \\\"Insights\": \\\"Aggressive batting style, known as a \\\"biffer\\\". Complements team with ability to score quickly. Limited experience in IPL context.\",\n",
      "    \\\"Arguments\": \\\"Great signing to complement traditional players like Dravid, but may struggle with IPL pressure.\",\n",
      "    \\\"match_performance\": 0.7,\n",
      "    \\\"predicted_future_performance\": 0.6\n",
      "  },\n",
      "  \n",
      "Error decoding JSON for row 53: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Wasim_Jaffer\",\n",
      "    \\\"Metrics\": \\\"28 Tests, bought for US$ 150,000\",\n",
      "    \\\"Insights\": \\\"Opener with moderate experience; ability to adapt may be uncertain. Recently bought indicates some form of contributions.\",\n",
      "    \\\"Arguments\": \\\"Signed for a reasonable price compared to others; potential doubts about current form compared to others in IPL.\",\n",
      "    \\\"match_performance\": 0.6,\n",
      "    \\\"predicted_future_performance\": 0.5\n",
      "  },\n",
      "  {\n",
      "    \\\"player_name\": \\\"Ishant_Sharma\",\n",
      "    \\\"M\n",
      "Error decoding JSON for row 54: Expecting property name enclosed in double quotes: line 3 column 9 (char 16)\n",
      "Problematic content: [\n",
      "    {\n",
      "        \\\"player_name\": \\\"Greg_Shipperd\",\n",
      "        \\\"Metrics\": \\\"Unparalleled Twenty20 coaching record; Victoria won 3 titles in 3 years; only 1 loss\",\n",
      "        \\\"Insights\": \\\"Strong management skills; effective with international players; experience with high-pressure situations; focuses on team dynamics and performance adaptation\",\n",
      "        \\\"Arguments\": \\\"First priority is Cricket Victoria; positive coaching experience but potential conflict with IPL responsibilities\",\n",
      "        \\\"match_pe\n",
      "Error decoding JSON for row 55: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Justin_Langer\",\n",
      "    \\\"Metrics\": \\\"Former Australian opener; Experience in international cricket.\",\n",
      "    \\\"Insights\": \\\"Known for his solid technique and ability to anchor innings; essential for team stability.\",\n",
      "    \\\"Arguments\": \\\"Valuable experience; leadership potential but could be rusty after retirement.\",\n",
      "    \\\"match_performance\": 0.7,\n",
      "    \\\"predicted_future_performance\": 0.6\n",
      "  },\n",
      "  {\n",
      "    \\\"player_name\": \\\"Shane_Warne\",\n",
      "    \\\"Metrics\": \\\"Legendary leg-spinner; ov\n",
      "Error decoding JSON for row 56: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Shoaib_Akhtar\",\n",
      "    \\\"Metrics\": \\\"5-year ban by PCB; previously banned for 13 matches; over US$50,000 fine; 2-year probation following incident with Asif.\",\n",
      "    \\\"Insights\": \\\"Aggressive fast bowler; known for his speed and impact; faced issues with discipline; strong in T20 formats but struggles within team dynamics.\",\n",
      "    \\\"Arguments\": \\\"Criticism of PCB led to harsh penalties; previously strong performances overshadowed by off-field controversies; perception as a v\n",
      "Error decoding JSON for row 57: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Jeremy_Snape\",\n",
      "    \\\"Metrics\": \\\"Key player in Twenty20 format, helped Leicestershire to four finals days, won title in 2004, selected for inaugural World Twenty20.\",\n",
      "    \\\"Insights\": \\\"Specialist Twenty20 player, experienced in high-pressure matches, role as performance coach could enhance team strategy.\",\n",
      "    \\\"Arguments\": \\\"Strong track record in limited overs, but may miss county games affecting form temporarily.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_fu\n",
      "Error decoding JSON for row 58: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Tatenda_Taibu\",\n",
      "    \\\"Metrics\": \\\"Played in domestic T20; previously played in Bangladesh; played as captain for Zimbabwe.\",\n",
      "    \\\"Insights\": \\\"Experienced wicketkeeper-batsman; likely to adapt to T20 format; missed matches due to rescheduling.\",\n",
      "    \\\"Arguments\": \\\"Returns to subcontinent cricket; has previous IPL experience; current form in domestic T20 not mentioned.\",\n",
      "    \\\"match_performance\": 0.7,\n",
      "    \\\"predicted_future_performance\": 0.65\n",
      "  },\n",
      "  {\n",
      "    \\\"player_na\n",
      "Error decoding JSON for row 59: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Mohammad_Yousuf\",\n",
      "    \\\"Metrics\": \\\"Cited lack of match fitness; moved from ICL to IPL; financial incentive from IPL\",\n",
      "    \\\"Insights\": \\\"Experienced middle-order batsman; previously in poor form; potential for adaptation to IPL style, though fitness concerns exist\",\n",
      "    \\\"Arguments\": \\\"Positive expectation for IPL performance due to financial support; doubts raised from his recent backing out of the Test match\",\n",
      "    \\\"match_performance\": 0.6,\n",
      "    \\\"predicted_future_p\n",
      "Error decoding JSON for row 60: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Adam_Gilchrist\",\n",
      "    \\\"Metrics\": \\\"International retirement in March, eager for IPL; experienced T20 player; formerly reluctant but now embraces the format.\",\n",
      "    \\\"Insights\": \\\"Aggressive opening batsman; now resuming T20 participation; strong entertainer; valuable experience for IPL.\",\n",
      "    \\\"Arguments\": \\\"Positive arguments about embracing T20 format, sees IPL as a lucrative and exciting opportunity; prior concerns about format have shifted.\",\n",
      "    \\\"match_performanc\n",
      "Error decoding JSON for row 61: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Lasith_Malinga\",\n",
      "    \\\"Metrics\": \\\"91 wickets in 28 Tests, 79 wickets in 53 ODIs, diagnosed with a swollen bone on right knee, brought by Mumbai Indians for US$350,000.\",\n",
      "    \\\"Insights\": \\\"Fast bowler, known for yorkers and penetrating pace, has been under constant treatment, missed recent tours and IPL, expected to bowl in nets by first week of June, key player for upcoming Asia Cup.\",\n",
      "    \\\"Arguments\": \\\"First serious injury at 24, recovery is uncertain, concerns a\n",
      "Error decoding JSON for row 62: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Dimitri_Mascarenhas\",\n",
      "    \\\"Metrics\": \\\"Signed for IPL; potential risk of injury; only one England player signed, impact on English summer.\",\n",
      "    \\\"Insights\": \\\"All-rounder; capable of performing in T20 format; recent performances may lead to increased interest; however, injury risk is a concern.\",\n",
      "    \\\"Arguments\": \\\"Serious risk of injury while playing in IPL; could miss entire English summer; selection is dependent on NOC from ECB.\",\n",
      "    \\\"match_performance\": 0.6,\n",
      "\n",
      "Error decoding JSON for row 63: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Shane_Warne\",\n",
      "    \\\"Metrics\": \\\"Sign-on fee: US$400,000\",\n",
      "    \\\"Insights\": \\\"Experienced spinner, known for his strategic mind and ability to turn matches; strong in T20 format due to wicket-taking capabilities.\",\n",
      "    \\\"Arguments\": \\\"Strong reputation in T20; however, age may affect fitness and consistency.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_future_performance\": 0.7\n",
      "  },\n",
      "  {\n",
      "    \\\"player_name\": \\\"Glenn_McGrath\",\n",
      "    \\\"Metrics\": \\\"Sign-on fee: US$350,000\"\n",
      "Error decoding JSON for row 64: Expecting property name enclosed in double quotes: line 3 column 9 (char 16)\n",
      "Problematic content: [\n",
      "    {\n",
      "        \\\"player_name\": \\\"Yuvraj_Singh\",\n",
      "        \\\"Metrics\": \\\"Success in one-day cricket, highly regarded for Test cricket significance.\",\n",
      "        \\\"Insights\": \\\"Known for strong batting, needs Test performance for legacy; struggles with pressure in longer formats.\",\n",
      "        \\\"Arguments\": \\\"Desire to secure a spot in the pantheon of cricket through Test performance, aware of importance of Tests.\",\n",
      "        \\\"match_performance\": 0.7,\n",
      "        \\\"predicted_future_performance\": 0.6\n",
      "    },\n",
      "   \n",
      "Error decoding JSON for row 65: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Mark_Ramprakash\",\n",
      "    \\\"Metrics\": \\\"Contract with Surrey till end of 2009, approached by Rajasthan Royals, not included in IPL\",\n",
      "    \\\"Insights\": \\\"Experienced player, known for solid batting technique, strong performances for Surrey, likely seeking consistency over T20 format, fits in traditional format more effectively.\",\n",
      "    \\\"Arguments\": \\\"Rejection of IPL offer suggests focus on county commitments, potential to extend earnings could be compromised by schedule con\n",
      "Error decoding JSON for row 66: Expecting property name enclosed in double quotes: line 3 column 9 (char 16)\n",
      "Problematic content: [\n",
      "    {\n",
      "        \\\"player_name\": \\\"Dimitri_Mascarenhas\",\n",
      "        \\\"Metrics\": \\\"Notable coaching appointment; led where bigger names hesitated\",\n",
      "        \\\"Insights\": \\\"Experienced player; shows potential as a leader; valuable for lower-order contributions.\",\n",
      "        \\\"Arguments\": \\\"Positive: proactive in taking leadership roles; Negative: overshadowed by more famous players who want to follow.\",\n",
      "        \\\"match_performance\": 0.7,\n",
      "        \\\"predicted_future_performance\": 0.6\n",
      "    },\n",
      "    {\n",
      "        \\\"\n",
      "Error decoding JSON for row 67: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Shane_Warne\",\n",
      "    \\\"Metrics\": \\\"Legendary spinner, unmatched T20 experience, pivotal in match-winning scenarios\",\n",
      "    \\\"Insights\": \\\"Tactically astute, can adapt to various formats, excellent cricketing brain, past performance history showcases domination in spin bowling.\",\n",
      "    \\\"Arguments\": \\\"Strong pedigree in T20 despite recent retirement doubts; potentially impactful presence.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_future_performance\": 0.75\n",
      "  },\n",
      "  {\n",
      "    \n",
      "Error decoding JSON for row 68: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Shahid_Afridi\",\n",
      "    \\\"Metrics\": \\\"Key player for Deccan Chargers, strong T20 performance, known for explosive batting\",\n",
      "    \\\"Insights\": \\\"Aggressive all-rounder, can change game dynamics; suitable for T20 format but might miss series due to IPL commitments.\",\n",
      "    \\\"Arguments\": \\\"Positive reputation in T20, however, concerns about availability during proposed series.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_future_performance\": 0.7\n",
      "  },\n",
      "  {\n",
      "    \\\"player_name\":\n",
      "Error decoding JSON for row 69: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Darren_Lehmann\",\n",
      "    \\\"Metrics\": \\\"More than 25,000 runs, batting average 57.83, retired after 2007-08 season\",\n",
      "    \\\"Insights\": \\\"Experienced batsman, likely to bring stability; not played professional cricket recently; adapting to T20 format may be challenging\",\n",
      "    \\\"Arguments\": \\\"Positive: strong first-class record; Negative: long absence from competitive cricket, may struggle with match fitness and T20 demands\",\n",
      "    \\\"match_performance\": 0.7,\n",
      "    \\\"predicted_futu\n",
      "Error decoding JSON for row 70: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Brian_Lara\",\n",
      "    \\\"Metrics\": \\\"Notable achievements; past batting average of 40.48 in Tests; strong in limited-overs cricket.\",\n",
      "    \\\"Insights\": \\\"Aggressive batting style; excels in short formats; may struggle in Tests due to changing focus in domestic leagues.\",\n",
      "    \\\"Arguments\": \\\"Strong T20 record, but concerns about adaptation to Test cricket due to possible focus shift.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_future_performance\": 0.75\n",
      "  },\n",
      "  {\n",
      "    \\\"pla\n",
      "Error decoding JSON for row 71: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Ricky_Ponting\",\n",
      "    \\\"Metrics\": \\\"Test player; notable achievements include multiple Ashes wins; experienced leader.\",\n",
      "    \\\"Insights\": \\\"Aggressive batsman, good against pace; leadership role crucial for the team; recent form might be impacted by IPL commitments.\",\n",
      "    \\\"Arguments\": \\\"High value in Twenty20; however, preparation concerns for West Indies tour could affect performance.\",\n",
      "    \\\"match_performance\": 0.7,\n",
      "    \\\"predicted_future_performance\": 0.6\n",
      "  },\n",
      "  {\n",
      " \n",
      "Error decoding JSON for row 72: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Ricky_Ponting\",\n",
      "    \\\"Metrics\": \\\"Experienced player; known for excellent batting; great eye and foot movement; numerous records in Test and ODI formats.\",\n",
      "    \\\"Insights\": \\\"Key player in the T20 format; can adapt his game; brings professionalism and commitment; has high potential to perform when in form.\",\n",
      "    \\\"Arguments\": \\\"Positive impact expected due to professionalism; capable of changing the game but may take time to settle into innings.\",\n",
      "    \\\"match_performa\n",
      "Error decoding JSON for row 73: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Shoaib_Akhtar\",\n",
      "    \\\"Metrics\": \\\"Notable for express pace; historically good T20 stats; strong wicket-taking ability.\",\n",
      "    \\\"Insights\": \\\"Explosive fast bowler known for speed; good performance in Indian conditions; Experienced; has a positive relationship with Indian fans.\",\n",
      "    \\\"Arguments\": \\\"Positive narrative about his appeal in India; concerns over injury history; noted enthusiasm for IPL and Indian crowds.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_futu\n",
      "Error decoding JSON for row 74: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Loots_Bosman\",\n",
      "    \\\"Metrics\": \\\"Recently signed IPL contract, previous ICL contract offer 2.3 million rand, missed ICC World Twenty20 due to fitness concerns.\",\n",
      "    \\\"Insights\": \\\"South African opener; experienced in T20 format, aiming to return to domestic cricket; has faced fitness doubts impacting selection.\",\n",
      "    \\\"Arguments\": \\\"Positive: Choosing IPL for career growth; Negative: Recent suspension and missed opportunities due to fitness may hinder immediate perfo\n",
      "Error decoding JSON for row 75: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Brendon_McCullum\",\n",
      "    \\\"Metrics\": \\\"Strike rate of 300; 13 sixes, 10 fours in the match; known for aggressive batting.\",\n",
      "    \\\"Insights\": \\\"Explosive opener; strong T20 player; ability to shift momentum quickly; suitable for high-pressure situations.\",\n",
      "    \\\"Arguments\": \\\"Displayed dominant striking ability; game-changing performances; likely to outperform in future matches.\",\n",
      "    \\\"match_performance\": 1,\n",
      "    \\\"predicted_future_performance\": 0.9\n",
      "  },\n",
      "  {\n",
      "    \\\"player\n",
      "Error decoding JSON for row 76: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Irfan_Pathan\",\n",
      "    \\\"Metrics\": \\\"Notable all-rounder, experience in T20s, recent strong performances.\",\n",
      "    \\\"Insights\": \\\"Versatile player, known for pace bowling and explosive batting. Effective in both T20 and traditional formats, leans towards aggressive play.\",\n",
      "    \\\"Arguments\": \\\"Positive outlook due to experience and past performances, potential to perform well in IPL.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_future_performance\": 0.75\n",
      "  },\n",
      "  {\n",
      "    \\\"pla\n",
      "Error decoding JSON for row 77: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Michael_Clarke\",\n",
      "    \\\"Metrics\": \\\"Recent focus on international career; father\\\"s health impacting decisions\",\n",
      "    \\\"Insights\": \\\"Strong batsman with leadership qualities; prioritizing family time over IPL participation; aiming for long-term fitness and health\",\n",
      "    \\\"Arguments\": \\\"Positive emphasis on family values; dedication to international cricket; potential distractions from IPL money\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_future_performance\": 0.85\n",
      "  \n",
      "Error decoding JSON for row 78: Expecting property name enclosed in double quotes: line 3 column 9 (char 16)\n",
      "Problematic content: [\n",
      "    {\n",
      "        \\\"player_name\": \\\"Shane_Warne\",\n",
      "        \\\"Metrics\": \\\"Most expensive player at US$400,000; reputation of strong Twenty20 performance\",\n",
      "        \\\"Insights\": \\\"Legendary spin bowler; experienced in high-pressure situations; can influence matches significantly; playing style effective in limited overs.\",\n",
      "        \\\"Arguments\": \\\"High expectations due to past performances and high price; leadership qualities and vast experience may elevate team\\\"s performance.\",\n",
      "        \\\"match_perfor\n",
      "Error decoding JSON for row 79: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Chris_Gayle\",\n",
      "    \\\"Metrics\": \\\"Known for aggressive batting; previously high strike rate; experienced T20 player.\",\n",
      "    \\\"Insights\": \\\"Strong T20 player; explosive opening batsman; potential to win matches single-handedly; may struggle with team commitments due to IPL.\",\n",
      "    \\\"Arguments\": \\\"Valuable asset in T20; possible distraction from national commitments due to IPL.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_future_performance\": 0.7\n",
      "  },\n",
      "  {\n",
      "    \\\"player_n\n",
      "Error decoding JSON for row 80: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Chris_Gayle\",\n",
      "    \\\"Metrics\": \\\"Injury disqualified from IPL 1st edition, groin injury sustained in ODI, missed multiple matches\",\n",
      "    \\\"Insights\": \\\"Powerful batsman, known for explosive hitting, role as a key player in the batting line-up, currently sidelined due to injury\",\n",
      "    \\\"Arguments\": \\\"Negative: Unavailability due to injury raises concerns over fitness; Positive: Past performances indicate strong T20 capabilities if healthy\",\n",
      "    \\\"match_performance\": 0,\n",
      "  \n",
      "Error decoding JSON for row 81: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Justin_Kemp\",\n",
      "    \\\"Metrics\": \\\"Recent international focus; interest in IPL; 30 years old; history of strong performance in county cricket\",\n",
      "    \\\"Insights\": \\\"Experienced all-rounder; known for aggressive batting; possible adaptability to T20 format; critical role expected in county team strategy\",\n",
      "    \\\"Arguments\": \\\"Desires to play for Kent; documented history of intent to play county cricket; potential conflict with Indian leagues; uncertain availability due to EC\n",
      "Error decoding JSON for row 82: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Jacques_Kallis\",\n",
      "    \\\"Metrics\": \\\"High batting average, versatile allrounder, recognized for both batting and bowling\",\n",
      "    \\\"Insights\": \\\"Experienced player with strong technique, balanced skill set in both formats, currently concerned about workload affecting performance\",\n",
      "    \\\"Arguments\": \\\"Concerns about the decline of allrounders due to increased workload; suggests a window for IPL to help manage player fatigue\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_f\n",
      "Error decoding JSON for row 83: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Dwayne_Bravo\",\n",
      "    \\\"Metrics\": \\\"IPL participant; notable achievements include multiple T20 titles; experienced player.\",\n",
      "    \\\"Insights\": \\\"All-rounder; strong bowling skills with the ability to score runs; experienced in pressure situations; crucial for T20 format.\",\n",
      "    \\\"Arguments\": \\\"Positive impact on team; valuable experience, but less frequent inclusion in IPL indicates possible decline in form.\",\n",
      "    \\\"match_performance\": 0.7,\n",
      "    \\\"predicted_future_performan\n",
      "Error decoding JSON for row 84: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Yuvraj_Singh\",\n",
      "    \\\"Metrics\": \\\"Key player, former captain, strong batting average in T20, known for explosive performances.\",\n",
      "    \\\"Insights\": \\\"Aggressive batting style, experienced captain, proven track record in T20 format, crucial middle-order role.\",\n",
      "    \\\"Arguments\": \\\"Positive: Strong T20 record and leadership skills; Negative: Injury history may affect fitness.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_future_performance\": 0.7\n",
      "  },\n",
      "  {\n",
      "    \\\"player_na\n",
      "Error decoding JSON for row 85: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Michael_Vaughan\",\n",
      "    \\\"Metrics\": \\\"Notable leadership, expressed desire to play in IPL, past record as Test captain.\",\n",
      "    \\\"Insights\": \\\"Experienced Test captain, strong analytical abilities, likely to adapt well to T20 format; currently not participating.\",\n",
      "    \\\"Arguments\": \\\"Positively advocates for IPL; indicates a strong interest in being part of the league.\",\n",
      "    \\\"match_performance\": 0.4,\n",
      "    \\\"predicted_future_performance\": 0.7\n",
      "  },\n",
      "  {\n",
      "    \\\"player_name\": \\\n",
      "Error decoding JSON for row 86: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Jacques_Kallis\",\n",
      "    \\\"Metrics\": \\\"Test average: 55.37, ODI average: 44.83, purchased for US$ 900,000\",\n",
      "    \\\"Insights\": \\\"Experienced allrounder, strong in multiple formats, historically adapts well to various cricket forms, good at handling difficult situations with bat.\",\n",
      "    \\\"Arguments\": \\\"Experience as a Test player is a definite asset; concerns about adapting to the faster pace of T20.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_future_performance\": 0.75\n",
      " \n",
      "Error decoding JSON for row 87: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Dimitri_Mascarenhas\",\n",
      "    \\\"Metrics\": \\\"Part of England\\\"s one-day squad, recently signed with Jaipur for IPL, non-centrally contracted player, captain of Hampshire.\",\n",
      "    \\\"Insights\": \\\"Bowler with experience, likely to improve through exposure to world-class players, strong support from Hampshire management.\",\n",
      "    \\\"Arguments\": \\\"Has opportunity to play in IPL without jeopardizing international career; ECB\\\"s supportive stance on his participation.\",\n",
      "    \\\"match_per\n",
      "Error decoding JSON for row 88: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Virender_Sehwag\",\n",
      "    \\\"Metrics\": \\\"35-ball hundred in DY Patil All-India Invitation T20 championship, competitive scores in recent games\",\n",
      "    \\\"Insights\": \\\"Explosive batting style, strong in limited-overs format, known for aggressive play early in innings, fit for T20\",\n",
      "    \\\"Arguments\": \\\"Potential for high scores based on recent form, can take advantage of a new pitch\",\n",
      "    \\\"match_performance\": 0.9,\n",
      "    \\\"predicted_future_performance\": 0.8\n",
      "  }\n",
      "]\n",
      "Error decoding JSON for row 89: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Shane_Warne\",\n",
      "    \\\"Metrics\": \\\"Captain, experienced, involved in IPL\",\n",
      "    \\\"Insights\": \\\"Strategic leader, well-versed in T20 format, plays as a key spinner\",\n",
      "    \\\"Arguments\": \\\"Valuable player due to IPL experience; potential impact on team dynamics.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_future_performance\": 0.7\n",
      "  },\n",
      "  {\n",
      "    \\\"player_name\": \\\"Shane_Bond\",\n",
      "    \\\"Metrics\": \\\"Contract in doubt due to ICL involvement\",\n",
      "    \\\"Insights\": \\\"Fast bowler, key pl\n",
      "Error decoding JSON for row 90: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Brett_Lee\",\n",
      "    \\\"Metrics\": \\\"Noteworthy pace bowler; notable strike rate; experience in T20 format; past successes against top batsmen.\",\n",
      "    \\\"Insights\": \\\"Aggressive fast bowler; adept at taking wickets in T20; can be mentally strong but may struggle against top order batsmen like Tendulkar.\",\n",
      "    \\\"Arguments\": \\\"May face challenges in dismissing high-caliber players; opportunity for strong performance if taking advantage of conditions.\",\n",
      "    \\\"match_performance\": \n",
      "Error decoding JSON for row 91: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Pradeep_Sangwan\",\n",
      "    \\\"Metrics\": \\\"Young talent, promising fast bowler, no specific metrics mentioned.\",\n",
      "    \\\"Insights\": \\\"Role as a fast bowler, potential for growth under Lillee\\\"s mentorship, young and upcoming.\",\n",
      "    \\\"Arguments\": \\\"Positive outlook due to mentorship, opportunities for development.\",\n",
      "    \\\"match_performance\": 0.7,\n",
      "    \\\"predicted_future_performance\": 0.75\n",
      "  },\n",
      "  {\n",
      "    \\\"player_name\": \\\"Yo_Mahesh\",\n",
      "    \\\"Metrics\": \\\"Emerging fast bowler, recent f\n",
      "Error decoding JSON for row 92: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Ashley_Noffke\",\n",
      "    \\\"Metrics\": \\\"Part of Cricket Australia\\\"s contracted players for 2008-09, recent international honors, expected to gain experience from IPL.\",\n",
      "    \\\"Insights\": \\\"Bowler with focus on development, likely to utilize IPL exposure for skills enhancement, may have adaptability to T20 format.\",\n",
      "    \\\"Arguments\": \\\"Positive: Opportunity to bowl against top players, gain match experience; Negative: Came in as a last-minute replacement, may lack match read\n",
      "Error decoding JSON for row 93: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Andrew_Symonds\",\n",
      "    \\\"Metrics\": \\\"Improved bat quality, dramatic improvements in last 5 years\",\n",
      "    \\\"Insights\": \\\"Power-hitter, relies on hitting; potential drawback in tactical gameplay; fits well in explosive game formats like T20\",\n",
      "    \\\"Arguments\": \\\"Positive: recognizes advancements in equipment; highlights game evolution. Negative: concerns over dependency on power hitting\",\n",
      "    \\\"match_performance\": 0.7,\n",
      "    \\\"predicted_future_performance\": 0.6\n",
      "  }\n",
      "]\n",
      "Error decoding JSON for row 94: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Shoaib_Akhtar\",\n",
      "    \\\"Metrics\": \\\"Banned for five years by PCB; $450,000 bid in IPL.\",\n",
      "    \\\"Insights\": \\\"Known for his express fast bowling; has faced disciplinary issues; currently unfit to play in IPL due to ban.\",\n",
      "    \\\"Arguments\": \\\"Plans to appeal ban; questions about disciplinary record despite being selected by Kolkata.\",\n",
      "    \\\"match_performance\": 0,\n",
      "    \\\"predicted_future_performance\": 0.2\n",
      "  },\n",
      "  {\n",
      "    \\\"player_name\": \\\"Shahrukh_Khan\",\n",
      "    \\\"Metrics\": \\\"Owner\n",
      "Error decoding JSON for row 95: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Ricky_Ponting\",\n",
      "    \\\"Metrics\": \\\"Captain; experienced top-order batsman; notable international achievements.\",\n",
      "    \\\"Insights\": \\\"Aggressive batting style; experienced in high-pressure situations; key strategist for the team.\",\n",
      "    \\\"Arguments\": \\\"Positive narrative due to leadership and extensive experience; could be challenged by upcoming tours affecting availability.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_future_performance\": 0.7\n",
      "  },\n",
      "  {\n",
      "    \\\"player_na\n",
      "Error decoding JSON for row 96: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Daniel_Vettori\",\n",
      "    \\\"Metrics\": \\\"Key player for New Zealand, missed warm-up matches due to IPL commitments.\",\n",
      "    \\\"Insights\": \\\"Experienced captain, known for spin bowling and lower-order batting. Leadership role; may struggle with focus due to league distractions.\",\n",
      "    \\\"Arguments\": \\\"Negative sentiment regarding prioritization of IPL over national duties; possible impact on team dynamics.\",\n",
      "    \\\"match_performance\": 0.6,\n",
      "    \\\"predicted_future_performance\": 0.65\n",
      "Error decoding JSON for row 97: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Shane_Bond\",\n",
      "    \\\"Metrics\": \\\"Key player for New Zealand, left for Indian Cricket League, significantly higher IPL contract compared to international pay.\",\n",
      "    \\\"Insights\": \\\"Fast bowler, experienced with a focus on limited-overs cricket. Lack of recent international matches may affect form.\",\n",
      "    \\\"Arguments\": \\\"Positive: Potentially high earnings from IPL; Negative: Risk of not contributing to New Zealand cricket if he chooses IPL over national duty.\",\n",
      "    \\\"match\n",
      "Error decoding JSON for row 98: Expecting property name enclosed in double quotes: line 3 column 5 (char 10)\n",
      "Problematic content: [\n",
      "  {\n",
      "    \\\"player_name\": \\\"Rahul_Dravid\",\n",
      "    \\\"Metrics\": \\\"Captain of Royal Challengers, notable leadership skills, experience in T20 format.\",\n",
      "    \\\"Insights\": \\\"Experienced batsman, solid technique, key leader for the team, adapting to shorter formats.\",\n",
      "    \\\"Arguments\": \\\"Positive narrative around leadership; expected to utilize experience effectively in T20.\",\n",
      "    \\\"match_performance\": 0.8,\n",
      "    \\\"predicted_future_performance\": 0.75\n",
      "  },\n",
      "  {\n",
      "    \\\"player_name\": \\\"Zaheer_Khan\",\n",
      "    \\\"Metric\n",
      "Processed CSV saved at: /Users/hemantg/Desktop/try-processed_output5.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Load the CSV\n",
    "input_file = '/Users/hemantg/Desktop/try-combined-output.csv'  # Replace with the actual file path\n",
    "df = pd.read_csv(input_file, sep=',')\n",
    "\n",
    "# Inspect columns\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# Initialize a list to store processed rows\n",
    "processed_rows = []\n",
    "\n",
    "# Enhanced JSON cleaning function\n",
    "def clean_json_string(json_string):\n",
    "    cleaned = (\n",
    "        json_string.strip()\n",
    "        .replace(\"```json\", \"\")\n",
    "        .replace(\"```\", \"\")\n",
    "        .replace(\"“\", '\"')\n",
    "        .replace(\"”\", '\"')\n",
    "        .replace(\"‘\", \"'\")\n",
    "        .replace(\"’\", \"'\")\n",
    "        .replace(\"'\", '\"')  # Fix single quotes\n",
    "    )\n",
    "\n",
    "    # Fix common JSON issues:\n",
    "    cleaned = re.sub(r'([^\\\\])\"(?![:,}\\]])', r'\\1\\\\\"', cleaned)  # Escape unescaped quotes inside text\n",
    "    cleaned = re.sub(r'(\\}\\s*)(\\{)', r'\\1,\\2', cleaned)  # Add missing commas between objects\n",
    "    cleaned = re.sub(r'^[^{\\[]*|[^}\\]]*$', '', cleaned, flags=re.DOTALL)  # Remove non-JSON text outside braces\n",
    "    return cleaned\n",
    "\n",
    "# Safer JSON loading function\n",
    "def safe_json_loads(json_string, row_index):\n",
    "    try:\n",
    "        return json.loads(json_string, strict=False)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON for row {row_index}: {e}\")\n",
    "        print(f\"Problematic content: {json_string[:500]}\")  # Show first 500 chars\n",
    "        return None\n",
    "\n",
    "# Process each row\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        date = row['date']\n",
    "        processed_results = row['processed_results']\n",
    "\n",
    "        # Ensure the value is not empty\n",
    "        if pd.notna(processed_results) and processed_results.strip():\n",
    "            cleaned_json = clean_json_string(processed_results)\n",
    "            players_data = safe_json_loads(cleaned_json, index)\n",
    "\n",
    "            if players_data is None:\n",
    "                continue\n",
    "\n",
    "            # Ensure it's a list\n",
    "            if isinstance(players_data, list):\n",
    "                row_data = {'date': date}\n",
    "\n",
    "                # Extract player information\n",
    "                for i, player in enumerate(players_data):\n",
    "                    row_data[f'player{i+1}_name'] = player.get('player_name', 'N/A')\n",
    "                    row_data[f'player{i+1}_output'] = json.dumps(player, ensure_ascii=False)\n",
    "\n",
    "                processed_rows.append(row_data)\n",
    "            else:\n",
    "                print(f\"Unexpected data type at row {index}: {type(players_data)}\")\n",
    "        else:\n",
    "            print(f\"Empty or invalid processed_results at row {index}\")\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing column: {e}\")\n",
    "    except TypeError as e:\n",
    "        print(f\"TypeError at row {index}: {e}\")\n",
    "\n",
    "# Create a new DataFrame\n",
    "output_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Save to a new CSV file\n",
    "output_file = '/Users/hemantg/Desktop/try-processed_output5.csv'\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Processed CSV saved at: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Metrics:   7%|▋         | 42/579 [01:35<20:16,  2.27s/it]\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(texts), batch_size), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     28\u001b[0m     batch_texts \u001b[38;5;241m=\u001b[39m texts[i:i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m---> 29\u001b[0m     batch_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mget_batch_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mextend(batch_embeddings)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Add the embeddings to the dataframe\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 10\u001b[0m, in \u001b[0;36mget_batch_embeddings\u001b[0;34m(texts, engine)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_batch_embeddings\u001b[39m(texts, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-3-large\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 10\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/api_resources/embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;66;03m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;66;03m# This is only for the default case.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    613\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    614\u001b[0m         )\n\u001b[1;32m    615\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    616\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    625\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    626\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/api_requestor.py:682\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    680\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    683\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: '$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set OpenAI API Key\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Function to generate embeddings for a batch of texts\n",
    "def get_batch_embeddings(texts, engine=\"text-embedding-3-large\"):\n",
    "    response = openai.Embedding.create(input=texts, engine=engine)\n",
    "    return [item['embedding'] for item in response['data']]\n",
    "\n",
    "# Load the CSV file\n",
    "input_file = \"/Users/hemantg/Downloads/data_ready.csv\"  # Update this path to your file\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Columns to generate embeddings for\n",
    "text_columns = [\"Metrics\", \"Insights\", \"Arguments\"]\n",
    "batch_size = 50  # Adjust the batch size depending on your API rate limits\n",
    "\n",
    "# Process each column\n",
    "for col in text_columns:\n",
    "    embeddings = []\n",
    "    texts = data[col].fillna(\"\").tolist()  # Replace NaNs with empty strings\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=f\"Processing {col}\"):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        batch_embeddings = get_batch_embeddings(batch_texts)\n",
    "        embeddings.extend(batch_embeddings)\n",
    "    \n",
    "    # Add the embeddings to the dataframe\n",
    "    data[f\"{col}_embeddings\"] = embeddings\n",
    "\n",
    "# Save the updated CSV\n",
    "output_file = \"/Users/hemantg/Downloads/player_performance_with_embeddings.csv\"\n",
    "data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Updated CSV saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Metrics:   9%|▊         | 5/58 [00:16<02:30,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing batch 2000-2500: '$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Metrics:  10%|█         | 6/58 [00:16<01:46,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing batch 2500-3000: '$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Metrics:  19%|█▉        | 11/58 [00:34<02:08,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing batch 5000-5500: '$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Metrics:  29%|██▉       | 17/58 [00:55<02:06,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing batch 8000-8500: '$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Metrics:  38%|███▊      | 22/58 [01:14<01:53,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing batch 10500-11000: '$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Metrics:  53%|█████▎    | 31/58 [01:44<01:17,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing batch 15000-15500: '$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Metrics:  55%|█████▌    | 32/58 [01:45<00:56,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing batch 15500-16000: '$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Metrics:  84%|████████▍ | 49/58 [02:51<00:28,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing batch 24000-24500: '$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Metrics:  98%|█████████▊| 57/58 [03:20<00:02,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing batch 28000-28500: '$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Metrics: 100%|██████████| 58/58 [03:25<00:00,  3.54s/it]\n",
      "Processing Insights:  17%|█▋        | 10/58 [00:42<02:48,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing batch 4500-5000: '$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Insights: 100%|██████████| 58/58 [04:25<00:00,  4.57s/it]\n",
      "Processing Arguments:  17%|█▋        | 10/58 [00:38<02:13,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing batch 4500-5000: '$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Arguments: 100%|██████████| 58/58 [04:06<00:00,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved as /Users/hemantg/Downloads/player_performance_with_embeddings_final.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Function to generate embeddings for a batch of texts\n",
    "def get_batch_embeddings(texts, engine=\"text-embedding-3-large\"):\n",
    "    \"\"\"\n",
    "    Generate embeddings for a batch of texts.\n",
    "    \"\"\"\n",
    "    # Ensure texts are strings\n",
    "    texts = [str(text) for text in texts]\n",
    "    response = openai.Embedding.create(input=texts, engine=engine)\n",
    "    return [item['embedding'] for item in response['data']]\n",
    "\n",
    "# Load the CSV file\n",
    "input_file = \"/Users/hemantg/Downloads/data_ready.csv\"  # Update this path to your file\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Columns to generate embeddings for\n",
    "text_columns = [\"Metrics\", \"Insights\", \"Arguments\"]\n",
    "batch_size = 500  # Adjust the batch size based on the API limits\n",
    "\n",
    "# Process each column\n",
    "for col in text_columns:\n",
    "    embeddings = []\n",
    "    texts = data[col].fillna(\"\").tolist()  # Replace NaNs with empty strings\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=f\"Processing {col}\"):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        try:\n",
    "            batch_embeddings = get_batch_embeddings(batch_texts)\n",
    "            embeddings.extend(batch_embeddings)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {i}-{i + batch_size}: {e}\")\n",
    "            embeddings.extend([None] * len(batch_texts))  # Add placeholders for failed batches\n",
    "    \n",
    "    # Add the embeddings to the dataframe\n",
    "    data[f\"{col}_embeddings\"] = embeddings\n",
    "\n",
    "# Save the updated CSV\n",
    "output_file = \"/Users/hemantg/Downloads/player_performance_with_embeddings_final.csv\"\n",
    "data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Updated CSV saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4500 rows with missing Metrics_embeddings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Metrics: 100%|██████████| 4500/4500 [59:34<00:00,  1.26it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 500 rows with missing Insights_embeddings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Insights: 100%|██████████| 500/500 [06:25<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 500 rows with missing Arguments_embeddings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Arguments: 100%|██████████| 500/500 [06:04<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved as /Users/hemantg/Downloads/player_performance_with_embeddings_final1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Function to generate embeddings for a single text\n",
    "def get_single_embedding(text, engine=\"text-embedding-3-large\"):\n",
    "    \"\"\"\n",
    "    Generate an embedding for a single text.\n",
    "    \"\"\"\n",
    "    text = str(text)  # Ensure the text is a string\n",
    "    response = openai.Embedding.create(input=[text], engine=engine)\n",
    "    return response['data'][0]['embedding']\n",
    "\n",
    "# Load the CSV file\n",
    "input_file = \"/Users/hemantg/Downloads/player_performance_with_embeddings_final.csv\"  # Update this path to your file\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Columns to generate embeddings for\n",
    "text_columns = [\"Metrics\", \"Insights\", \"Arguments\"]\n",
    "\n",
    "# Process each column\n",
    "for col in text_columns:\n",
    "    embedding_col = f\"{col}_embeddings\"\n",
    "\n",
    "    # Check if the embedding column already exists\n",
    "    if embedding_col not in data.columns:\n",
    "        print(f\"Embedding column {embedding_col} not found. Creating a new column with None values.\")\n",
    "        data[embedding_col] = None\n",
    "\n",
    "    # Identify rows with missing embeddings\n",
    "    rows_to_process = data[data[embedding_col].isna()]\n",
    "    print(f\"Processing {len(rows_to_process)} rows with missing {embedding_col}.\")\n",
    "\n",
    "    # Process rows sequentially\n",
    "    for index, row in tqdm(rows_to_process.iterrows(), total=len(rows_to_process), desc=f\"Processing {col}\"):\n",
    "        try:\n",
    "            embedding = get_single_embedding(row[col])\n",
    "            data.at[index, embedding_col] = embedding  # Update the embedding column\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {index}: {e}\")\n",
    "            continue\n",
    "\n",
    "# Save the updated CSV\n",
    "output_file = \"/Users/hemantg/Downloads/player_performance_with_embeddings_final1.csv\"\n",
    "data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Updated CSV saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"/Users/hemantg/Downloads/player_performance_with_embeddings_final1.csv\")\n",
    "df2 = pd.read_csv(\"/Users/hemantg/Downloads/player_performance_with_embeddings_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>Metrics</th>\n",
       "      <th>Insights</th>\n",
       "      <th>Arguments</th>\n",
       "      <th>match_performance</th>\n",
       "      <th>predicted_future_performance</th>\n",
       "      <th>date</th>\n",
       "      <th>Metrics_embeddings</th>\n",
       "      <th>Insights_embeddings</th>\n",
       "      <th>Arguments_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28904</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28905</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28906</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28907</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28908</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28909 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       player_name  Metrics  Insights  Arguments  match_performance  \\\n",
       "0            False    False     False      False              False   \n",
       "1            False    False     False      False              False   \n",
       "2            False    False     False      False              False   \n",
       "3            False    False     False      False              False   \n",
       "4            False    False     False      False              False   \n",
       "...            ...      ...       ...        ...                ...   \n",
       "28904        False    False     False      False              False   \n",
       "28905        False    False     False      False              False   \n",
       "28906        False    False     False      False              False   \n",
       "28907        False    False     False      False              False   \n",
       "28908        False    False     False      False              False   \n",
       "\n",
       "       predicted_future_performance   date  Metrics_embeddings  \\\n",
       "0                             False  False               False   \n",
       "1                             False  False               False   \n",
       "2                             False  False               False   \n",
       "3                             False  False               False   \n",
       "4                             False  False               False   \n",
       "...                             ...    ...                 ...   \n",
       "28904                         False  False               False   \n",
       "28905                         False  False               False   \n",
       "28906                         False  False               False   \n",
       "28907                         False  False               False   \n",
       "28908                         False  False               False   \n",
       "\n",
       "       Insights_embeddings  Arguments_embeddings  \n",
       "0                    False                 False  \n",
       "1                    False                 False  \n",
       "2                    False                 False  \n",
       "3                    False                 False  \n",
       "4                    False                 False  \n",
       "...                    ...                   ...  \n",
       "28904                False                 False  \n",
       "28905                False                 False  \n",
       "28906                False                 False  \n",
       "28907                False                 False  \n",
       "28908                False                 False  \n",
       "\n",
       "[28909 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [-0.0035224382299929857, -0.03489496186375618,...\n",
       "1        [-0.023905431851744652, -0.006605220027267933,...\n",
       "2        [0.006208884529769421, 0.022419022396206856, -...\n",
       "3        [0.02593395859003067, -0.024754418060183525, -...\n",
       "4        [0.0013744279276579618, 0.009274468757212162, ...\n",
       "                               ...                        \n",
       "28904    [-0.0012793116038665175, -0.02274535596370697,...\n",
       "28905    [0.023514321073889732, -0.023244429379701614, ...\n",
       "28906    [0.009010076522827148, 0.00954776257276535, -0...\n",
       "28907    [0.009952873922884464, -0.023141490295529366, ...\n",
       "28908    [-0.008739352226257324, -0.01818043924868107, ...\n",
       "Name: Arguments_embeddings, Length: 28909, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Metrics:   7%|▋         | 2136/28909 [29:27<4:41:14,  1.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating embedding for text: ... Error: '$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Metrics:  10%|█         | 2966/28909 [42:04<5:11:27,  1.39it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating embedding for text: ... Error: '$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Metrics:  10%|█         | 2968/28909 [42:05<4:41:30,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating embedding for text: ... Error: '$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Metrics:  10%|█         | 2969/28909 [42:06<4:04:52,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating embedding for text: ... Error: '$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Metrics:  18%|█▊        | 5259/28909 [1:16:59<5:06:03,  1.29it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating embedding for text: ... Error: '$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Metrics:  21%|██        | 6018/28909 [1:30:13<5:21:38,  1.19it/s] "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Function to generate embedding for a single text\n",
    "def get_single_embedding(text, engine=\"text-embedding-3-large\"):\n",
    "    \"\"\"\n",
    "    Generate embedding for a single text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure text is a string\n",
    "        text = str(text) if text is not None else \"\"\n",
    "        response = openai.Embedding.create(input=[text], engine=engine)\n",
    "        return response['data'][0]['embedding']\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating embedding for text: {text[:50]}... Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the CSV file\n",
    "input_file = \"/Users/hemantg/Desktop/DL Project Sem5 -- Nighter/data_ready.csv\"  # Update this path to your file\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Columns to generate embeddings for\n",
    "text_columns = [\"Metrics\", \"Insights\", \"Arguments\"]\n",
    "\n",
    "# Process each column\n",
    "for col in text_columns:\n",
    "    # Generate embeddings row by row\n",
    "    embeddings = []\n",
    "    for text in tqdm(data[col].fillna(\"\"), desc=f\"Processing {col}\"):\n",
    "        embedding = get_single_embedding(text)\n",
    "        embeddings.append(embedding)\n",
    "    \n",
    "    # Add the embeddings to the dataframe\n",
    "    data[f\"{col}_embeddings\"] = embeddings\n",
    "\n",
    "# Save the updated CSV\n",
    "output_file = \"'/Users/hemantg/Desktop/DL Project Sem5 -- Nighter/player_performance_with_embeddings_final-squared.csv\"\n",
    "data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Updated CSV saved as {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
